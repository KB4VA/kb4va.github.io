[{"viewId": "vis-2819_00_0", "viewFile": "vis-2819_00_0.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "line", "encoding": {"x": {"field": "map_x", "type": "quantitative"}, "y": {"field": "map_y", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}, "opacity": {"field": "time", "type": "temporal"}}}, {"mark": "point", "encoding": {"x": {"field": "player_x", "type": "quantitative"}, "y": {"field": "player_y", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}, "stroke": {"field": "opponent_meet", "type": "nominal"}, "opacity": {"field": "time", "type": "temporal"}}}, {"mark": "point", "remark": "Players from the same camp form a bubble if they are close to each other", "encoding": {"x": {"field": "player_x", "type": "quantitative"}, "y": {"field": "player_y", "type": "quantitative"}, "color": {"field": "team", "type": "nominal"}}}, {"mark": "graph", "remark": "And attack actions are represented by a moving arrow from the attacker", "encoding": {"node": {"field": "player", "type": "node"}, "link": {"field": "attack", "type": "nominal"}}}]}, "marks": ["geoshape", "line", "point", "graph"], "channels": ["x", "y", "color", "opacity", "stroke", "node", "link"], "dataTypes": ["quantitative", "nominal", "temporal", "node", "relation"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.011662436366473131, "y": 0.009484831769116629, "width": 0.18559982464634114, "height": 0.5578519424337165}, "figVis": ["map"], "relationText": "We display the gameplay dynamics in a game map in the TrajectoryView (Fig. 7) to simulate real matches (R.2).", "note": "Filtering is mentioned in R.2."}, {"viewId": "vis-2819_00_1", "viewFile": "vis-2819_00_1.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "resource", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}}}, {"nested": {"child": {"child_type": "configured", "canvas": "point", "configuration": {"mark": "arc", "encoding": {"theta": {"field": "resource_value", "type": "quantitative"}, "color": {"field": "original_value_or_change", "type": "nominal"}}}}, "parent": {"mark": "point", "remark": "An arrow indicates that a upgrading behavior occurs", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "resource", "type": "quantitative"}}}}}, {"mark": "others", "encoding": {"x": {"field": "time", "type": "temporal"}, "icon": {"field": "action_type", "type": "nominal", "remark": "In addition, we design a glyph icon for each tactical action and group them based on our data analyst\u2019s suggestions (E.2)."}}}]}, "marks": ["line", "arc", "point", "others"], "channels": ["x", "y", "color", "theta", "icon"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["layer", "nested"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-distribution", "query-summarize:Attributes-correlation"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.2094730706716508, "y": 0.008156205293599566, "width": 0.4940422174784336, "height": 0.5565294612716374}, "figVis": ["line_chart"], "relationText": "This view serves as an extension of the Trend View and displays more detailed information on resource within the user-selected timeframe(F.2).\n\n{upgrading events, effect of a tactical action on its executor\u2019s status}\n\nr. It provides a overview of how players are distributed across the battle field over time which is easier to obtain than using the interactive approach in the four design alternatives.", "note": "(N, [T, Q, (1, N, Q, N)])"}, {"viewId": "vis-2819_00_2", "viewFile": "vis-2819_00_2.png", "specification": {"mark": "radar", "layout": "Bezier curve", "encoding": {"theta": {"field": "metric_type", "type": "nominal"}, "radius": {"field": "metric_value", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}}}, "marks": ["radar"], "channels": ["theta", "radius", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.8033724140242783, "y": 0.585697384415274, "width": 0.18034520856398806, "height": 0.40301352149592407}, "figVis": ["others", "polar_plot"], "relationText": "To provide a summary of the results of such evolution, a Player Billing Radar on the right (Fig. 1f) displays the overall statistics of each player. ", "note": ""}, {"viewId": "vis-2819_00_3", "viewFile": "vis-2819_00_3.png", "specification": {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "action_type", "type": "nominal"}, "size": {"field": "action", "aggregate": "count", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"mark": "arc", "encoding": {"theta": {"field": "value", "type": "quantitative"}, "color": {"field": "team", "type": "nominal"}}}}}}, "marks": ["point", "arc"], "channels": ["x", "y", "size", "theta", "color"], "dataTypes": ["temporal", "nominal", "quantitative"], "compositions": ["nested"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.2876108369798785, "y": 0.5844699752521616, "width": 0.26271084170820796, "height": 0.41342780804837864}, "figVis": ["matrix", "pie_chart"], "relationText": "We develop the Matrix View (Fig. 1e) to unfold the temporal dynamics of all the tactical actions (F.2) in the two camps, providing an overview of the match from the tactics\u2019 perspective (R.1)", "note": "(Category, Value, Size)"}, {"viewId": "vis-2819_00_4", "viewFile": "vis-2819_00_4.png", "specification": {"facet": {"row": {"field": "player", "type": "nominal"}}, "spec": {"mark": "graph", "encoding": {"node": {"field": "equipment", "type": "node", "shape": {"field": "equipment_type", "type": "nominal"}, "color": {"field": "player", "type": "nominal"}, "x": {"field": "time", "type": "temporal"}}, "link": {"field": "evolution_hierarchy", "type": "nominal", "width": {"field": "cost", "type": "quantitative"}}}}}, "marks": ["graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.5515168166878816, "y": 0.5924574053102545, "width": 0.24368450933457414, "height": 0.3949154178699359}, "figVis": ["graph"], "relationText": "To capture this, we design an Equipment Evolution View, which different types of equip-ment are encoded by different glyphs (A.2) and the equipment levels are visualized by the sizes of the glyphs", "note": "All equipment of players can evolve that allows a significant im-provement of the abilities for each character."}, {"viewId": "vis-2819_00_5", "viewFile": "vis-2819_00_5.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "distance", "type": "quantitative"}, "color": {"field": "team", "type": "nominal"}}}, {"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "intra-team distance", "aggregate": "average", "type": "quantitative"}}}]}, "marks": ["line", "area"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["layer"], "aggregates": ["average"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.011872723890238617, "y": 0.59405582685056, "width": 0.2655487807634665, "height": 0.14087969964983738}, "figVis": ["bar_chart", "line_chart"], "relationText": "The Trend View (Fig. 5) provides an overview of the game progress during a match (R.1). ", "note": "(time, [chart1, chart2, chart3])"}, {"viewId": "vis-2819_00_6", "viewFile": "vis-2819_00_6.png", "specification": {"layer": [{"remark": "Combats", "facet": {"layout": "mirrored", "row": {"field": "team", "type": "nominal"}, "color": {"field": "team", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "combat_result", "type": "quantitative"}, "width": {"field": "duration", "type": "quantitative"}}}}, {"mark": "point", "remark": "attacking towers", "encoding": {"x": {"field": "time", "type": "temporal"}, "color": {"field": "team", "type": "nominal"}}}, {"mark": "others", "remark": "occupying light towers", "encoding": {"x": {"field": "time", "type": "temporal"}, "stroke": {"field": "team", "type": "nominal"}}}]}, "marks": ["bar", "point", "others"], "channels": ["x", "y", "width", "color", "stroke"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["layer", "facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.011118367866509701, "y": 0.7273858756292416, "width": 0.2291974657333601, "height": 0.14363056975983438}, "figVis": ["bar_chart"], "relationText": "After this, to display the periods of time when importantevents occur (F.2), we provide a timeline view with bars suggestingthe duration of combats, circle dots representing timestamps of towerattacking and glyphs indicating the starting time of the occupation oflight towers(See Fig. 6b).", "note": ""}, {"viewId": "vis-2819_00_7", "viewFile": "vis-2819_00_7.png", "specification": {"layer": [{"facet": {"layout": "mirrored", "row": {"field": "team", "type": "nominal"}, "color": {"field": "team", "type": "nominal"}}, "spec": {"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "resource", "type": "quantitative"}}}}, {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "resource_difference", "type": "quantitative"}}}]}, "marks": ["area", "line"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": ["layer", "facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-correlation"], "figId": "vis-2819_00", "figFile": "vis-2819_00.png", "figCaption": "", "figBox": {"x": 0.009803937720596309, "y": 0.8759346705164955, "width": 0.2331547480279076, "height": 0.11317516556412968}, "figVis": ["area_chart", "line_chart"], "relationText": "Lastly, the comparison view (Fig. 5c) displays the change of accu-mulated resources of each team in terms of cash, experience (F.3) and killing counts (F.4), with a black line in the middle showing the valuedifference between the two teams.", "note": ""}, {"viewId": "vis-2821_00_0", "viewFile": "vis-2821_00_0.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "surface", "encoding": {"x": {"field": "geo_x", "type": "quantitative"}, "y": {"field": "geo_y", "type": "quantitative"}, "surface": {"field": "density", "type": "quantitative"}}}]}, "marks": ["geoshape", "surface"], "channels": ["x", "y", "surface"], "dataTypes": ["quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2821_00", "figFile": "vis-2821_00.png", "figCaption": "", "figBox": {"x": 0.12418549043978253, "y": 0.04196350950221263, "width": 0.3816634913624691, "height": 0.6603479436838932}, "figVis": ["map", "heatmap"], "relationText": "{OD}\n\nThus, we add a heatmap layer, where we provide users with two types of density maps, namely, the OD and road heatmap (Fig. 2).\n\nThe area dimensionality reductionawing layer provides the function of dimensionality reductionawing polygons in the map, enabling users to specify the target and solution areas (i.e., the areas considered for placing billboards) in the forms of red and blue polygons, respectively (Fig. 2).", "note": "(latitude, longitude, [heatmap value,POI])"}, {"viewId": "vis-2821_00_1", "viewFile": "vis-2821_00_1.png", "specification": {"facet": {"column": {"field": "solution", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature", "type": "nominal"}, "y": {"field": "feature_value", "type": "quantitative"}, "color": {"field": "solution", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2821_00", "figFile": "vis-2821_00.png", "figCaption": "", "figBox": {"x": 0.12814585168466222, "y": 0.7486981967439935, "width": 0.3763996128781535, "height": 0.2309790576135588}, "figVis": ["bar_chart"], "relationText": "The horizontally laid boxes enable users to perform a rough-level comparison among candidate solutions; thus, the solutions with poor performances can be easily detected and deleted (R4)\n\n{the number of billboard (N), cost (C), average speed (S), traffic volume (V), value for money (M), reach (R), OTS (O), and GRP (G)}\n\nWhen users hover over a bar of one solution, the bars indicating the same attribute values of other solutions would be highlighted to facilitate comparison (as shown in Fig. 6 #1 - #6)", "note": "(solution,(attribute, value))"}, {"viewId": "vis-2821_00_2", "viewFile": "vis-2821_00_2.png", "specification": {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "MDS_x", "type": "quantitative"}, "y": {"field": "MDS_y", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"layer": [{"mark": "boxplot", "layout": "circular", "encoding": {"y": {"field": "speed", "type": "quantitative"}}}, {"mark": "arc", "layout": "circular", "encoding": {"theta": {"field": "speed", "type": "quantitative"}, "color": {"field": "speed", "type": "quantitative"}}}, {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "remark": "weekday_reach", "layout": "circular", "encoding": {"y": {"field": "reach", "type": "quantitative"}}}, {"mark": "bar", "layout": "circular", "remark": "weekend_reach", "encoding": {"y": {"field": "reach", "type": "quantitative"}}}]}, {"mark": "point", "layout": "circular", "encoding": {"x": {"field": "POI_category", "type": "nominal"}, "size": {"field": "POI", "aggregate": "count", "type": "nominal"}}}]}}}}, "marks": ["point", "boxplot", "arc", "bar"], "channels": ["x", "y", "theta", "color", "size"], "dataTypes": ["quantitative", "nominal"], "compositions": ["nested", "layer", "concat"], "aggregates": ["count"], "actionTargets": ["query-summarize:Attributes-values", "consume-present:Attributes-similarity"], "figId": "vis-2821_00", "figFile": "vis-2821_00.png", "figCaption": "", "figBox": {"x": 0.5273897570382906, "y": 0.033876364111884445, "width": 0.2447796475371387, "height": 0.5177963492366096}, "figVis": ["glyph_based"], "relationText": "The solution view aims to provide users with a visual summary of each solution and the relationships among them (R5, R6)\n\nWe compute the similarities among different solutions and utilize Multidimensional Scaling (MDS) [27] to create the layout.", "note": "(Pos, Pos, [Reach, speed, others])"}, {"viewId": "vis-2821_00_3", "viewFile": "vis-2821_00_3.png", "specification": {"nested": {"parent": {"mark": "point", "remark": "derived a layout algorithm by extending Dorling cartogram to show the value-by-location maps effectively", "encoding": {"x": {"field": "Dorling_x", "type": "quantitative"}, "y": {"field": "Dorling_y", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"layer": [{"mark": "geoshape"}, {"mark": "point", "encoding": {"x": {"field": "geo_x", "type": "quantitative"}, "y": {"field": "geo_y", "type": "quantitative"}}}, {"mark": "bar", "layout": "circular", "encoding": {"color": {"field": "solution", "type": "nominal"}, "x": {"field": "solution", "type": "nominal"}, "opacity": {"field": "present_in_a_solution", "type": "nominal"}, "y": {"field": "solution_of_interest", "type": "nominal"}}}]}}}}, "marks": ["point", "geoshape", "bar"], "channels": ["x", "y", "color", "opacity"], "dataTypes": ["quantitative", "nominal"], "compositions": ["nested", "layer"], "aggregates": [], "actionTargets": ["query-identify:Attributes-distribution"], "figId": "vis-2821_00", "figFile": "vis-2821_00.png", "figCaption": "", "figBox": {"x": 0.7727910763696855, "y": 0.03212158057455881, "width": 0.21110435845567027, "height": 0.5177786744173061}, "figVis": ["glyph_based"], "relationText": "R.5 Solution comparison ", "note": "(Pos, Pos, [(Pos, Pos), Solution])"}, {"viewId": "vis-2821_00_4", "viewFile": "vis-2821_00_4.png", "specification": {"facet": {"column": {"field": "feature", "type": "nominal"}, "row": {"field": "solution", "type": "nominal"}}, "spec": {"condition": {"test": "dimensionality reductionill down for details", "value": {"mark": "boxplot", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}}}, "mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}}}}}, "marks": ["bar", "boxplot"], "channels": ["x"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-identify:Attributes-extremes", "query-compare:Attributes-values"], "figId": "vis-2821_00", "figFile": "vis-2821_00.png", "figCaption": "", "figBox": {"x": 0.5352396296050296, "y": 0.5746283077751859, "width": 0.44561268884728067, "height": 0.30223034687576805}, "figVis": ["box_plot", "bar_chart"], "relationText": "Users need a flexible ranking tool to help them quickly identify good solutions they desire (R7).\n\nThe system should enable users and customers to freely adjust each attribute weight because they may have different opinions on the performance indicators.\n\nTo support location-level comparison, we embed boxplots [4] into the matrix.", "note": "(row, column, [(bar value) OR (derived value of boxplot)])"}, {"viewId": "vis-2822_00_0", "viewFile": "vis-2822_00_0.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"position": 1, "facet": {"row": {"field": "time", "type": "temporal"}}, "spec": {"facet": {"row": {"field": "user_or_thread", "type": "nominal"}, "color": {"field": "user_or_thread", "type": "nominal"}}, "spec": {"mark": "boxplot", "encoding": {"x": {"field": "temporal_distribution", "remark": "the temporal distributions of activities of the new users and threads in that time step", "type": "temporal"}}}}}, {"mark": "area", "position": 2, "encoding": {"x": {"field": "volume_of_topic", "type": "quantitative"}, "y": {"field": "time", "type": "temporal"}, "color": {"field": "topic", "type": "nominal"}}}, {"mark": "bar", "position": 5, "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"aggregate": "count", "type": "nominal"}, "color": {"field": "user_or_thread", "type": "nominal"}, "xoffset": {"field": "user_or_thread", "type": "nominal"}, "opacity": {"field": "status_user_or_thread", "type": "nominal"}}}]}, "marks": ["boxplot", "area", "bar"], "channels": ["x", "y", "color", "xoffset", "opacity"], "dataTypes": ["temporal", "nominal"], "compositions": ["concat", "facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-2822_00", "figFile": "vis-2822_00.png", "figCaption": "", "figBox": {"x": 0.007366866212092459, "y": 0.1550555074375179, "width": 0.25931908362295647, "height": 0.4881737811302679}, "figVis": ["box_plot", "bar_chart", "flow_diagram"], "relationText": "{volumes of different types users and threads (i.e., new, active and inactive items)}\n\nFor each time step (one week in this example) along the y-axis,two box-and-whisker diagrams, where orange indicates threads and purple indicates users, depict the temporal distributions of activities of the new users and threads in that time step.\n\nThey can align the boxplots to the left to compare them in a relative time manner", "note": "(horizontal time attribute, [(vertical time attributes of boxplot, categories of the boxplot), (categories of the bar)])\nThe boxplots and bar chart share the horizontal axis.\nA data column of the horizontal timeline is transformed to be a boxplot by overlaying raw data points and computing quintiles. Similarly, the column is transformed to the bars by bin count. Therefore, we denote this data column as T#."}, {"viewId": "vis-2822_00_1", "viewFile": "vis-2822_00_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "user_group", "type": "nominal"}, "y": {"field": "post", "type": "nominal", "aggregate": "count"}}}, {"layer": [{"mark": "surface", "encoding": {"x": {"field": "user_group", "type": "nominal"}, "y": {"field": "time", "type": "temporal"}, "surface": {"field": "user", "type": "nominal", "aggregate": "count"}}}, {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "user_group", "type": "nominal"}, "y": {"field": "time", "type": "temporal"}, "size": {"field": "post", "type": "nominal", "aggregate": "count"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"mark": "arc", "encoding": {"theta": {"field": "post", "type": "nominal", "aggregate": "count"}, "color": {"field": "topic", "type": "nominal"}}}}}}, {"mark": "graph", "encoding": {"node": {"field": "user_group_at_time", "type": "node"}, "link": {"field": "in_one_thread", "type": "relation"}}}]}]}, "marks": ["bar", "surface", "point", "arc", "graph"], "channels": ["x", "y", "surface", "size", "theta", "color", "node", "link"], "dataTypes": ["nominal", "node", "relation"], "compositions": ["concat", "layer", "nested"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-clusters", "query-compare:Attributes-correlation", "consume-present:Attributes-distribution"], "figId": "vis-2822_00", "figFile": "vis-2822_00.png", "figCaption": "", "figBox": {"x": 0.272320185597709, "y": 0.15337311219268923, "width": 0.39555470979968893, "height": 0.48593537150895966}, "figVis": ["heatmap", "matrix", "pie_chart", "graph", "bar_chart"], "relationText": "To unfold the temporal dynamics of the whole forum in different user groups (R2), we develop the Matrix View that includes a matrix diagram and a bar chart on top to reveal information at the mesoscopic level (Figure1(b)).  \n\nA summary of user distribution is further indicated as a bar chart on top of the matrix, where the height of the bar maps to the total user volume in each group. \n\nThree different interaction techniques, sorting, aggregation, and filtering, are integrated with the matrix diagram to help the analyze transit from the mesoscopic exploration to the microscopic level\n\nR2", "note": "(matrix columns, [(matrix rows, [(pie value, pie categories), pie size, pie relation]), (histogram)])\nPlease note that the matrix columns are shared by the matrix and the histogram, so we use the \"[]\" to denote their relation."}, {"viewId": "vis-2822_00_2", "viewFile": "vis-2822_00_2.png", "specification": {"mark": "graph", "layout": "circle packing", "encoding": {"node": {"field": "user", "type": "node", "size": {"field": "activeness", "type": "quantitative"}, "color": {"field": "attribute", "remark": "e.g., grade", "type": "nominal"}}, "link": {"field": "social_connection", "type": "relation"}}}, "marks": ["graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["search-explore:Graphs-graphs", "search-explore:Attributes-correlation"], "figId": "vis-2822_00", "figFile": "vis-2822_00.png", "figCaption": "", "figBox": {"x": 0.6718190302517335, "y": 0.1188044285255644, "width": 0.3127921219073847, "height": 0.5382631385103194}, "figVis": ["graph"], "relationText": "The Social Network View serves the microscopic exploration of data from the user perspective (Figure1(d)), revealing the social dynamics of users in MOOC forums (R4)", "note": ""}, {"viewId": "vis-2822_00_3", "viewFile": "vis-2822_00_3.png", "specification": {"facet": {"field": "thread", "type": "nominal"}, "spec": {"mark": "graph", "layout": "timeline", "encoding": {"node": {"field": "posts", "type": "node", "x": {"field": "time", "type": "temporal"}, "color": {"field": "grade", "type": "quantitative"}, "length": {"field": "post", "aggregate": "count", "type": "quantitative"}}, "link": {"field": "post_relation", "remark": "hierarchical structure of a conversational thread and its chronological sequence of messages", "type": "relation"}}}}, "marks": ["graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["search-explore:Graphs-graphs"], "figId": "vis-2822_00", "figFile": "vis-2822_00.png", "figCaption": "", "figBox": {"x": 0.0056955223311016745, "y": 0.6627729107897841, "width": 0.6616358237906556, "height": 0.3273074440281284}, "figVis": ["graph"], "relationText": "After the analyst identifies points of interests by interacting with the\nOverview and the Matrix View, she can shift the exploration focus to\nthe microscopic level with the Thread View (Figure 1(c)). This view displays detailed information of all selected threads, initiated by the focusing cells in the Matrix View\nvarious sorting strategies are embedded to enable the analyst to organize threads with specific criteria", "note": "(Time, Grade Value, relations)"}, {"viewId": "vis-2824_00_0", "viewFile": "vis-2824_00_0.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"position": 1, "nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "tsne_x", "type": "quantitative"}, "y": {"field": "tsne_y", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"mark": "bar", "layout": "circular", "encoding": {"x": {"field": "feature", "type": "nominal"}, "y": {"field": "feature_value", "type": "quantitative"}, "color": {"field": "feature", "type": "nominal"}}}}}}, {"mark": "area", "position": 4, "encoding": {"x": {"field": "tsne_x", "type": "quantitative"}, "y": {"field": "feature_value", "type": "quantitative"}}}, {"mark": "line", "position": 5, "encoding": {"x": {"field": "tsne_x", "type": "quantitative"}, "y": {"field": "feature_value", "type": "quantitative"}}}]}, "marks": ["point", "bar", "area", "line"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "nested"], "aggregates": [], "actionTargets": ["search-explore:Attributes-values"], "figId": "vis-2824_00", "figFile": "vis-2824_00.png", "figCaption": "", "figBox": {"x": 0.18026402107985992, "y": 0.03462625237676689, "width": 0.5365456729376097, "height": 0.943354695496135}, "figVis": ["scatterplot", "area_chart", "sector_chart"], "relationText": "In the scatterplot, the user can view data items in the two-dimensional plane, wherein each point is plotted according to the two axes.\n\nInitially, the scatterplot shows similarities of data using t-distributed stochastic neighbor embedding (t-SNE).\n\nWith freeform line (Fig. 3(c)), the user can dimensionality reductionaw a free-form curve on the scatterplot by simply clicking and dimensionality reductionagging. As the user clicks and dimensionality reductionags across the scatterplot, the system collects coordinates of the user\u2019s click path.", "note": "[(y-axis, flow width, categories),(x pos, y pos, (sector values,categories)),(x-axis, flow width, categories)]"}, {"viewId": "vis-2824_00_1", "viewFile": "vis-2824_00_1.png", "specification": {"mark": "bar", "layout": "circular", "encoding": {"x": {"field": "feature", "type": "nominal"}, "y": {"field": "feature_value", "type": "quantitative"}, "color": {"field": "feature", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2824_00", "figFile": "vis-2824_00.png", "figCaption": "", "figBox": {"x": 0.7318341751823365, "y": 0.5077504618273595, "width": 0.23324473901447376, "height": 0.4313542851946426}, "figVis": ["sector_chart"], "relationText": "The user can show details of a group of data points by selecting them in the Main View", "note": ""}, {"viewId": "vis-2825_00_0", "viewFile": "vis-2825_00_0.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "segment", "aggregate": "count", "type": "quantitative"}, "y": {"field": "segment", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2825_00", "figFile": "vis-2825_00.png", "figCaption": "", "figBox": {"x": 0.13554276402414117, "y": 0.10564779485753382, "width": 0.0907564196039311, "height": 0.876954812032612}, "figVis": ["bar_chart"], "relationText": "The split panel displays data distribution across segments created by the split operation.\n\nTo create segments, the user can dimensionality reductionag-and-dimensionality reductionop a field from the fields panel onto the split panel, where each segment corresponding value of the selected field is represented by a horizontal bar. ", "note": ""}, {"viewId": "vis-2825_00_1", "viewFile": "vis-2825_00_1.png", "specification": {"facet": {"column": {"field": "segment", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"concat": {"layout": "horizontal"}, "spec": [{"mark": "text", "encoding": {"color": {"field": "relevance", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "segment", "aggregate": "count", "type": "quantitative"}}}]}, {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "value", "type": "ordinal"}, "y": {"field": "value", "aggregate": "count", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "value", "type": "ordinal"}, "y": {"field": "value_proportion", "type": "quantitative"}}}]}, {"layer": [{"mark": "geoshape"}, {"mark": "point", "encoding": {"x": {"field": "geo_x", "type": "quantitative"}, "y": {"field": "geo_y", "type": "quantitative"}, "size": {"field": "field_value", "aggregate": "count", "type": "quantitative"}, "color": {"field": "field_value_proportion", "type": "quantitative"}}}]}]}}, "marks": ["text", "bar", "geoshape", "point"], "channels": ["color", "x", "y", "size"], "dataTypes": ["quantitative"], "compositions": ["facet", "concat", "layer"], "aggregates": ["count"], "actionTargets": ["query-summarize:Attributes-values", "query-compare:Attributes-distribution"], "figId": "vis-2825_00", "figFile": "vis-2825_00.png", "figCaption": "", "figBox": {"x": 0.2304220409079658, "y": 0.09528917941273113, "width": 0.7561438847014301, "height": 0.8822632426170652}, "figVis": ["map", "bar_chart"], "relationText": "The summarize panel allows the user to generate visual summaries\nof selected fields and compare them across segments.", "note": "(segment categories, [(latitude, longitude, value on map), [count,proportion], (texts)])"}, {"viewId": "vis-2827_05_0", "viewFile": "vis-2827_05_0.png", "specification": {"facet": {"row": {"field": "subject", "type": "nominal"}, "color": {"field": "subject", "type": "nominal"}}, "spec": {"layer": [{"mark": "line", "remark": "the current subject", "encoding": {"x": {"field": "visit", "type": "ordinal"}, "y": {"field": "measurement", "type": "quantitative"}}}, {"mark": "point", "remark": "all subject", "encoding": {"x": {"field": "visit", "type": "ordinal"}, "y": {"field": "feature_value", "type": "quantitative"}}}]}}, "marks": ["line", "point"], "channels": ["x", "y"], "dataTypes": ["ordinal", "quantitative"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-correlation"], "figId": "vis-2827_05", "figFile": "vis-2827_05.png", "figCaption": "", "figBox": {"x": 0.08741714630800825, "y": 0.10952194858368668, "width": 0.1560816418551136, "height": 0.4041408953703111}, "figVis": ["scatterplot"], "relationText": "An overall progression trend for the patient based on measurement metrics (volume,length, width, and thickness)\n\nRQ1\n\nIn order to enable fast comparison of the trend of one subject with respect to others, this\nchart shows distribution of measurements across the population (grey empty markers).", "note": ""}, {"viewId": "vis-2827_05_1", "viewFile": "vis-2827_05_1.png", "specification": {"facet": {"row": {"field": "patient", "type": "nominal"}}, "spec": {"mark": "rect", "encoding": {"y": {"field": "visit", "type": "ordinal"}, "x": {"field": "feature", "type": "nominal"}, "color": {"field": "feature_value", "type": "quantitative"}}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["ordinal", "nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2827_05", "figFile": "vis-2827_05.png", "figCaption": "", "figBox": {"x": 0.47272707743298614, "y": 0.11221632290943186, "width": 0.23582477914431263, "height": 0.3889465465246346}, "figVis": ["heatmap"], "relationText": "a heatmap-style visualization of feature progression over time", "note": "(vertical split 1, (sequence item index, vertical split 2, value))"}, {"viewId": "vis-2827_05_2", "viewFile": "vis-2827_05_2.png", "specification": {"facet": {"column": {"field": "feature", "type": "nominal"}, "row": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "unit", "encoding": {"x": {"field": "feature_value", "bin": true, "type": "quantitative"}, "unit": {"field": "subject", "type": "node"}, "color": {"remark": "rectangles can be colored using one of the color schemes: individually for each subject, disease status, gender, or age"}}}}, "marks": ["unit"], "channels": ["x", "unit", "color"], "dataTypes": ["quantitative", "node"], "compositions": ["facet"], "aggregates": ["bin"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2827_05", "figFile": "vis-2827_05.png", "figCaption": "", "figBox": {"x": 0.013620578183198786, "y": 0.5589112171785295, "width": 0.779943977459027, "height": 0.4186839762677277}, "figVis": ["unit_visualization", "bar_chart"], "relationText": "Feature Distribution Overview (FDO)- a visualization of several groups of quantitative imaging features via familiar information visualization plots with interactive capabilities as per RQ4.", "note": "(histogram id, (histogram data column))\nThe bin width and item height in each histogram is computed based on the Freedman-Diaconis rule."}, {"viewId": "vis-2827_05_3", "viewFile": "vis-2827_05_3.png", "specification": {"facet": {"row": {"field": "feature", "type": "nominal"}}, "spec": {"condition_1": {"test": "feature data type is nominal", "value": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "condition_2": {"test": "feature data type is quantitative", "value": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "bin": true, "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": ["count", "bin"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2827_05", "figFile": "vis-2827_05.png", "figCaption": "", "figBox": {"x": 0.7921524327907064, "y": 0.5526957225765963, "width": 0.1680027105612703, "height": 0.4227101653051464}, "figVis": ["bar_chart"], "relationText": "The demographics overview consists of a bar chart visualization showing the distribution of gender, age, and disease status (sick or healthy) in the population. \nThrough interactions with this view, the user can filter which sets are shown and analyzed.", "note": "Demographics Overview (DO) - an overview of basic demographic information (age, gender, and disease types)."}, {"viewId": "vis-2828_00_0", "viewFile": "vis-2828_00_0.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"condition_1": {"test": "node_left", "value": {"field": "confirmed_group", "type": "nominal"}}, "condition_2": {"test": "node_right", "value": {"field": "ambiguous_group", "type": "nominal"}}, "condition_3": {"test": "node_middle", "value": {"field": "the_same_group", "type": "nominal"}}}, "link": {"field": "the_same_group", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"condition_1": {"test": "node_left", "value": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "unit", "encoding": {"unit": {"field": "paper", "type": "node", "sort": "allocation_likelihoods"}, "color": {"field": "allocation_likelihoods", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "paper", "type": "nominal", "aggregate": "count"}}}]}}, "condition_2": {"test": "node_middle", "value": {"mark": "venn", "encoding": {"set": {"field": "element-to-group", "type": "relation"}}}}, "condition_3": {"test": "node_right", "value": {"mark": "unit", "encoding": {"unit": {"field": "author", "type": "node"}, "color": {"field": "ambiguous_author", "type": "nominal"}}}}}}}}, "marks": ["graph", "unit", "line", "venn"], "channels": ["node", "link", "unit", "color", "x", "y", "set"], "dataTypes": ["node", "relation", "quantitative", "temporal", "nominal"], "compositions": ["nested", "concat"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2828_00", "figFile": "vis-2828_00.png", "figCaption": "", "figBox": {"x": 0.02298951538549121, "y": 0.05136158696346813, "width": 0.566480380050304, "height": 0.9322968267665861}, "figVis": ["graph"], "relationText": "The relation view presents the many-to-many comparisons between confirmed and ambiguous authors.", "note": "(overall links, [(a1 categories, [(a1 density bar), (a1 temporal distribution)]), (a2 temporal axis, [(a2 bottom vertical splits, [(point categories, point values) OR (C bar split 1, C bar split 2 items)]), (line chart value)]),(a3 categories, a3 items)])"}, {"viewId": "vis-2828_00_1", "viewFile": "vis-2828_00_1.png", "specification": {"nested": {"parent": {"mark": "unit", "encoding": {"unit": {"field": "paper", "type": "node"}, "x": {"field": "time", "type": "temporal"}}}, "child": {"child_type": "configured", "canvas": "unit", "configuration": {"mark": "unit", "encoding": {"unit": {"field": "paper", "type": "node"}, "color": {"field": "the_same_author_or_venue", "type": "nominal"}}}}}}, "marks": ["unit"], "channels": ["unit", "x", "color"], "dataTypes": ["node", "temporal", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-2828_00", "figFile": "vis-2828_00.png", "figCaption": "", "figBox": {"x": 0.181653712137198, "y": 0.2406167850365374, "width": 0.2362112638853858, "height": 0.09272134441411607}, "figVis": ["bar_chart", "unit_visualization"], "relationText": "{paper item}\n\nTherefore, we support every comparison link with a temporal view by showing detailed temporal distributions of the confirmed papers", "note": "(Temporal, (vertical splits, paper item column))"}, {"viewId": "vis-2828_00_2", "viewFile": "vis-2828_00_2.png", "specification": {"layer": [{"mark": "arc", "layout": "donut", "encoding": {"theta": {"field": "ambiguous_paper", "aggregate": "count", "type": "quantitative"}, "color": {"field": "confidence", "type": "quantitative"}}}, {"mark": "arc", "layout": "donut", "encoding": {"theta": {"field": "confirmed_paper", "aggregate": "count", "type": "quantitative"}, "color": {"field": "confidence", "type": "quantitative"}}}, {"mark": "graph", "encoding": {"node": {"field": "paper", "type": "node", "color": {"field": "time", "type": "temporal"}}, "link": {"field": "has_co_author", "type": "relation"}}}]}, "marks": ["arc", "graph"], "channels": ["theta", "color", "node", "link"], "dataTypes": ["quantitative", "node", "relation"], "compositions": ["layer"], "aggregates": ["count"], "actionTargets": ["query-identify:Attributes-values"], "figId": "vis-2828_00", "figFile": "vis-2828_00.png", "figCaption": "", "figBox": {"x": 0.6739807818760316, "y": 0.06591543773024701, "width": 0.2752363959992946, "height": 0.5669971185752002}, "figVis": ["graph", "donut_chart"], "relationText": "To cover this shortage, we further design a group view\nto \u201cverify the persons\u201d, thus facilitating the evaluation of whether all the researchers with the same name have been thoroughly classified", "note": ""}, {"viewId": "vis-2832_00_0", "viewFile": "vis-2832_00_0.png", "specification": {"mark": "sunburst", "encoding": {"node": {"field": "node", "type": "node", "encoding": {"color": {"field": "metric", "type": "quantitative", "remark": "Darker colors indicate stronger metrics"}, "width": {"field": "count", "type": "quantitative", "remark": "The width of segments communicates the number of leaf nodes, with each leaf having equal weight, and all charts are sorted identically to support comparisons."}}}, "link": {"field": "global pattern hierarchy", "type": "relation"}}}, "marks": ["sunburst"], "channels": ["node", "link", "color", "width"], "dataTypes": ["node", "relation", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2832_00", "figFile": "vis-2832_00.png", "figCaption": "", "figBox": {"x": 0.010620445924254904, "y": 0.27317626145587115, "width": 0.26257970982678897, "height": 0.7068140377492605}, "figVis": ["sunburst_icicle"], "relationText": "{a specific metric (e.g., frequency, similarity, entropy, outliers), weighted by the diagnostic significance score}\nIn addition to locate, the summary charts also support lookup searches to starting points of potential interest. These use the principles of encode, aggregate, and navigate [3].", "note": "((name, color, size),relations)"}, {"viewId": "vis-2832_00_1", "viewFile": "vis-2832_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "point", "encoding": {"y": {"field": "phenotype", "type": "nominal"}, "x": {"field": "cohorts", "type": "nominal"}, "color": {"field": "type", "type": "nominal"}}}, {"mark": "bar", "encoding": {"y": {"field": "phenotype", "type": "nominal"}, "x": {"aggregate": "count"}, "color": {"field": "type", "type": "nominal"}}}]}, "marks": ["point", "bar"], "channels": ["y", "x", "color"], "dataTypes": ["nominal"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-2832_00", "figFile": "vis-2832_00.png", "figCaption": "", "figBox": {"x": 0.48523993237751656, "y": 0.012761014273629153, "width": 0.34097833327855936, "height": 0.9828965246405089}, "figVis": ["matrix"], "relationText": "The Detail Panel can be sorted across phenotypes and across patients to identify patterns in the observations plot. Phenotypes can be sorted alphabetically, by information content, by frequency, and by co- occurrence. Patients can be sorted by ID, dataset-specific patient attributes (e.g. age, severity, diagnostic test scores, treatments), frequency, and by co-occurrence. This supports the explore task using the encode and navigate principles", "note": "([(dot's x index, color), bin/count aggregation of the row], row names)\nThe matrix and bar chart share the same y-axis."}, {"viewId": "vis-2833_00_0", "viewFile": "vis-2833_00_0.png", "specification": {"facet": {"field": "group", "type": "nominal"}, "spec": {"mark": "point", "encoding": {"y": {"field": "pca_y", "type": "quantitative"}, "x": {"field": "pca_x", "type": "quantitative"}, "color": {"field": "group", "type": "nominal"}}}}, "marks": ["point"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-2833_00", "figFile": "vis-2833_00.png", "figCaption": "", "figBox": {"x": 0.013405223768527302, "y": 0.030941286875448847, "width": 0.17079623782950815, "height": 0.4554675557687262}, "figVis": ["scatterplot"], "relationText": "The results are then presented on a small multiple visualization where each cluster is represented by a multiple and a distinct color (taken from ColorBrewer [20], see Figure 1-a). The non-clustered (those not yet processed) are displayed within the first multiple.", "note": "small multiples of scatterplots, not scatterplot matrix"}, {"viewId": "vis-2833_00_1", "viewFile": "vis-2833_00_1.png", "specification": {"mark": "point", "encoding": {"y": {"field": "pca_y", "type": "quantitative"}, "x": {"field": "pca_x", "type": "quantitative"}}}, "marks": ["point"], "channels": ["y", "x"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-clusters"], "figId": "vis-2833_00", "figFile": "vis-2833_00.png", "figCaption": "", "figBox": {"x": 0.014000652389853818, "y": 0.49237743618507407, "width": 0.1743149524995966, "height": 0.4897695794152748}, "figVis": ["scatterplot"], "relationText": "on a plot showing principal component analysis (PCA) results", "note": ""}, {"viewId": "vis-2833_00_2", "viewFile": "vis-2833_00_2.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"layer": [{"mark": "geoshape"}, {"mark": "point", "encoding": {"longitude": {"field": "lon", "type": "quantitative"}, "latitude": {"field": "lat", "type": "quantitative"}, "color": {"field": "if_selected", "type": "nominal"}}}]}, {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "total_num_cc", "type": "quantitative", "bin": true}, "y": {"aggregate": "count"}, "color": {"field": "if_selected", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "max_eff_bank", "type": "quantitative", "bin": true}, "y": {"aggregate": "count"}, "color": {"field": "if_selected", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "bank_cc_max_limit_n", "type": "quantitative"}, "y": {"field": "mean_eff_n", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "job_fyp", "type": "quantitative", "bin": true}, "y": {"aggregate": "count"}, "color": {"field": "if_selected", "type": "nominal"}}}]}]}, "marks": ["geoshape", "point", "bar"], "channels": ["longitude", "latitude", "color", "x", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "layer"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2833_00", "figFile": "vis-2833_00.png", "figCaption": "", "figBox": {"x": 0.1833447138097516, "y": 0.022906967444881896, "width": 0.6374314478041455, "height": 0.9444355626762894}, "figVis": ["map", "scatterplot", "bar_chart"], "relationText": "In addition to these algorithms that often operate on the dimensions, there are also computational methods to estimate statistics from the data. For instance, our prototype has a view that dynamically computes difference statistics (Cohen\u2019s D [44]) between the selected and not-selected items (see Figure 1-c).", "note": "(q,q,c) for the map. "}, {"viewId": "vis-2836_00_0", "viewFile": "vis-2836_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "value", "type": "quantitative"}, "y": {"aggregate": "count"}, "color": {"field": "if_selected", "type": "nominal"}}}, {"nested": {"parent": {"mark": "line", "encoding": {"x": {"field": "feature space", "type": "nominal"}, "y": {"field": "value", "type": "quantitative"}, "color": {"field": "if_selected", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "axis", "configuration": {"mark": "boxplot", "encoding": {"y": {"field": "value", "type": "quantitative"}}}}}}]}, "marks": ["line", "boxplot"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "nested"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "query-summarize:Attributes-distribution"], "figId": "vis-2836_00", "figFile": "vis-2836_00.png", "figCaption": "", "figBox": {"x": 0.1296762586350732, "y": 0.018035644935479468, "width": 0.8675534904960955, "height": 0.965889621806082}, "figVis": ["line_chart", "parallel_coordinate"], "relationText": "visualizing distribution and change of each axis. (a) Each axis bar incorporating a heat map represents a feature. (b) The box plot of each bar shows the distribution of a feature. (c) The user can filter the range via cursors provided at each axis. (d) The current and previous probability density functions (PDFs) of a feature are visualized by orange, purple, and grey lines. (e) A window shows the value range of a feature after filtering. (f) The change of entropy and the current entropy are also indicated.\n\nWe hence modify the parallel coordinates to encode the feature distribution.\n\nSince comparing the box plot against the PDF may assist understanding, a 1D heat map is also provided to show the feature\u2019s PDF.\n\nThe user can set a constraint by filtering the feature\u2019s range using a cursor (Fig. 5 (c)), then the polylines whose feature values are out of range will fade out. \n\nMany other relations can also be applied (e.g., spurious correlation).", "note": "((line, box plot, pdf distribution),x-axis)"}, {"viewId": "vis-2839_03_0", "viewFile": "vis-2839_03_0.png", "specification": {"concat": "vertical", "spec": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "value", "type": "quantitative"}, "color": {"type": "nominal", "field": "time series type"}}}, {"facet": {"row": {"field": "time series id", "type": "nominal"}}, "spec": {"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "value", "type": "quantitative"}, "color": {"type": "nominal", "field": "time series type"}}}}]}, "marks": ["line", "area"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["concat", "facet"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation"], "figId": "vis-2839_03", "figFile": "vis-2839_03.png", "figCaption": "", "figBox": {"x": 0.5465838513764376, "y": 0.5206194412944306, "width": 0.44840593942845935, "height": 0.47021734314145675}, "figVis": ["area_chart", "line_chart"], "relationText": "The Timeline View (Figure 3-b) reveals the temporal structure of data and allows for data selections across time (navigate+select, Chunks). \n\nIn this way, a user can explore the time series without visual clutter, synchronized with the rows in the Grid View. ", "note": "line chart and area charts share the same color encoding and temporal axis."}, {"viewId": "vis-2839_03_1", "viewFile": "vis-2839_03_1.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "dataset", "type": "node", "encoding": {"color": {"field": "type", "type": "nominal"}, "radius": {"field": "size", "type": "quantitative"}}}, "link": {"field": "model_overview", "type": "relation"}}}, "marks": ["graph"], "channels": ["node", "link", "color", "radius"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["search-explore:Attributes-values"], "figId": "vis-2839_03", "figFile": "vis-2839_03.png", "figCaption": "", "figBox": {"x": 0.17307344984070128, "y": 0.03525453486833716, "width": 0.4702446907485784, "height": 0.48017424597687347}, "figVis": ["graph"], "relationText": "The Annotation Graph View (Figure 3-e) helps an analyst visualize and explore the annotation semantics that they continuously generate during exploratory data analysis.", "note": ""}, {"viewId": "vis-2842_00_0", "viewFile": "vis-2842_00_0.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "work stations", "type": "ordinal"}}}, {"mark": "point", "encoding": {"color": {"field": "fault codes", "type": "nominal"}, "x": {"field": "time", "type": "temporal"}, "y": {"field": "work stations", "type": "ordinal"}}}]}, "marks": ["line", "point"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "ordinal", "nominal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation", "consume-discover:Attributes-outliers"], "figId": "vis-2842_00", "figFile": "vis-2842_00.png", "figCaption": "", "figBox": {"x": 0.19153342732604384, "y": 0.10167469354873468, "width": 0.8061429228274942, "height": 0.8775291294251403}, "figVis": ["area_chart", "bar_chart", "line_chart"], "relationText": "Marey\u2019s graph allows us to use the familiar metaphor of transportation schedules to explain the visual encoding (R8). It shows multivariate information and supports the detection of when and on which station the delay occurs (R1). More importantly, a set of recurring visual patterns emerge from the visualization. Based on the visual patterns the operators can form hypothesis about the causes of the inefficiency (R2). Here we summarize the visual patterns for the users to quickly read high-level semantic information from the visualization. In this way, we are able to visualize a larger number of processes and still highlight the anomalies. The aggregated processes show the surrounding context for these abnormal processes for troubleshooting (R4).", "note": "T the first T for the date, which is shared by Marey's Graph and the top histograms.  T the second T for hhmm, because the value is aggregated along the date. O is for the y-axis. N is for color"}, {"viewId": "vis-2842_00_1", "viewFile": "vis-2842_00_1.png", "specification": {"facet": {"row": {"field": "station", "type": "nominal"}}, "spec": {"mark": "area", "encoding": {"x": {"type": "quantitative", "field": "cycle time"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "marks": ["area"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-values"], "figId": "vis-2842_00", "figFile": "vis-2842_00.png", "figCaption": "", "figBox": {"x": 0.011691061369889571, "y": 0.1149070443092702, "width": 0.1775423798127753, "height": 0.8765401265450072}, "figVis": ["matrix"], "relationText": "Supplementary views include small multiples of histograms (D) showing the distribution of the cycle times on each station and a map (E) showing the assembly line schema", "note": "Q# is for distribution. O represents the ordinal indexes of the distributions. G represents the links between the distributions."}, {"viewId": "vis-2842_00_2", "viewFile": "vis-2842_00_2.png", "specification": {"mark": "calendar", "encoding": {"x": {"field": "month", "type": "temporal"}, "unit": {"field": "day", "type": "node"}, "color": {"field": "number of products", "type": "quantitative"}}}, "marks": ["calendar"], "channels": ["x", "unit", "color"], "dataTypes": ["temporal", "node", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2842_00", "figFile": "vis-2842_00.png", "figCaption": "", "figBox": {"x": 0.17730618922465133, "y": 0.0030803526397163872, "width": 0.5886201176063238, "height": 0.09946113442797459}, "figVis": ["heatmap"], "relationText": "We choose the calendar based display as it aligns the weekdays and weekends for better cross comparison. The user can select a continuous set of days on the calendar.", "note": "(T,T,T) represents (month, week, weekday)."}, {"viewId": "vis-2842_00_3", "viewFile": "vis-2842_00_3.png", "specification": {"mark": "bar", "layout": "circular", "encoding": {"x": {"field": "work station", "type": "nominal"}, "width": {"field": "duration", "type": "quantitative", "remark": "long it takes for a part to finish its process on a station"}, "y": {"field": "date", "type": "temporal"}, "color": {"field": "is ongoing", "type": "nominal", "remark": "Light blue color represents ongoing processes on a station"}}}, "marks": ["bar"], "channels": ["x", "width", "y", "color"], "dataTypes": ["nominal", "quantitative", "temporal"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2842_00", "figFile": "vis-2842_00.png", "figCaption": "", "figBox": {"x": 0.5737114352469942, "y": 0.41796009053119276, "width": 0.19940324949491925, "height": 0.2835789370989042}, "figVis": ["matrix"], "relationText": "{statuses of all the currently ongoing processes on the assembly line}", "note": "(O,Q,N) is for each each sector, O represents the order from inner to outer, Q represents the cell length, and N represents the cell color. The above is duplicated along the angle (different sectors), so an additional O is required.\n"}, {"viewId": "vis-2844_05_0", "viewFile": "vis-2844_05_0.png", "specification": {"remark": "a scatterplot matrix to see projected gaze data on scatterplots for all variable pairs", "facet": {"row": {"field": "variable 1", "type": "nominal"}, "column": {"field": "variable 2", "type": "nominal"}}, "spec": {"mark": "point", "encoding": {"x": {"field": "proj_x", "type": "quantitative"}, "y": {"field": "proj_y", "type": "quantitative"}}}}, "marks": ["point"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2844_05", "figFile": "vis-2844_05.png", "figCaption": "", "figBox": {"x": 0.204014515003813, "y": 0.18780978947051802, "width": 0.1810595782094289, "height": 0.2981478284786417}, "figVis": ["scatterplot", "matrix"], "relationText": "However, one can easily perceive overall gaze patterns with a scatterplot matrix, and then click on a specific cell (Fig. 5A) to see the corresponding scatterplot in the aforementioned CIS for analysis on gaze points of interests, as described in section 4.3.", "note": "scatterplot matrix"}, {"viewId": "vis-2844_05_1", "viewFile": "vis-2844_05_1.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"mark": "point", "position": 1, "encoding": {"x": {"field": "proj_x", "type": "quantitative"}, "y": {"field": "proj_y", "type": "quantitative"}, "color": {"field": "group", "type": "nominal"}}}, {"mark": "bar", "position": 2, "encoding": {"x": {"field": "proj_x", "type": "quantitative", "bin": true}, "y": {"aggregate": "count"}, "color": {"field": "group", "type": "nominal"}}}, {"mark": "bar", "position": 3, "encoding": {"y": {"field": "proj_y", "type": "quantitative", "bin": true}, "x": {"aggregate": "count"}, "color": {"field": "group", "type": "nominal"}}}]}, "marks": ["point", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-2844_05", "figFile": "vis-2844_05.png", "figCaption": "", "figBox": {"x": 0.20404801776117754, "y": 0.48449685185549773, "width": 0.19060828389086812, "height": 0.3237791357841657}, "figVis": ["scatterplot", "bar_chart"], "relationText": "CIS: context-embedded interactive scatter plot with gaze points grouped to five clusters.", "note": "(Q,Q) represents the scatterplot with clusters. Q# represents the cluster distribution on x/y axes. All graphics share the same color encoding for the clusters N."}, {"viewId": "vis-2844_05_2", "viewFile": "vis-2844_05_2.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"mark": "point", "position": 1, "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "index of gazed slice", "type": "nominal"}, "color": {"field": "group", "type": "nominal"}}}, {"mark": "bar", "position": 2, "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"aggregate": "count"}, "color": {"field": "group", "type": "nominal"}}}, {"mark": "bar", "position": 3, "encoding": {"y": {"field": "index of gazed slice", "type": "nominal", "bin": true}, "x": {"aggregate": "count"}, "color": {"field": "group", "type": "nominal"}}}]}, "marks": ["point", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "nominal"], "compositions": ["concat"], "aggregates": ["count", "bin"], "actionTargets": ["consume-discover:Attributes-correlation"], "figId": "vis-2844_05", "figFile": "vis-2844_05.png", "figCaption": "", "figBox": {"x": 0.20408521666011975, "y": 0.8287864231491404, "width": 0.18220026972297135, "height": 0.1521382918349327}, "figVis": ["scatterplot"], "relationText": "an interactive temporal chart (Fig. 5C) to examine the temporal aspect of gaze data", "note": "(Q,T) represents the scatterplot with clusters. T# represents the temporal distribution on the x-axis. Q# represents the temporal distribution on the y-axis. All graphics share the same color encoding for the clusters N."}, {"viewId": "vis-2845_00_0", "viewFile": "vis-2845_00_0.png", "specification": {"mark": "others", "encoding": {"vertical_scale": {"field": "average number of clicks"}, "size": {"field": "number of visitors transitioning between events"}}, "remark": "The vertical scale represents the average number of clicks taken by visitors to reach that event, and the size of the links represents the number of visitors transitioning between events."}, "marks": ["others"], "channels": ["vertical_scale", "size"], "dataTypes": [], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2845_00", "figFile": "vis-2845_00.png", "figCaption": "", "figBox": {"x": 0.09796613452541045, "y": 0.06966238477041113, "width": 0.4396199987285625, "height": 0.9195660189801775}, "figVis": ["others"], "relationText": "{average sequence length}\n\nWhen the number of patterns is still too large after pruning, users can filter patterns by pattern length and search for patterns containing a particular event.\n\nWe display the patterns from left to right, sorted by metrics such as support or pattern length.", "note": "(N, Q) for each cell. The cells have hierarchical relation, which is denoted as G.\nO for each column (sorted) "}, {"viewId": "vis-2845_00_1", "viewFile": "vis-2845_00_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "stream", "type": "nominal"}, "y": {"field": "metric", "type": "quantitative"}}}, {"mark": "unit", "encoding": {"x": {"field": "stream", "type": "nominal"}, "unit": {"field": "event sequence", "type": "node"}, "color": {"field": "category", "type": "nominal"}}}]}, "marks": ["bar", "unit"], "channels": ["x", "y", "unit", "color"], "dataTypes": ["nominal", "quantitative", "node"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2845_00", "figFile": "vis-2845_00.png", "figCaption": "", "figBox": {"x": 0.5297398612886156, "y": 0.06442857365477656, "width": 0.37602181439300664, "height": 0.9133905922816001}, "figVis": ["others"], "relationText": "{detailed sequence information for a selected sequential pattern}", "note": ""}, {"viewId": "vis-2846_03_0", "viewFile": "vis-2846_03_0.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "class", "type": "nominal"}, "y": {"field": "prediction_score", "type": "quantitative"}, "remark": "pcp"}}, {"facet": {"column": {"field": "class", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "class", "type": "nominal"}, "y": {"field": "proportion", "type": "quantitative"}, "color": {"field": "class", "type": "nominal"}}}, {"condition_1": {"test": "expanded to boxes for more details", "value": {"mark": "unit", "encoding": {"unit": {"field": "instance", "type": "node"}, "y": {"field": "prediction_score", "type": "quantitative", "bin": "true"}, "color": {"field": "class", "type": "nominal"}, "texture": {"field": "correctness", "type": "nominal"}}}}, "condition_2": {"test": "not expanded to boxes for details", "value": {"mark": "bar", "encoding": {"color": {"field": "class", "type": "nominal"}, "y": {"field": "prediction_score", "type": "quantitative", "bin": "true"}, "x": {"aggregate": "count", "type": "quantitative"}, "texture": {"field": "correctness", "type": "nominal"}}}}}]}}]}, "marks": ["line", "unit", "bar"], "channels": ["x", "y", "remark", "color", "unit", "texture"], "dataTypes": ["nominal", "quantitative", "node"], "compositions": ["layer", "facet", "concat"], "aggregates": ["bin", "count"], "actionTargets": ["produce:Attributes-values", "consume-present:Attributes-distribution"], "figId": "vis-2846_03", "figFile": "vis-2846_03.png", "figCaption": "", "figBox": {"x": 0.004761548708258931, "y": 0.05123718599576616, "width": 0.9872229023843461, "height": 0.9164802768547176}, "figVis": ["bar_chart", "line_chart", "unit_visualization", "parallel_coordinate"], "relationText": "{common performance metrics}\n\nDistributing boxes vertically by prediction score provides instance-level performance (G1).\n\nThe strips view serves as a trade-off between boxes and stacks by allowing for more\ninstances to be displayed than with the boxes view, and better granularity for instance selection than the stacks view.", "note": "[(Q#,N#),(Q,N),Q] for the histogram with units, the distribution on the top, and the y position of the line."}, {"viewId": "vis-2848_00_0", "viewFile": "vis-2848_00_0.png", "specification": {"mark": "line", "encoding": {"x": {"field": "fuction type", "type": "nominal"}, "y": {"field": "function value", "type": "quantitative"}, "color": {"field": "controlled value", "type": "quantitative"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-values"], "figId": "vis-2848_00", "figFile": "vis-2848_00.png", "figCaption": "", "figBox": {"x": 0.012205000806307315, "y": 0.01578817755415098, "width": 0.7466656034088818, "height": 0.5285975938470227}, "figVis": ["parallel_coordinate"], "relationText": "R1: Understanding Intra-Set Parameter Correlation. \nR2: Comparing Inter-Set Parameter Correlations. \n\nIntuitive high-dimensional range query (R3) and smooth view transition can be performed via simple interactions with the\nNPCP", "note": ""}, {"viewId": "vis-2848_00_1", "viewFile": "vis-2848_00_1.png", "specification": {"facet": {"column": {"field": "quality level", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "tree", "encoding": {"node": {"field": "ensemble member", "type": "node"}, "link": {"field": "cluster hierarchy", "type": "relation"}}}, {"mark": "rect", "encoding": {"x": {"field": "ensemble members", "type": "nominal"}, "y": {"field": "dimension", "type": "nominal"}, "lightness": {"field": "ensemble quality", "type": "quantitative"}}}]}}, "marks": ["tree", "rect"], "channels": ["node", "link", "x", "y", "lightness"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["produce:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-2848_00", "figFile": "vis-2848_00.png", "figCaption": "", "figBox": {"x": 0.021847859321340157, "y": 0.5583939427605091, "width": 0.7245254674888094, "height": 0.43799270159215015}, "figVis": ["heatmap", "matrix", "tree"], "relationText": "{Ensemble Member/Item Quality Evaluation}\n\nThe quality of ensemble sets is evaluated through comparing with the corresponding observation sets (R4)", "note": "Tree (G) and matrix (Q,N,N) are connected."}, {"viewId": "vis-2848_00_2", "viewFile": "vis-2848_00_2.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "point", "encoding": {"x": {"field": "coordinate_x", "type": "quantitative"}, "y": {"field": "coordinate_y", "type": "quantitative"}, "color": {"field": "mm/day", "type": "quantitative"}}}]}, "marks": ["geoshape", "point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-2848_00", "figFile": "vis-2848_00.png", "figCaption": "", "figBox": {"x": 0.7584370544530649, "y": 0.00931018637877769, "width": 0.15001169145097004, "height": 0.970134074800962}, "figVis": ["heatmap", "map"], "relationText": "R5: Ensemble Member Comparison.\nR6: Demonstrating Both Spatial and Temporal Facets of Ensembles. ", "note": ""}, {"viewId": "vis-2851_00_0", "viewFile": "vis-2851_00_0.png", "specification": {"nested": {"parent": {"mark": "area", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "number of people", "type": "quantitative", "stack": "normalize"}, "color": {"field": "academic position", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "area", "configuration": {"mark": "bar", "encoding": {"y": {"field": "academic position", "type": "nominal"}, "x": {"field": "timepoint", "type": "ordinal"}}}}}}, "marks": ["area", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2851_00", "figFile": "vis-2851_00.png", "figCaption": "", "figBox": {"x": 0.014656973523488713, "y": 0.06827568200018864, "width": 0.42598509548971447, "height": 0.3374066829035763}, "figVis": ["area_chart", "bar_chart"], "relationText": "R3 Facilitating the three levels of matching comparison.\n\nThe stacked graph view aims to support the comparison amongst multiple matchings (R3). ", "note": "((bar value, vertical split, horizontal split),split and merge relation)"}, {"viewId": "vis-2851_00_1", "viewFile": "vis-2851_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "arc", "encoding": {"theta": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "academic position", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "academic position", "type": "nominal"}, "color": {"field": "academic position", "type": "nominal"}, "size": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "y": {"field": "academic position", "type": "nominal"}}}]}, "marks": ["arc", "point", "bar"], "channels": ["theta", "color", "x", "y", "size"], "dataTypes": ["quantitative", "nominal", "ordinal"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["produce:Attributes-values", "consume-discover:Attributes-extremes"], "figId": "vis-2851_00", "figFile": "vis-2851_00.png", "figCaption": "", "figBox": {"x": 0.49556928845204606, "y": 0.051468033983470295, "width": 0.4877194076790363, "height": 0.21858226806357448}, "figVis": ["bar_chart", "donut_chart", "glyph_based", "scatterplot"], "relationText": "{welfare, fairness, and number of matched pairs}\n\nThis helps the user understand the number of agents in each group who get their best possible match, their second best match and so on (R4).", "note": ""}, {"viewId": "vis-2851_00_2", "viewFile": "vis-2851_00_2.png", "specification": {"mark": "point", "encoding": {"y": {"field": "welfare", "type": "quantitative"}, "x": {"field": "popularity", "type": "quantitative"}, "color": {"field": "academic position", "type": "nominal"}}}, "marks": ["point"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": [], "figId": "vis-2851_00", "figFile": "vis-2851_00.png", "figCaption": "", "figBox": {"x": 0.00934677134003836, "y": 0.5989798699209619, "width": 0.4761565079934683, "height": 0.4156504615814769}, "figVis": ["scatterplot"], "relationText": "R1 Revealing agents\u2019 popularity and their goodness of match for problem detection.", "note": ""}, {"viewId": "vis-2851_00_3", "viewFile": "vis-2851_00_3.png", "specification": {"mark": "point", "encoding": {"y": {"field": "professor", "type": "nominal"}, "x": {"field": "time", "type": "quantitative"}, "color": {"field": "match type", "type": "nominal"}}}, "marks": ["point"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-range", "query-compare:Attributes-values"], "figId": "vis-2851_00", "figFile": "vis-2851_00.png", "figCaption": "", "figBox": {"x": 0.5589061486990856, "y": 0.32124919079417597, "width": 0.4082664051091272, "height": 0.6373909236218951}, "figVis": ["glyph_based"], "relationText": "R2 Providing interaction techniques to enable direct assignment and range search.\n\nHence it provides the agent-level comparison of matching (R3).\n\nUpon identifying an agent with a poor match in the number line view, the user is enabled to improve it. The number line design provides an intuitive spatial metaphor for range search (R2)", "note": "(vertical splits,[(match sequence item,match sequence item value),word size,preference list items])"}, {"viewId": "vis-2854_00_0", "viewFile": "vis-2854_00_0.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"aggregate": "average", "field": "accuracy", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative"], "compositions": [], "aggregates": ["count", "average"], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2854_00", "figFile": "vis-2854_00.png", "figCaption": "", "figBox": {"x": 0.011206650823601718, "y": 0.04686499925742318, "width": 0.9743737477447562, "height": 0.05535653341292955}, "figVis": ["bar_chart"], "relationText": "{average of their accuracy}\n\nThis view not only provides an overview of all the datasets but can also be used to filter\nthe datasets to focus on a specific dataset, which in turn is shown in the main views.", "note": ""}, {"viewId": "vis-2854_00_1", "viewFile": "vis-2854_00_1.png", "specification": {"facet": {"column": {"field": "metric type", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "y": {"field": "crowd consensus value", "bin": true, "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": ["count", "bin"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2854_00", "figFile": "vis-2854_00.png", "figCaption": "", "figBox": {"x": 0.011121473854639663, "y": 0.3013475473218907, "width": 0.13017651346185438, "height": 0.13240967006794868}, "figVis": ["bar_chart"], "relationText": "Under the Overview tab, this view provides basic aggregated textual information about the selected dataset in our timeline filtering view (Fig. 1(A)), including an average of all information described in Table 1, and distributions for sensitivity and specificity. ", "note": ""}, {"viewId": "vis-2854_00_2", "viewFile": "vis-2854_00_2.png", "specification": {"mark": "word_cloud", "encoding": {"word": {"field": "word", "type": "nominal"}, "size": {"field": "frequency", "type": "quantitative"}, "color": {"field": "frequency", "type": "quantitative"}}}, "marks": ["word_cloud"], "channels": ["word", "size", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["search-locate:Attributes-outliers"], "figId": "vis-2854_00", "figFile": "vis-2854_00.png", "figCaption": "", "figBox": {"x": 0.004593751657283195, "y": 0.8179733717417564, "width": 0.15865828920282643, "height": 0.168540557089042}, "figVis": ["word_cloud"], "relationText": "In order to visualize these comments effectively, we opt for the Word Cloud technique, which can provide a keyword summary of these comments [34]. It helps clinical technicians detect anomaly video segments (T2), as shown in Figs. 1(G) and 9.", "note": "(x,y,size,text)"}, {"viewId": "vis-2854_00_3", "viewFile": "vis-2854_00_3.png", "specification": {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "dimention 1", "type": "quantitative"}, "y": {"field": "dimention 2", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"layer": [{"mark": "arc", "encoding": {"theta": {"field": "timing", "type": "ordinal"}}}, {"mark": "point", "encoding": {"color": {"field": "accuracy", "type": "quantitative"}}}]}}}}, "marks": ["point", "arc"], "channels": ["x", "y", "theta", "color"], "dataTypes": ["quantitative", "ordinal"], "compositions": ["nested", "layer"], "aggregates": [], "actionTargets": ["search-locate:Attributes-outliers", "produce:Attributes-values", "consume-discover:Attributes-clusters"], "figId": "vis-2854_00", "figFile": "vis-2854_00.png", "figCaption": "", "figBox": {"x": 0.17261701782275207, "y": 0.15555840030981694, "width": 0.21523432117449356, "height": 0.36776020188468034}, "figVis": ["scatterplot", "glyph_based"], "relationText": "{the number of true polyps detected or accuracy and the aggregated time to complete the task/video segment}\n\nOn the other hand, MDS ignores local neighborhood information whereas t-SNE takes into account both global and local information, thus showing better clustering results [28].\n\nT2. Anomaly detection. ", "note": ""}, {"viewId": "vis-2854_00_4", "viewFile": "vis-2854_00_4.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"mark": "rect", "position": 1, "encoding": {"x": {"field": "video segment", "type": "nominal"}, "y": {"field": "user", "type": "nominal"}, "color": {"field": "correctness", "type": "nominal"}}}, {"mark": "bar", "position": 2, "encoding": {"x": {"field": "video segment", "type": "nominal"}, "y": {"field": "accuracy", "type": "quantitative"}, "color": {"field": "poly/no poly/accumulated time", "type": "nominal"}}}, {"mark": "bar", "position": 5, "encoding": {"x": {"field": "accuracy", "type": "quantitative"}, "y": {"field": "user", "type": "nominal"}, "color": {"field": "poly/no poly/accumulated time", "type": "nominal"}}}]}, "marks": ["rect", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["produce:Attributes-order", "search-locate:Attributes-outliers"], "figId": "vis-2854_00", "figFile": "vis-2854_00.png", "figCaption": "", "figBox": {"x": 0.41323720615793574, "y": 0.1340897408613158, "width": 0.5642203816219092, "height": 0.726822494970043}, "figVis": ["bar_chart", "matrix"], "relationText": "T2. Anomaly detection.\n\nThe consensus map can order users by time, by number of polyps, by accuracy, and by the number of false negatives.", "note": "[(matrix cell value, matrix rows, matrix columns), (left rows,[ratio,green bar height, red or blue]),[top ratio,(top columns,[ratio,green bar height])]] "}, {"viewId": "vis-2854_00_5", "viewFile": "vis-2854_00_5.png", "specification": {"mark": "sankey", "encoding": {"node": {"field": "parameter", "type": "node", "encoding": {"y": {"field": "variable type", "type": "nominal"}}}, "link": {"field": "same parameter", "type": "relation", "encoding": {"width": {"aggregate": "count", "type": "quantitative"}}}}}, "marks": ["sankey"], "channels": ["node", "link", "y", "width"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2854_00", "figFile": "vis-2854_00.png", "figCaption": "", "figBox": {"x": 0.1668761338241017, "y": 0.558007366648329, "width": 0.22350313856375337, "height": 0.4175242547603752}, "figVis": ["parallel_coordinate"], "relationText": "In order to show the distributions as well as the relationships between these parameters\n(T1), we use the Parallel Sets technique [16].", "note": ""}, {"viewId": "vis-2856_00_0", "viewFile": "vis-2856_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "point", "encoding": {"x": {"field": "dimention1", "type": "quantitative"}, "y": {"field": "dimention2", "type": "quantitative"}, "color": {"field": "feature type", "type": "nominal"}}}, {"mark": "word_cloud", "encoding": {"word": {"field": "word", "type": "nominal"}, "size": {"field": "TF-IDF value", "type": "quantitative"}}}]}, "marks": ["point", "word_cloud"], "channels": ["x", "y", "color", "word", "size"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2856_00", "figFile": "vis-2856_00.png", "figCaption": "", "figBox": {"x": 0.2579003280520625, "y": 0.05895561198511551, "width": 0.14983720223464086, "height": 0.47895395178279454}, "figVis": ["scatterplot"], "relationText": "In one aspect, users can analyze people relationships, which are reflected by the distributions of participants in reposting each source weibo.", "note": ""}, {"viewId": "vis-2856_00_1", "viewFile": "vis-2856_00_1.png", "specification": {"layer": [{"mark": "others", "encoding": {"node": {"field": "one person or a group of people with similar behaviors"}, "color region with multiple nodes": {"field": "community"}, "highlighting orange stroke": {"field": "central user"}, "black stroke": {"field": "key players"}, "inner small hexagon": {"aggregate": "count", "field": "weibos these people have reposted"}}}, {"mark": "graph", "encoding": {"node": {"field": "weibo type", "type": "node"}, "link": {"field": "retweet", "type": "relation"}}}]}, "marks": ["others", "graph"], "channels": ["node", "color region with multiple nodes", "highlighting orange stroke", "black stroke", "inner small hexagon", "link"], "dataTypes": ["node", "relation"], "compositions": ["layer"], "aggregates": ["count"], "actionTargets": ["consume-discover:Attributes-clusters"], "figId": "vis-2856_00", "figFile": "vis-2856_00.png", "figCaption": "", "figBox": {"x": 0.4358619341657227, "y": 0.07688078424797615, "width": 0.3940647975359915, "height": 0.7203360043807532}, "figVis": ["others"], "relationText": "Each color region with multiple nodes indicates a community (Figure 4).", "note": "((time stamps,postings at each time stamp),reposting relations)"}, {"viewId": "vis-2856_00_2", "viewFile": "vis-2856_00_2.png", "specification": {"mark": "radar", "encoding": {"theta": {"field": "feature_type", "type": "nominal"}, "radius": {"field": "feature_value", "type": "quantitative"}, "color": {"field": "weibo_type", "type": "nominal"}}}, "marks": ["radar"], "channels": ["theta", "radius", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2856_00", "figFile": "vis-2856_00.png", "figCaption": "", "figBox": {"x": 0.2758197454072185, "y": 0.5434486224303771, "width": 0.11559309951953266, "height": 0.22015051108278824}, "figVis": ["polar_plot"], "relationText": "The radar visualization shows the distribution of each dimension of selected communities.\n\nMoreover, when users select multiple communities, features of communities can be compared interactively in the Community Radar View (Figure 11b).", "note": ""}, {"viewId": "vis-2856_00_3", "viewFile": "vis-2856_00_3.png", "specification": {"mark": "tree", "encoding": {"node": {"field": "weibo", "type": "node", "encoding": {"size": {"field": "retweet times", "type": "quantitative"}, "color": {"field": "weibo_type", "type": "nominal"}}}, "link": {"field": "retweet", "type": "relation"}}}, "marks": ["tree"], "channels": ["node", "link", "size", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2856_00", "figFile": "vis-2856_00.png", "figCaption": "", "figBox": {"x": 0.022665703119092565, "y": 0.5450729328231692, "width": 0.2386339279149426, "height": 0.45200540217029517}, "figVis": ["tree"], "relationText": "Also, the Hierarchical View aggregates the nodes of the same communities in the diffusion process, which helps users understand the position of a selected community in the hierarchical reposting tree (Figure 11c).", "note": "((node value,node type),tree relation)"}, {"viewId": "vis-2856_00_4", "viewFile": "vis-2856_00_4.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "time", "type": "nominal"}, "y": {"field": "behavior", "type": "nominal"}, "color": {"field": "weibo type", "type": "nominal"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2856_00", "figFile": "vis-2856_00.png", "figCaption": "", "figBox": {"x": 0.41097656097555446, "y": 0.8072819667204992, "width": 0.42841980129601454, "height": 0.19328273849869085}, "figVis": ["matrix"], "relationText": "It is likely to have concentrated community distribution of repostings inside the community with low entropy values.", "note": "(timestamp, the posts at that timestamp)"}, {"viewId": "vis-2856_00_5", "viewFile": "vis-2856_00_5.png", "specification": {"facet": {"row": {"field": "pattern index", "type": "ordinal"}}, "spec": {"layer": [{"mark": "others", "encoding": {"node": {"field": "one person or a group of people with similar behaviors"}, "color region with multiple nodes": {"field": "community"}, "highlighting orange stroke": {"field": "central user"}, "black stroke": {"field": "key players"}, "inner small hexagon": {"aggregate": "count", "field": "weibos these people have reposted"}}}, {"mark": "graph", "encoding": {"node": {"field": "weibo type", "type": "node"}, "link": {"field": "retweet", "type": "relation"}}}]}}, "marks": ["others", "graph"], "channels": ["node", "color region with multiple nodes", "highlighting orange stroke", "black stroke", "inner small hexagon", "link"], "dataTypes": ["node", "relation"], "compositions": ["facet", "layer"], "aggregates": ["count"], "actionTargets": ["produce:Attributes-order"], "figId": "vis-2856_00", "figFile": "vis-2856_00.png", "figCaption": "", "figBox": {"x": 0.8466392330901759, "y": 0.07413319998297874, "width": 0.13315051165501263, "height": 0.9134000949515741}, "figVis": ["graph"], "relationText": "In the Small Multiple View, key players are shown as rectangles in the order of influenced people number (Figure 1g). When we click the thumbnail, the corresponding D-Map would be shown in the main window.", "note": ""}, {"viewId": "vis-2857_00_0", "viewFile": "vis-2857_00_0.png", "specification": {"mark": "venn", "encoding": {"set": {"field": "idea-to-group", "type": "relation"}}}, "marks": ["venn"], "channels": ["set"], "dataTypes": ["relation"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-clusters"], "figId": "vis-2857_00", "figFile": "vis-2857_00.png", "figCaption": "", "figBox": {"x": 0.018363348314080097, "y": 0.08541519675693644, "width": 0.21109137896699506, "height": 0.5563669097797422}, "figVis": ["scatterplot", "contour_graph"], "relationText": "Thus we extract representative ideas for each cluster and display their keywords and global lead-lag relationships along with the high-level clusters. \n\nA user can select an idea cluster to zoom in or click the zoom out button (Fig. 1E) to return to high-level views.", "note": ""}, {"viewId": "vis-2857_00_1", "viewFile": "vis-2857_00_1.png", "specification": {"mark": "sankey", "encoding": {"node": {"field": "split point", "type": "node"}, "link": {"field": "transition", "type": "relation", "encoding": {"color": {"field": "idea_type", "type": "nominal"}}}}}, "marks": ["sankey"], "channels": ["node", "link", "color"], "dataTypes": ["node", "relation", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Graphs-links/paths"], "figId": "vis-2857_00", "figFile": "vis-2857_00.png", "figCaption": "", "figBox": {"x": 0.24380596627219348, "y": 0.06564468370072009, "width": 0.7276768868082373, "height": 0.6740345297846131}, "figVis": ["sankey_diagram"], "relationText": "R2.1 Tracking local lead-lag relationships within/across groups on a set of correlated ideas.\nR2.2 Exploring and comparing idea flows at different levels of detail (time, social group). ", "note": "The original data is (time, text,Rep or Dem). After counting and arranging by time, the flow can be formed."}, {"viewId": "vis-2857_00_2", "viewFile": "vis-2857_00_2.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "word_cloud", "encoding": {"word": {"field": "word", "type": "nominal"}, "size": {"field": "frequency", "type": "quantitative"}}}, {"mark": "word_cloud", "encoding": {"word": {"field": "user", "type": "nominal"}, "size": {"field": "frequency", "type": "quantitative"}}}]}, "marks": ["word_cloud"], "channels": ["word", "size"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["query-identify:Attributes-values"], "figId": "vis-2857_00", "figFile": "vis-2857_00.png", "figCaption": "", "figBox": {"x": 0.24123376093660778, "y": 0.7373490340311631, "width": 0.3689366466696634, "height": 0.25355552521955804}, "figVis": ["word_cloud"], "relationText": "{key content in the word and tweet panel}", "note": "(words, categories)"}, {"viewId": "vis-2858_00_0", "viewFile": "vis-2858_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "date", "type": "ordinal"}, "y": {"field": "attribute_type", "type": "nominal"}, "size": {"field": "times", "type": "quantitative"}, "color": {"field": "person percentage", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y", "size", "color"], "dataTypes": ["ordinal", "nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["search-lookup:Attributes-values"], "figId": "vis-2858_00", "figFile": "vis-2858_00.png", "figCaption": "", "figBox": {"x": 0.20075521284377432, "y": 0.08450806720851939, "width": 0.5409527273916379, "height": 0.3486746164260172}, "figVis": ["matrix"], "relationText": "retrieving a current student\u2019s record from the database.", "note": "(column, row, color, size)"}, {"viewId": "vis-2858_00_1", "viewFile": "vis-2858_00_1.png", "specification": {"mark": "bar", "encoding": {"y": {"field": "career", "type": "nominal"}, "x": {"field": "person percentage", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["y", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "query-compare:Attributes-values"], "figId": "vis-2858_00", "figFile": "vis-2858_00.png", "figCaption": "", "figBox": {"x": 0.7509674080557482, "y": 0.023912976207651863, "width": 0.2388313097310065, "height": 0.4148865420471674}, "figVis": ["bar_chart"], "relationText": "From this view, users can estimate: (1) the current student\u2019s most likely outcome, (2) the current student\u2019s probability of achieving the desired outcome, and (3) whether the current student is more or less likely to achieve the desired outcome compared to all archived students", "note": ""}, {"viewId": "vis-2858_00_2", "viewFile": "vis-2858_00_2.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "distance", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "career", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2858_00", "figFile": "vis-2858_00.png", "figCaption": "", "figBox": {"x": 0.007130629557689639, "y": 0.4900159562340984, "width": 0.18834573297029378, "height": 0.30735442770303933}, "figVis": ["bar_chart"], "relationText": "To find similar archived students, EventAction compares the event sequence patterns of the current student and each archived student.\n\nThen, EventAction computes a similarity score between the current student and each archived student and shows the results in the similarity distribution view (Fig. 3a).\n\nWe included a range selection widget to allow users to customize the set of archived students to be considered as the similar cohort.", "note": ""}, {"viewId": "vis-2858_00_3", "viewFile": "vis-2858_00_3.png", "specification": {"mark": "point", "encoding": {"x": {"field": "date", "type": "ordinal"}, "y": {"field": "attribute_type", "type": "nominal"}, "size": {"field": "times", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y", "size"], "dataTypes": ["ordinal", "nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": [], "figId": "vis-2858_00", "figFile": "vis-2858_00.png", "figCaption": "", "figBox": {"x": 0.19739438359682399, "y": 0.44269689868818735, "width": 0.5469974818041174, "height": 0.5556817594951312}, "figVis": ["matrix"], "relationText": "{archived students uses relative time}", "note": "The time axis of the current student (Fig. 1b) shows the exact date, while the time axis of the archived students uses relative time (Fig. 1f)."}, {"viewId": "vis-2858_00_4", "viewFile": "vis-2858_00_4.png", "specification": {"facet": {"row": {"field": "career", "type": "nominal"}, "column": {"field": "career", "type": "nominal"}}, "spec": {"layer": [{"mark": "line", "encoding": {"y": {"field": "person percentage", "type": "quantitative"}, "x": {"field": "times", "type": "quantitative"}}}, {"mark": "point", "encoding": {"y": {"field": "person percentage", "type": "quantitative"}, "x": {"field": "times", "type": "quantitative"}, "size": {"aggregate": "count", "type": "quantitative"}}}]}}, "marks": ["line", "point"], "channels": ["y", "x", "size"], "dataTypes": ["quantitative"], "compositions": ["facet", "layer"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2858_00", "figFile": "vis-2858_00.png", "figCaption": "", "figBox": {"x": 0.7555146450320335, "y": 0.48518866196242944, "width": 0.22770612353417352, "height": 0.5031853844442645}, "figVis": ["line_chart", "matrix"], "relationText": "correlation view", "note": "Line chart matrix with color encoding the correlation value of each cell."}, {"viewId": "vis-2860_00_0", "viewFile": "vis-2860_00_0.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "summarized subset", "type": "node"}, "link": {"field": "subset structure", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"condition_1": {"test": "categorical view", "value": {"mark": "bar", "encoding": {"x": {"field": "categorical x", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "condition_2": {"test": "numerical view", "value": {"mark": "line", "encoding": {"x": {"field": "numerical x", "type": "quantitative"}, "y": {"field": "numerical y", "type": "quantitative"}}}}, "condition_3": {"test": "time-related view", "value": {"mark": "calendar", "encoding": {"date": {"field": "time", "type": "temporal"}, "color": {"aggregate": "count", "type": "quantitative"}}}}, "condition_4": {"test": "2D view", "value": {"mark": "point", "encoding": {"x": {"field": "numerical x", "type": "quantitative"}, "y": {"field": "numerical y", "type": "quantitative"}}}}}, "remark": "Examples include bar charts for categorical views, line charts for numerical views, calendars for time-related views, and scatterplots for 2D views."}}}, "marks": ["graph", "bar", "line", "calendar", "point"], "channels": ["node", "link", "x", "y", "date", "color"], "dataTypes": ["node", "relation", "nominal", "quantitative", "temporal"], "compositions": ["nested"], "aggregates": ["count"], "actionTargets": ["consume-present:Graphs-topology/structures", "query-compare:Graphs-links/paths", "search-explore:Graphs-links/paths", "consume-present:Attributes-distribution"], "figId": "vis-2860_00", "figFile": "vis-2860_00.png", "figCaption": "", "figBox": {"x": 0.26852319832711147, "y": 0.09768189505769992, "width": 0.42325064902392273, "height": 0.8397195071456407}, "figVis": ["line_chart", "tree", "scatterplot", "matrix", "bar_chart"], "relationText": "{data values and the value counts}\n\nThe exploration component visualizes layouts of the structured categorization tree, and enables data analysts to interactively compare and explore data views and their relations\n\nTo avoid an overwhelming information display, we use a view thumbnail in place of a leaf node, whose shape indicates the overall distribution of the view.", "note": "(Graph layout, [thumbnail line chart OR thumbnail bar chart  OR thumbnail stacked graph])"}, {"viewId": "vis-2860_00_1", "viewFile": "vis-2860_00_1.png", "specification": {"mark": "rect", "encoding": {"y": {"field": "feature_name_1", "type": "nominal"}, "x": {"field": "feature_name_2", "type": "nominal"}, "color": {"field": "view_type", "type": "nominal", "remark": "white for regular views, black for hidden views and other colors for highlighted views"}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["nominal"], "compositions": [], "aggregates": [], "actionTargets": ["search-locate:Attributes-values"], "figId": "vis-2860_00", "figFile": "vis-2860_00.png", "figCaption": "", "figBox": {"x": 0.015368716166019251, "y": 0.4277606015647502, "width": 0.2283650641364111, "height": 0.4173488866785945}, "figVis": ["matrix"], "relationText": "The view selector widget allows analysts to select or deselect one or multiple views with pre-defined colors (Figure 6) by clicking the entries of the matrix.", "note": ""}, {"viewId": "vis-2860_00_2", "viewFile": "vis-2860_00_2.png", "specification": {"facet": {"row": {"field": "tree index", "type": "ordinal"}}, "spec": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "summarized subset", "type": "node"}, "link": {"field": "subset structure", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"condition_1": {"test": "categorical view", "value": {"mark": "bar", "encoding": {"x": {"field": "categorical x", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "condition_2": {"test": "numerical view", "value": {"mark": "line", "encoding": {"x": {"field": "numerical x", "type": "quantitative"}, "y": {"field": "numerical y", "type": "quantitative"}}}}, "condition_3": {"test": "time-related view", "value": {"mark": "calendar", "encoding": {"date": {"field": "time", "type": "temporal"}, "color": {"aggregate": "count", "type": "quantitative"}}}}, "condition_4": {"test": "2D view", "value": {"mark": "point", "encoding": {"x": {"field": "numerical x", "type": "quantitative"}, "y": {"field": "numerical y", "type": "quantitative"}}}}}, "remark": "Examples include bar charts for categorical views, line charts for numerical views, calendars for time-related views, and scatterplots for 2D views."}}}}, "marks": ["graph", "bar", "line", "calendar", "point"], "channels": ["node", "link", "x", "y", "date", "color"], "dataTypes": ["node", "relation", "nominal", "quantitative", "temporal"], "compositions": ["facet", "nested"], "aggregates": ["count"], "actionTargets": ["produce:Attributes-values"], "figId": "vis-2860_00", "figFile": "vis-2860_00.png", "figCaption": "", "figBox": {"x": 0.7711679690145965, "y": 0.0592117367293028, "width": 0.2166398995111472, "height": 0.9143446420598981}, "figVis": ["bar_chart", "graph", "line_chart", "scatterplot"], "relationText": "{analysts\u2019 observation}", "note": ""}, {"viewId": "vis-2863_00_0", "viewFile": "vis-2863_00_0.png", "specification": {"facet": {"row": {"field": "prediction type", "type": "nominal"}}, "spec": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}}}}, "marks": ["point"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-2863_00", "figFile": "vis-2863_00.png", "figCaption": "", "figBox": {"x": 0.03805777247501094, "y": 0.14633793124188224, "width": 0.15472811547417123, "height": 0.8131876732748216}, "figVis": ["scatterplot"], "relationText": "As shown in Fig. 1(a), the cluster view shows the clustering resultsof learner groups (T2).", "note": ""}, {"viewId": "vis-2863_00_1", "viewFile": "vis-2863_00_1.png", "specification": {"layer": [{"facet": {"row": {"field": "subgroup of learner", "type": "nominal"}, "remark": "each row represents a subgroup of learners\u2019 actions throughout the whole course period"}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"facet": {"column": {"field": "learner", "type": "nominal"}}, "spec": {"mark": "others", "encoding": {"outer_radius": {"aggregate": "average", "field": "number of videos watched", "type": "quantitative"}, "inner_radius": {"aggregate": "variance", "field": "number of videos watched", "type": "quantitative"}, "color": {"field": "action", "type": "nominal"}, "arc": {"field": "percentage", "aggregate": "average", "type": "quantitative"}, "arc2": {"field": "achieved scores each week", "aggregate": "stdev", "type": "quantitative"}, "complete_circle": {"field": "full mark or not", "type": "nominal"}, "small_circle_on_arc": {"field": "percentage", "aggregate": "average", "type": "quantitative"}, "short_lines": {"field": "percentage", "type": "quantitative", "aggregate": "stdev"}}, "remark": "Specifically, the outer radius of the donutchart indicates the average number of videos watched by subgroupof learners and the inner radius shows the corresponding standard deviation of the same subgroup. The arc around the donut chart shows the average percentage and its standard deviation of achieved scores in each week\u2019s assignments. A complete circle denotes a full mark while a small-angle arc indicatesthe average poor performance for the subgroup in that week. The small circle on the arc represents the average percentage and the two short lines denote the standard deviation."}, "remark": "Given that the horizontal line is the course timeline, each column corresponds to a consecutive week. "}, {"mark": "bar", "encoding": {"y": {"field": "learner", "type": "nominal"}, "x": {"aggregate": "count", "type": "quantitative"}}}]}}, {"mark": "graph", "encoding": {"node": {"field": "learner/time", "type": "node"}, "link": {"field": "correspondence", "type": "relation"}}}, {"mark": "bar", "encoding": {"y": {"field": "time", "type": "temporal"}, "x": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "return type", "type": "nominal"}}}]}, "marks": ["others", "bar", "graph"], "channels": ["outer_radius", "inner_radius", "color", "arc", "arc2", "complete_circle", "small_circle_on_arc", "short_lines", "y", "x", "node", "link"], "dataTypes": ["quantitative", "nominal", "node", "relation"], "compositions": ["layer", "facet", "concat"], "aggregates": ["average", "variance", "stdev", "count"], "actionTargets": ["consume-present:Attributes-order", "consume-discover:Attributes-extremes", "consume-discover:Attributes-correlation"], "figId": "vis-2863_00", "figFile": "vis-2863_00.png", "figCaption": "", "figBox": {"x": 0.19808279877515317, "y": 0.13185387834818668, "width": 0.5896240985554042, "height": 0.8104533500752649}, "figVis": ["glyph_based"], "relationText": "We have also ranked the subgroups based on the number of learners so that larger subgroups will be shown at the top of each general category.\n\nThe goal of the flow view is to allow users to correlate forum activities with the subgroup information(T4)", "note": "pattern->task?\n(vertical group splits, (y-axis, (x-axis, [(donut categories, donut value, inner radius, outer radius), (arc)])))"}, {"viewId": "vis-2863_00_2", "viewFile": "vis-2863_00_2.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "active/dimensionality reductionop", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}, "xoffset": {"field": "correct/wrong", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "xoffset"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2863_00", "figFile": "vis-2863_00.png", "figCaption": "", "figBox": {"x": 0.8096194787557964, "y": 0.10141968447073216, "width": 0.1559951684032319, "height": 0.18315212365873318}, "figVis": ["bar_chart"], "relationText": "The general distribution of the four categories is illustrated at the top of the dash-board view (T1).", "note": ""}, {"viewId": "vis-2866_00_0", "viewFile": "vis-2866_00_0.png", "specification": {"mark": "tick", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "user", "type": "nominal"}}}, "marks": ["tick"], "channels": ["x", "y"], "dataTypes": ["temporal", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-order"], "figId": "vis-2866_00", "figFile": "vis-2866_00.png", "figCaption": "", "figBox": {"x": 0.004663583704338058, "y": 0.04176660259972107, "width": 0.1223421541863269, "height": 0.26369398187327536}, "figVis": ["stripe_graph"], "relationText": "This visualization representsthe temporal order of selected activities with respect to all activities of a user.", "note": ""}, {"viewId": "vis-2866_00_1", "viewFile": "vis-2866_00_1.png", "specification": {"mark": "bar", "encoding": {"y": {"field": "code category", "type": "nominal"}, "x": {"field": "fraction of currently selected activities", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["y", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2866_00", "figFile": "vis-2866_00.png", "figCaption": "", "figBox": {"x": 0.0015515488498005388, "y": 0.3158166132902339, "width": 0.1254314561033269, "height": 0.34455317294793586}, "figVis": ["bar_chart"], "relationText": "Entering a text string into the search box selects those activities containing this string in the transcript and highlights it.\n\n{fractionof currently selected activities}", "note": ""}, {"viewId": "vis-2866_00_2", "viewFile": "vis-2866_00_2.png", "specification": {"facet": {"column": {"field": "activity", "type": "nominal"}}, "spec": {"condition_1": {"test": "if header is AOI-based Vis", "value": {"concat": {"layout": "vertical"}, "spec": [{"mark": "rect", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "activity type", "type": "nominal"}, "color": {"field": "AOI dwell times", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "activity type", "type": "nominal"}, "color": {"field": "interaction category", "type": "nominal"}}}]}}, "condition_2": {"test": "if header is point-based Vis", "value": {"concat": {"layout": "vertical"}, "spec": [{"encoding": {"x": {"field": "screen x", "type": "nominal"}, "y": {"field": "screen y", "type": "nominal"}, "color": {"aggregate": "count", "field": "eye tracking data", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"x": {"field": "screen x", "type": "nominal"}, "y": {"field": "screen y", "type": "nominal"}, "color": {"aggregate": "count", "field": "interaction", "type": "quantitative"}}}]}}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2866_00", "figFile": "vis-2866_00.png", "figCaption": "", "figBox": {"x": 0.13003500843037433, "y": 0.002657871059229228, "width": 0.6219935441875417, "height": 0.6352754217327693}, "figVis": ["heatmap"], "relationText": "These visualizations integrated into the activity table enable an analyst to code user activities without switching between multiple views or windows.  ", "note": "(activity category, (time, [(vertical rows, eye tracking data), (vertical rows, interaction data)]))"}, {"viewId": "vis-2866_00_3", "viewFile": "vis-2866_00_3.png", "specification": {"mark": "sankey", "encoding": {"node": {"field": "user/AOI/reading mode/interaction items", "type": "node"}, "link": {"field": "overlap of coded behavior patterns", "type": "relation", "width": {"field": "overlapping value", "type": "quantitative"}}}}, "marks": ["sankey"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["search-browse:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-2866_00", "figFile": "vis-2866_00.png", "figCaption": "", "figBox": {"x": 0.21646849920669728, "y": 0.6960413924928514, "width": 0.5357153236658472, "height": 0.2620908279693217}, "figVis": ["parallel_coordinate"], "relationText": "We extend browsing and analyzing individual activities using a ded-icated comparison view (Figure 1, D) to facilitate higher-level anal-ysis  of  assigned  codes", "note": "(item,dimension values)\nThe color is calculated by counting the number of the dimension value."}, {"viewId": "vis-2931_00_0", "viewFile": "vis-2931_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values", "consume-present:Attributes-clusters"], "figId": "vis-2931_00", "figFile": "vis-2931_00.png", "figCaption": "", "figBox": {"x": 0.13898088455250046, "y": 0.02193624976226343, "width": 0.4257128553283248, "height": 0.6857730951214694}, "figVis": ["scatterplot"], "relationText": "The t-SNE view (Fig. 1(c)) presents a 2D non-linear embedding of data points and usually performs well in visual clustering. The number of subspaces/manifolds is visually\npresented (T1). \n\nThe t-SNE view supports lasso-based selection which is linked with other views", "note": ""}, {"viewId": "vis-2931_00_1", "viewFile": "vis-2931_00_1.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-clusters", "query-identify:Attributes-distribution"], "figId": "vis-2931_00", "figFile": "vis-2931_00.png", "figCaption": "", "figBox": {"x": 0.5743791979080012, "y": 0.023292881471473507, "width": 0.41177036338599826, "height": 0.6788574316198255}, "figVis": ["scatterplot"], "relationText": "After selecting a subset of points in the t-SNE view or LTSD-GD view and clicking the\n\u201cRegenerate LTSD-GD view\u201d button, a new layout of the LTSD-GD view for selected points is generated. \n\nIf a low-dimensional structure is identified, the analyst can add it into the list of identified-structures (Fig. 1(b)). => Cluster\n\nT4. What are the distributions of subspaces/manifolds?", "note": "What is \"structure\"? distribution->T4"}, {"viewId": "vis-2931_00_2", "viewFile": "vis-2931_00_2.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "dimensionality", "type": "ordinal"}, "y": {"aggregate": "count", "type": "quantitative"}, "xoffset": {"field": "index", "type": "nominal"}, "color": {"field": "index", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "xoffset", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2931_00", "figFile": "vis-2931_00.png", "figCaption": "", "figBox": {"x": 0.0038726385271820474, "y": 0.755953544182608, "width": 0.25987330691092897, "height": 0.24180377923982832}, "figVis": ["bar_chart"], "relationText": "Then, the histogram of estimated local dimensionality (Fig. 1(e)) shows the statistics of\nthe local dimensionality. This view is connected to other views with bin-based selection. \n\nA bar chart is employed to visualize the distribution of estimated local dimensionality, which is estimated as mentioned in Section 3.3.", "note": ""}, {"viewId": "vis-2931_00_3", "viewFile": "vis-2931_00_3.png", "specification": {"mark": "line", "encoding": {"x": {"field": "Index", "type": "ordinal"}, "y": {"field": "singular values", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation", "consume-present:Attributes-order"], "figId": "vis-2931_00", "figFile": "vis-2931_00.png", "figCaption": "", "figBox": {"x": 0.27255907365651977, "y": 0.7241684220798711, "width": 0.35450062790150233, "height": 0.26607116998814007}, "figVis": ["parallel_coordinate"], "relationText": "{eigenvalues}\n\nThe scree plot of pointwise LTS (Fig. 1(f)) provides ordered eigenvalues of each LTS. \n\nThe trend of the eigenvalues is helpful to understand local intrinsic dimensionality. ", "note": ""}, {"viewId": "vis-2931_00_4", "viewFile": "vis-2931_00_4.png", "specification": {"mark": "line", "encoding": {"x": {"field": "Index", "type": "ordinal"}, "y": {"field": "singular values", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values", "consume-discover:Graphs-topology/structures", "query-compare:Graphs-topology/structures"], "figId": "vis-2931_00", "figFile": "vis-2931_00.png", "figCaption": "", "figBox": {"x": 0.6362011020355514, "y": 0.7284133214101856, "width": 0.36040103697642784, "height": 0.26738697152169816}, "figVis": ["parallel_coordinate"], "relationText": "Having a good understanding of the local dimensionality, the analyst can study the intrinsic dimensionality of structures in the scree plot of structures (Fig. 1(g)). In this view, eigenvalues from SVD decompositions of the structures are presented.\n\nThe analyst can study the dimensionality of structures by the gradient of lines, and infer whether a structure is linear or non-linear by comparing two modes. If a structure is non-linear, the non-linear mode indicates lower intrinsic dimensionality. Otherwise, two modes can lead to a similar dimensionality", "note": ""}, {"viewId": "vis-2933_00_0", "viewFile": "vis-2933_00_0.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "step", "type": "nominal"}, "y": {"field": "accuracy", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "step", "type": "nominal"}, "y": {"field": "error", "type": "quantitative"}}}], "resolve": {"scale": {"y": "independent"}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2933_00", "figFile": "vis-2933_00.png", "figCaption": "", "figBox": {"x": 0.09770920159932556, "y": 0.06603502876662842, "width": 0.8694054831090726, "height": 0.13531152795822735}, "figVis": ["line_chart"], "relationText": "The evolution of the loss- and accuracy-curve presented in the Training Overview, is the de-facto standard way to visualize the evolution ofthe network during training.: correlate", "note": ""}, {"viewId": "vis-2933_00_1", "viewFile": "vis-2933_00_1.png", "specification": {"facet": {"row": {"field": "layer", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "step", "type": "quantitative"}, "y": {"field": "perplexity", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "step", "type": "nominal"}, "y": {"field": "change", "type": "quantitative"}, "color": {"field": "increase or decrease", "type": "nominal"}}, "remark": "Changes in the histogramsduring training are visualized in a second histogram. "}]}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-identify:Attributes-values", "query-identify:Attributes-outliers", "consume-present:Attributes-distribution"], "figId": "vis-2933_00", "figFile": "vis-2933_00.png", "figCaption": "", "figBox": {"x": 0.017778781246247995, "y": 0.2210336492942688, "width": 0.1931110262729051, "height": 0.7316319048513396}, "figVis": ["bar_chart"], "relationText": "T1. Identification of stable layers: compare\nT3. Identification of patterns undetected: anomalies\n\nThe Perplexity Histogram accumulates the sampled input based on the corresponding perplexity value: distribution", "note": "(layer, [(value#, color), (value#, color)])"}, {"viewId": "vis-2933_00_2", "viewFile": "vis-2933_00_2.png", "specification": {"mark": "unit", "encoding": {"unit": {"field": "filters", "type": "node"}, "color": {"field": "activation value", "type": "quantitative"}}}, "marks": ["unit"], "channels": ["unit", "color"], "dataTypes": ["node", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-outliers"], "figId": "vis-2933_00", "figFile": "vis-2933_00.png", "figCaption": "", "figBox": {"x": 0.23569279002533605, "y": 0.21800926164310777, "width": 0.7325547364230646, "height": 0.1745590690018001}, "figVis": ["heatmap"], "relationText": "T2. Identification of degenerated filters: anomalies\nT4. Identification of oversized layers that contain unused filters: anomalies\n\nBy clicking on a cell in the heatmap, the corresponding filter activation is visualized in the Input Map: filter", "note": "Each cell is a filter. No data encoded on the x- or y-axis."}, {"viewId": "vis-2933_00_3", "viewFile": "vis-2933_00_3.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-outliers", "consume-present:Attributes-similarity"], "figId": "vis-2933_00", "figFile": "vis-2933_00.png", "figCaption": "", "figBox": {"x": 0.24951179841116658, "y": 0.5465602331113261, "width": 0.22201518457251912, "height": 0.23886914035195303}, "figVis": ["scatterplot"], "relationText": "T4. Identification of oversized layers: anomalies\nT5. Identification of unnecessary layers or the need of addi-tional layers: anomalies\n\nThe Filter Map provides a view on how similarly filters in a layer respond to the input as a whole: cluster", "note": "(x, y, activated or not, color)"}, {"viewId": "vis-2933_00_4", "viewFile": "vis-2933_00_4.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "filter", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-outliers", "consume-present:Attributes-clusters"], "figId": "vis-2933_00", "figFile": "vis-2933_00.png", "figCaption": "", "figBox": {"x": 0.7502260955626883, "y": 0.45240299649880933, "width": 0.20231546298568368, "height": 0.35034646984156476}, "figVis": ["scatterplot"], "relationText": "T2. Identification of degenerated filters: anomalies\nT3. Identification of patterns undetected: anomalies\nT4. Identification of oversized layers: anomalies\nT5. Identification of unnecessary layers or the need of addi-tional layers: anomalies\n\nBy brushing on the scatterplot, the user selects instances of receptive fields of interest that are visualized in a linked view, here abstracted as arrows pointing to image patches: filter\n\nalso showing that a clustering of the neurons: cluster", "note": ""}, {"viewId": "vis-2934_00_0", "viewFile": "vis-2934_00_0.png", "specification": {"mark": "area", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"aggregate": "sum", "field": "count"}, "color": {"field": "confusion type", "type": "nominal"}, "textual": {"field": "TP/FP", "type": "nominal"}}}, "marks": ["area"], "channels": ["x", "y", "color", "textual"], "dataTypes": ["ordinal", "nominal"], "compositions": [], "aggregates": ["sum"], "actionTargets": ["query-identify:Attributes-correlation"], "figId": "vis-2934_00", "figFile": "vis-2934_00.png", "figCaption": "", "figBox": {"x": 0.02395840898008776, "y": 0.05696452419361202, "width": 0.35814227903332335, "height": 0.47283494342919546}, "figVis": ["area_chart"], "relationText": "Examining the model performance for each class and its evolution through the iteration process: correlate\n\nParticularly, the confusion matrix and predictionscores in the class view, as well as t-SNE projection in the instanceview, provide an overview of the model\u2019s performance atthe class-and instance-levels. Based upon the examination of the model\u2019s per-formance at different instance subsets,an expert can easily discoverthe subset(s) of interest. After selecting an instance subset, their distri-butions on different decision trees are displayed in the classifier view(Fig. 1(c)): filter", "note": "(epoch, class count, TP/FP, class)"}, {"viewId": "vis-2934_00_1", "viewFile": "vis-2934_00_1.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "class", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "consume-present:Attributes-clusters", "query-summarize:Attributes-values", "consume-discover:Attributes-values"], "figId": "vis-2934_00", "figFile": "vis-2934_00.png", "figCaption": "", "figBox": {"x": 0.13976869494703956, "y": 0.571287945118439, "width": 0.22126074684278663, "height": 0.38692652024919955}, "figVis": ["scatterplot"], "relationText": "An instance view that displays the relationships between instancesas well as instance clusters based on the prediction scores: cluster\n\nParticularly, the confusion matrix and prediction scores in the class view, as well as t-SNE projection in the instance view, provide an overview of the model\u2019s performance atthe class-and instance-levels. Based upon the examination of the model\u2019s performance at different instance subsets,an expert can easily discoverthe subset(s) of interest. After selecting an instance subset, their distri-butions on different decision trees are displayed in the classifier view (Fig. 1(c)): filter", "note": ""}, {"viewId": "vis-2934_00_2", "viewFile": "vis-2934_00_2.png", "specification": {"facet": {"row": {"field": "feature name", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "value", "type": "quantitative", "bin": "true"}, "y": {"aggregate": "count", "type": "quantitative"}, "xoffset": {"field": "class", "type": "nominal"}, "color": {"field": "class", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "y", "xoffset", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["query-identify:Attributes-extremes", "query-compare:Attributes-extremes", "consume-present:Attributes-distribution"], "figId": "vis-2934_00", "figFile": "vis-2934_00.png", "figCaption": "", "figBox": {"x": 0.8140195016151319, "y": 0.016618656931027268, "width": 0.18963178593941854, "height": 0.9443498856940901}, "figVis": ["bar_chart"], "relationText": "R4. Examining and comparing important features for the class of interest: compare\n\nThe feature view consists of a set of grouped bar charts to illustrate the feature distribution: distribution", "note": "(feature, (class, value count))"}, {"viewId": "vis-2934_00_3", "viewFile": "vis-2934_00_3.png", "specification": {"facet": {"column": {"field": "classifier", "type": "nominal"}}, "spec": {"mark": "tree", "encoding": {"node": {"field": "decision node", "type": "node"}, "link": {"field": "hierarchy", "type": "relation", "color": {"field": "class", "type": "nominal"}, "width": {"aggregate": "count", "type": "quantitative"}}}}}, "marks": ["tree"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["search-explore:Graphs-topology/structures", "search-locate:Attributes-values"], "figId": "vis-2934_00", "figFile": "vis-2934_00.png", "figCaption": "", "figBox": {"x": 0.3809873924637717, "y": 0.038990069294622544, "width": 0.43406215115681107, "height": 0.26504464840025044}, "figVis": ["tree"], "relationText": "R3. Exploring the structures of classifiers(decision trees): graph\n\nWhen a user selects a cluster of interest,the bars that correspond to the trees in the cluster will be highlighted: filter", "note": ""}, {"viewId": "vis-2934_00_4", "viewFile": "vis-2934_00_4.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "iteration", "type": "ordinal"}, "y": {"field": "tree", "aggregate": "count", "type": "quantitative"}, "color": {"field": "class", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2934_00", "figFile": "vis-2934_00.png", "figCaption": "", "figBox": {"x": 0.38461050856041956, "y": 0.30733704332681017, "width": 0.4290022044960549, "height": 0.0435307065775876}, "figVis": ["bar_chart"], "relationText": "shows how tree size changes during the training process: correlate\n\nUsers can also interact with the bars to select a decision tree of interest: filter", "note": ""}, {"viewId": "vis-2934_00_5", "viewFile": "vis-2934_00_5.png", "specification": {"mark": "tree", "encoding": {"node": {"field": "decision node", "type": "node"}, "link": {"field": "hierarchy", "type": "relation", "color": {"field": "class", "type": "nominal"}, "width": {"aggregate": "count", "type": "quantitative"}}}}, "marks": ["tree"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2934_00", "figFile": "vis-2934_00.png", "figCaption": "", "figBox": {"x": 0.4156030126117931, "y": 0.3548512338322955, "width": 0.3641021490165879, "height": 0.611080738688087}, "figVis": ["tree"], "relationText": "instance distribution on tree structures: distribution and graph", "note": ""}, {"viewId": "vis-2936_04_0", "viewFile": "vis-2936_04_0.png", "specification": {"layer": [{"mark": "geoshape"}, {"nested": {"parent": {"mark": "rect", "encoding": {"x": {"field": "longitude", "type": "quantitative"}, "y": {"field": "latitude", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "others", "encoding": {"saturation": {"field": "anomaly likelihood", "type": "quantitative"}, "inner_rectangle_size": {"field": "difficulty of finding an anomaly", "type": "quantitative"}}}}}}]}, "marks": ["geoshape", "rect", "others"], "channels": ["x", "y", "saturation", "inner_rectangle_size"], "dataTypes": ["quantitative"], "compositions": ["layer", "nested"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-outliers"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.23339432286760114, "y": 0.06919652421041968, "width": 0.3676859618462532, "height": 0.645883747307055}, "figVis": ["map", "treemap"], "relationText": "It provides an overview of the anomalous information in the form of a heatmap with visual cues to direct users attention: derived value, anomalies\n\nWhen a user chooses to investigate a particular region: filter\n\nFiltering:In the system, a user can filter the regions shown in the macro andmicro map views via a range slider (Fig. 5(e)) respectively based ontheir (1) anomaly scores, (2) the volumes of the containing data, and (3)z-scores: filter", "note": "(x, y, color, size of inner rect)"}, {"viewId": "vis-2936_04_1", "viewFile": "vis-2936_04_1.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "rect", "encoding": {"x": {"field": "longitude", "type": "quantitative"}, "y": {"field": "latitude", "type": "quantitative"}, "color": {"field": "z-score", "type": "quantitative"}}}]}, "marks": ["geoshape", "rect"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["search-browse:Attributes-values", "consume-present:Attributes-correlation"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.6022572128479955, "y": 0.06306278914797941, "width": 0.18091185037037727, "height": 0.3303640109405526}, "figVis": ["heatmap", "map"], "relationText": "T3. Efficient browsing of the raw data: retrieve value\n\nA heatmap is generated on the map centered on the focal region, with colors reflecting the strengthof the relationships.We show three types of relationships: (i)rawin-coming or out-going flows at a given time, directly extracted fromthe raw data, (ii)expectedin-coming or out-going flows derived fromthe tensor analysis as described before (i.e., based on theB\u2217matrix),and (iii)deviatedflow with respect to the focal region\u2019s historic data,which reveals how the flows at a given time deviate from their typicalor normal values: graph\n\nFilter-ing:In the system, a user can filter the regions shown in the macro and micro map views via a range slider (Fig. 5(e)) respectively based ontheir (1) anomaly scores, (2) the volumes of the containing data, and (3)z-scores: filter", "note": "(x, y, color)"}, {"viewId": "vis-2936_04_2", "viewFile": "vis-2936_04_2.png", "specification": {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "anomaly scores", "type": "quantitative"}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.5988465450324033, "y": 0.3962927150063738, "width": 0.18693354642466214, "height": 0.08134256749056773}, "figVis": ["line_chart"], "relationText": "T3. Efficient browsing of the raw data: retrieve value\n\nThe history view shows the anomaly scores of the focal region overtime as a time-series chart, from which a user can inspect how the focal region\u2019s abnormal behavior changes over time: correlate", "note": ""}, {"viewId": "vis-2936_04_3", "viewFile": "vis-2936_04_3.png", "specification": {"nested": {"parent": {"mark": "rect", "encoding": {"x": {"field": "date", "type": "temporal"}, "y": {"field": "latent pattern", "type": "nominal"}, "color": {"field": "degree of anomaly", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "line", "encoding": {"x": {"field": "epoch", "type": "ordinal"}, "y": {"field": "latent pattern value captured", "type": "nominal"}}}}}}, "marks": ["rect", "line"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "nominal", "quantitative"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["query-compare:Attributes-outliers", "query-compare:Attributes-values", "consume-present:Attributes-correlation"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.41873582464712406, "y": 0.751717374370758, "width": 0.5551513829642304, "height": 0.2292641184474148}, "figVis": ["matrix", "line_chart"], "relationText": "T4. Interpreting anomaly in their spatiotemporal contexts: compare\nT5. Facilitating visual data comparisons and correlations: compare, correlate\nThe temporal pattern view (Fig. 5(4)) visualizes the temporal distribution of the dynamic latent patterns derived from the tensor analysis, as described in Section 4.3.: correlate", "note": "(x, [background color, (y, (x in cell, y in cell, size of circle))])"}, {"viewId": "vis-2936_04_4", "viewFile": "vis-2936_04_4.png", "specification": {"layer": [{"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "anomaly score", "type": "quantitative"}, "size": {"field": "trip volume", "type": "quantitative"}}}, {"mark": "contour", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "contour": {"field": "density", "type": "quantitative"}}}]}, "marks": ["point", "contour"], "channels": ["x", "y", "color", "size", "contour"], "dataTypes": ["quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-similarity"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.05243049723454911, "y": 0.028273195468645908, "width": 0.17546338631983796, "height": 0.3369071970508776}, "figVis": ["scatterplot", "contour_graph"], "relationText": "shows the similarity among regions in terms of sharing similar expected pattern", "note": "(x, y, color, size) The contour graph in the background is derived by the point distributions."}, {"viewId": "vis-2936_04_5", "viewFile": "vis-2936_04_5.png", "specification": {"facet": {"row": {"field": "grid id", "type": "nominal"}}, "spec": {"mark": "rect", "encoding": {"x": {"field": "longitude", "type": "nominal"}, "y": {"field": "latitude", "type": "nominal"}, "color": {"field": "anomaly scores", "type": "quantitative"}}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-identify:Attributes-extremes"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.05559468736497332, "y": 0.37745023859280247, "width": 0.16913500605898957, "height": 0.5924979296941492}, "figVis": ["heatmap"], "relationText": "Dynamic visual ranking of suspicious regions: sort", "note": "(order, (x, y, color))"}, {"viewId": "vis-2936_04_6", "viewFile": "vis-2936_04_6.png", "specification": {"facet": {"field": "date", "type": "temporal", "columns": 2}, "spec": {"layer": [{"mark": "geoshape"}, {"nested": {"parent": {"mark": "rect", "encoding": {"x": {"field": "longitude", "type": "quantitative"}, "y": {"field": "latitude", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "others", "encoding": {"saturation": {"field": "anomaly likelihood", "type": "quantitative"}, "inner_rectangle_size": {"field": "difficulty of finding an anomaly", "type": "quantitative"}}}}}}]}}, "marks": ["geoshape", "rect", "others"], "channels": ["x", "y", "saturation", "inner_rectangle_size"], "dataTypes": ["quantitative"], "compositions": ["facet", "layer", "nested"], "aggregates": [], "actionTargets": ["produce:Attributes-values"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.6022820059842572, "y": 0.4786545768765024, "width": 0.18246154325165714, "height": 0.236001250075246}, "figVis": ["map", "heatmap"], "relationText": "snapshot panel and the anomaly panel respectively allow users to record the suspicious regions and anomaly cases for later retrieval and further examination", "note": "not a VA task"}, {"viewId": "vis-2936_04_7", "viewFile": "vis-2936_04_7.png", "specification": {"facet": {"field": "date", "type": "temporal", "columns": 2}, "spec": {"layer": [{"mark": "geoshape"}, {"mark": "rect", "encoding": {"x": {"field": "longitude", "type": "quantitative"}, "y": {"field": "latitude", "type": "quantitative"}, "color": {"field": "z-score", "type": "quantitative"}}}]}}, "marks": ["geoshape", "rect"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["produce:Attributes-values"], "figId": "vis-2936_04", "figFile": "vis-2936_04.png", "figCaption": "", "figBox": {"x": 0.23657072991255063, "y": 0.723901103791139, "width": 0.1774160450690808, "height": 0.24419300612174963}, "figVis": ["map"], "relationText": "Anomaly Panel (Fig. 5(8)) shows the snapshots of the micro map view automatically captured while the users click to inspect a suspicious region", "note": "not a VA task"}, {"viewId": "vis-2938_00_0", "viewFile": "vis-2938_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "tsne_x", "type": "quantitative"}, "y": {"field": "tsne_y", "type": "quantitative"}, "color": {"field": "group", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-clusters"], "figId": "vis-2938_00", "figFile": "vis-2938_00.png", "figCaption": "", "figBox": {"x": 0.2523004478046617, "y": 0.2710953612379104, "width": 0.26878571345894675, "height": 0.5755908545661811}, "figVis": ["scatterplot"], "relationText": "revealing word- and cluster-level relationships", "note": ""}, {"viewId": "vis-2938_00_1", "viewFile": "vis-2938_00_1.png", "specification": {"mark": "point", "encoding": {"x": {"field": "relevance score for group 1", "type": "quantitative"}, "y": {"field": "relevance score for group 2", "type": "quantitative"}, "color": {"field": "accepted/rejected/picked", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-discover:Attributes-outliers"], "figId": "vis-2938_00", "figFile": "vis-2938_00.png", "figCaption": "", "figBox": {"x": 0.5316741874047677, "y": 0.26843078437584117, "width": 0.22893739011764172, "height": 0.42782853058680953}, "figVis": ["scatterplot"], "relationText": "P2 appreciated the concept score scatterplot (Figure 1(7)) that showed the distribution of comments with respect to custom concepts as axes. It revealed outliers and enabled filtering of comments based on semantic contents: distribution, anomaly", "note": ""}, {"viewId": "vis-2939_00_0", "viewFile": "vis-2939_00_0.png", "specification": {"mark": "treemap", "encoding": {"node": {"field": "class", "type": "node", "encoding": {"color": {"field": "performance", "type": "quantitative"}}}, "link": {"field": "hierarchy", "type": "relation"}}}, "marks": ["treemap"], "channels": ["node", "link", "color"], "dataTypes": ["node", "relation", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Graphs-topology/structures"], "figId": "vis-2939_00", "figFile": "vis-2939_00.png", "figCaption": "", "figBox": {"x": 0.10504054305975011, "y": 0.07079936408867828, "width": 0.11589498793307404, "height": 0.894247838748471}, "figVis": ["sunburst_icicle"], "relationText": "As we show in Section 4, inspecting group-level performance under different conditions reveals the impact of the hierarchical structure on CNN performance (T2) and its sensitivity to data variation (T3). The child nodes of a parent node in the hierarchy can be sorted by a user-selected criterion, such as size or performance metrics: correlate\n\nThe child nodes of a parent node in the hierarchy can be sorted by a user-selected criterion, such as size or performance metrics: sort", "note": "((node, metric),hierarchy)\nEach rectangle in this plot rep- resents a group of classes. The rectangle color can encode information about this group such as a group-level performance metric"}, {"viewId": "vis-2939_00_1", "viewFile": "vis-2939_00_1.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "predict class", "type": "nominal"}, "y": {"field": "actual class", "type": "nominal"}, "color": {"field": "predict performance", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2939_00", "figFile": "vis-2939_00.png", "figCaption": "", "figBox": {"x": 0.221077254827164, "y": 0.06707772826582488, "width": 0.4943913550577328, "height": 0.908092283059501}, "figVis": ["matrix"], "relationText": "For this purpose, we compute the correlation matrix of network responses to these samples at a selected reference layer: correlate", "note": ""}, {"viewId": "vis-2943_01_0", "viewFile": "vis-2943_01_0.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "layer", "type": "node", "encoding": {"shape": {"field": "layer type", "type": "nominal"}}}, "link": {"field": "hierarchy", "type": "relation"}}}, "marks": ["graph"], "channels": ["node", "link", "shape"], "dataTypes": ["node", "relation", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Graphs-topology/structures"], "figId": "vis-2943_01", "figFile": "vis-2943_01.png", "figCaption": "", "figBox": {"x": 0.011710485453747645, "y": 0.13976795750493998, "width": 0.7049184546751195, "height": 0.38999877079253703}, "figVis": ["graph"], "relationText": "ACTIVIS provides an overview of the model by displaying its architecture as a computation graph (Fig. 1A, top), summarizing the model structure.\n\nSusan clicks the node for the last hidden layer, and ACTIVIS displays the layer\u2019s neuron activation in a panel (Fig. 1B): filter", "note": ""}, {"viewId": "vis-2943_01_1", "viewFile": "vis-2943_01_1.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "a group of instances", "type": "nominal"}, "y": {"field": "neuron", "type": "nominal"}, "color": {"field": "neuron activation", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2943_01", "figFile": "vis-2943_01.png", "figCaption": "", "figBox": {"x": 0.15892040918124783, "y": 0.5930067076538018, "width": 0.4246722195063807, "height": 0.3529653231128674}, "figVis": ["matrix"], "relationText": "The neuron activation matrix, shown at Fig. 2B.1, illustrates this concept of comparing multiple instances and instance subsets: compare", "note": ""}, {"viewId": "vis-2943_01_2", "viewFile": "vis-2943_01_2.png", "specification": {"mark": "point", "encoding": {"x": {"field": "tsne_x", "type": "quantitative"}, "y": {"field": "tsne_y", "type": "quantitative"}, "color": {"field": "class", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-clusters"], "figId": "vis-2943_01", "figFile": "vis-2943_01.png", "figCaption": "", "figBox": {"x": 0.5934528750983996, "y": 0.6492077533039293, "width": 0.11611244304287804, "height": 0.1842329123577404}, "figVis": ["scatterplot"], "relationText": "The projected view complements with the neuron activation matrix view (Fig. 2B.1). Hovering over a subset\u2019s row in the matrix would highlight the subset\u2019s instances in the projected view, allowing the user to see how instances within the subsets are distributed.: filter\n\ntheir activation patterns gradually become more discernible and clustered (in projected view).: cluster\n", "note": ""}, {"viewId": "vis-2943_01_3", "viewFile": "vis-2943_01_3.png", "specification": {"facet": {"row": {"field": "class", "type": "nominal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "unit", "encoding": {"unit": {"field": "correctly classified instances", "type": "node"}, "color": {"field": "true class", "type": "nominal"}}, "remark": "correctly classified instances shown on the left"}, {"mark": "unit", "encoding": {"unit": {"field": "misclassified instances", "type": "node"}, "color": {"field": "predicted class", "type": "nominal"}}, "remark": "misclassified on the right"}]}}, "marks": ["unit"], "channels": ["unit", "color"], "dataTypes": ["node", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2943_01", "figFile": "vis-2943_01.png", "figCaption": "", "figBox": {"x": 0.7260649938364383, "y": 0.1348247100823537, "width": 0.25674417941372546, "height": 0.6906633093102699}, "figVis": ["unit_visualization"], "relationText": "The instance selection panel helps users get an overview of instances with their prediction results and determine which ones should be added to the neuron activation view for further exploration and comparison.", "note": "([left correctly classified element number, (right misclassified elements)], class)"}, {"viewId": "vis-2944_00_0", "viewFile": "vis-2944_00_0.png", "specification": {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "proj_x", "type": "quantitative"}, "y": {"field": "proj_y", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"layer": [{"mark": "point", "encoding": {"color": {"field": "dominating score", "type": "quantitative"}}, "remark": "the dot in the center"}, {"mark": "arc", "encoding": {"theta": {"field": "attribute", "type": "nominal"}, "radius": {"field": "attribute value", "type": "quantitative"}, "color": {"field": "value difference", "type": "quantitative"}}}]}}}}, "marks": ["point", "arc"], "channels": ["x", "y", "color", "theta", "radius"], "dataTypes": ["quantitative", "nominal"], "compositions": ["nested", "layer"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-clusters", "consume-discover:Attributes-outliers", "query-compare:Attributes-values"], "figId": "vis-2944_00", "figFile": "vis-2944_00.png", "figCaption": "", "figBox": {"x": 0.006592522303166484, "y": 0.008514991238987846, "width": 0.3275226809104161, "height": 0.47855761149431575}, "figVis": ["scatterplot", "glyph_based"], "relationText": "The Projection View aims at providing an overview of skyline to allow users to discover clusters and outliers (T4). : anomalies, cluster\n\nIn addition, we design skyline glyphs to encode detailed attribute values of each point and help users compare different skyline points (T1).: compare", "note": "([inner circle color for the dominating score, (outer sector radiuses for numerical values of attributes)], x, y)"}, {"viewId": "vis-2944_00_1", "viewFile": "vis-2944_00_1.png", "specification": {"remark": "Visual encodings in the Tabular View: (a) the column header showing a specific attribute\u2019s value distribution; (b) the diverging bar chart depicting the point\u2019s relative ranking at this attribute and its overall differences with the other skyline points; (c) the expansion mode show- ing the detailed comparisons between this point and other points at all attributes; (d) the bars representing the decisive subspaces of the point; and (e) the linking curve connecting the relative ranking and absolute value of the point at this attribute.", "facet": {"column": {"field": "attribute", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "area", "encoding": {"x": {"field": "values", "type": "quantitative"}, "y": {"field": "frequency", "type": "quantitative"}}, "remark": "the column header showing a specific attribute\u2019s value distribution"}, {"facet": {"row": {"field": "player", "type": "nominal"}}, "spec": {"condition_1": {"test": "detailed information", "value": {"concat": {"layout": "crossing"}, "spec": [{"remark": "the diverging bar chart depicting the point\u2019s relative ranking at this attribute and its overall differences with the other skyline points", "position": 2, "mark": "bar", "encoding": {"y": {"field": "overall differences with the other skyline points", "type": "quantitative"}, "x": {"field": "relative ranking at this attribute", "type": "quantitative"}}}, {"remark": "the bars representing the decisive subspaces of the point", "position": 5, "mark": "tick", "encoding": {"y": {"field": "attribute (compared)", "type": "nominal"}, "x": {"field": "decisive subspaces", "type": "nominal"}}}, {"position": 1, "mark": "rect", "encoding": {"y": {"field": "attribute (compared)", "type": "nominal"}, "x": {"field": "attribute value", "type": "quantitative"}, "color": {"field": "value difference", "type": "quantitative"}}}]}}, "condition_2": {"test": "not detailed information", "value": {"mark": "rect", "encoding": {"y": {"field": "attribute (compared)", "type": "nominal"}, "x": {"field": "attribute value", "type": "quantitative"}, "color": {"field": "value difference", "type": "quantitative"}}}}}}]}}, "marks": ["area", "bar", "tick", "rect"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2944_00", "figFile": "vis-2944_00.png", "figCaption": "", "figBox": {"x": 0.025958622984082805, "y": 0.5431845096137556, "width": 0.969087954966039, "height": 0.4434541154647291}, "figVis": ["area_chart", "bar_chart", "heatmap", "matrix"], "relationText": "For example, users may want to know the difference between a specific skyline point and other skyline points to infer how good it is in the entire skyline (T3). : compare\n\nIn addition, the decisive subspaces can help users understand how balanced a skyline point is (T2). All these details are encoded in this view to provide users with insights into why and how a skyline point is superior, thereby facilitating the decision-making process (T2, T3). To addimensionality reductioness the scalability issue, three interactions are also tightly integrated into this view to allow users to eliminate unsuitable skyline points rapidly (T7) and focus on the interesting subset of skyline points.", "note": "[Q# for the area chart, (N, Q) for the bar chart, (N, N, Q) for the heatmap]: please refer to figure 5.\nThis is repeated along the x-axis (n) and y-axis (n).\n\nVisual encodings in the Tabular View: (a) the column header showing a specific attribute\u2019s value distribution; (b) the diverging bar chart depicting the point\u2019s relative ranking at this attribute and its overall differences with the other skyline points; (c) the expansion mode show- ing the detailed comparisons between this point and other points at all attributes; (d) the bars representing the decisive subspaces of the point; and (e) the linking curve connecting the relative ranking and absolute value of the point at this attribute."}, {"viewId": "vis-2944_00_2", "viewFile": "vis-2944_00_2.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "player/comparison glyph", "type": "node", "encoding": {"condition_1": {"test": "player", "value": {"mark": "radar", "encoding": {"theta": {"field": "attribute", "type": "nominal"}, "radius": {"field": "relative ranking", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}}}}, "condition_2": {"test": "comparison glyph", "value": {"mark": "others", "encoding": {"inner theta": {"field": "dominating scores"}, "radius": {"field": "points that are dominated by at least one linked skyline point", "aggregate": "count", "type": "quantitative"}, "outer theta": {"field": "proportion of points that are exclusively dominated by the corresponding skyline points"}, "color": {"field": "player", "type": "nominal"}}}}}}, "link": {"field": "comparision relation", "type": "relation"}}}, "marks": ["graph", "radar", "others"], "channels": ["node", "link", "theta", "radius", "color", "inner theta", "outer theta"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-values", "query-compare:Attributes-distribution"], "figId": "vis-2944_00", "figFile": "vis-2944_00.png", "figCaption": "", "figBox": {"x": 0.33721477404835015, "y": 0.00846929713820127, "width": 0.30863077373055425, "height": 0.4722478270305626}, "figVis": ["graph", "polar_plot", "sector_chart"], "relationText": "When users find desirable skyline points in the other views, they can click on the glyphs or rows to add them to this Comparison View for detailed comparison: compare\n\nApart from attribute values (T3), the number of dominated points and the value distribution of these dominated points are also important aspects to compare (T5).: distribution", "note": "([(N,Q) for the radar chart OR (N,Q,Q) for the glyph], G)"}, {"viewId": "vis-2945_00_0", "viewFile": "vis-2945_00_0.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "is_selected", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2945_00", "figFile": "vis-2945_00.png", "figCaption": "", "figBox": {"x": 0.018583595574359422, "y": 0.059472832322163126, "width": 0.4425385434532683, "height": 0.24221730335611505}, "figVis": ["bar_chart"], "relationText": "Both views represent the temporal dimension of transactions.: correlate", "note": "In both views, time is laid out on the x-axis, while the y-axis represents the total amount of money transacted per day. Thus, in A.1 (see Figure 4), each bar represents a day. Days that contain at least one suspicious transaction are highlighted in red."}, {"viewId": "vis-2945_00_1", "viewFile": "vis-2945_00_1.png", "specification": {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"aggregate": "count", "type": "quantitative"}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2945_00", "figFile": "vis-2945_00.png", "figCaption": "", "figBox": {"x": 0.03823210951208242, "y": 0.3180793431144442, "width": 0.41877268767925657, "height": 0.0860304200959505}, "figVis": ["line_chart"], "relationText": "A.2 (see Figure 4) serves as an overview visualization of the inspected time period and as an interactive temporal filter: filter, correlate", "note": ""}, {"viewId": "vis-2945_00_2", "viewFile": "vis-2945_00_2.png", "specification": {"mark": "line", "encoding": {"x": {"field": "score type", "type": "nominal"}, "y": {"field": "score value", "type": "quantitative"}, "color": {"field": "if selected", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-correlation", "query-identify:Attributes-clusters"], "figId": "vis-2945_00", "figFile": "vis-2945_00.png", "figCaption": "", "figBox": {"x": 0.005977746483067163, "y": 0.4384329058681425, "width": 0.4670442792676076, "height": 0.5571336949728342}, "figVis": ["line_chart"], "relationText": "We needed to provide a visualization that enables investigators to identify sub-scores with strong influences on the overall score.: correlate\n\nThey also need to identify groups of transactions with similar sub-scores in order to better understand fraudulent patterns.: cluster", "note": ""}, {"viewId": "vis-2945_00_3", "viewFile": "vis-2945_00_3.png", "specification": {"mark": "point", "encoding": {"x": {"field": "score value", "type": "quantitative"}, "y": {"field": "amount", "type": "quantitative"}, "color": {"field": "if selected", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters", "consume-present:Attributes-outliers"], "figId": "vis-2945_00", "figFile": "vis-2945_00.png", "figCaption": "", "figBox": {"x": 0.4678236065499545, "y": 0.06866465370463047, "width": 0.1744829163466174, "height": 0.2916860908436388}, "figVis": ["scatterplot"], "relationText": "Thus, clusters of dots represent transactions with similar characteristics in these two dimensions, while outliers indicate uncommon transactions.: cluster, anomalies", "note": ""}, {"viewId": "vis-2945_00_4", "viewFile": "vis-2945_00_4.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "amount", "type": "quantitative"}, "y": {"field": "top receiver", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "frequency", "type": "quantitative"}, "y": {"field": "top receiver", "type": "nominal"}}}]}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-extremes"], "figId": "vis-2945_00", "figFile": "vis-2945_00.png", "figCaption": "", "figBox": {"x": 0.4636378712585972, "y": 0.3676972617440505, "width": 0.1814424621928362, "height": 0.5936257515096682}, "figVis": ["bar_chart"], "relationText": "View D.1 shows the rank of the top 10 receivers that received the biggest amount of money from the currently selected account, while the bar length encodes the sum of money received (see Figure 4). In D.2, we display the top 10 accounts which received money most frequently from the selected account, and thus, the bar length encodes the number of transactions received.:  sort", "note": ""}, {"viewId": "vis-2945_00_5", "viewFile": "vis-2945_00_5.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "amount", "type": "quantitative"}, "y": {"field": "frequency", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2945_00", "figFile": "vis-2945_00.png", "figCaption": "", "figBox": {"x": 0.6507432533540991, "y": 0.0232142911108379, "width": 0.3399914202489087, "height": 0.156069498354031}, "figVis": ["bar_chart"], "relationText": "When investigating more than one account, this view facilitates comparison and switching between accounts.: filter, compare", "note": ""}, {"viewId": "vis-2951_00_0", "viewFile": "vis-2951_00_0.png", "specification": {"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "loss", "type": "quantitative"}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["ordinal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["search-explore:Attributes-correlation"], "figId": "vis-2951_00", "figFile": "vis-2951_00.png", "figCaption": "", "figBox": {"x": 0.005193945070195771, "y": 0.01416663025114511, "width": 0.9889077301874096, "height": 0.09854678794721076}, "figVis": ["line_chart"], "relationText": "In DGMTracker, we allow an expert to explore the loss changes with different time granularities by employing the focus+context time- line [50] (Fig. 1 (a)).: correlate\nThe expert can click on the loss curve to select the snapshot of interest.: filter", "note": ""}, {"viewId": "vis-2951_00_1", "viewFile": "vis-2951_00_1.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "neuron", "type": "node"}, "link": {"field": "neuron connection", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "averaged activations", "aggregate": "average", "type": "quantitative"}}}}}}, "marks": ["graph", "line"], "channels": ["node", "link", "x", "y"], "dataTypes": ["node", "relation", "ordinal", "quantitative"], "compositions": ["nested"], "aggregates": ["average"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2951_00", "figFile": "vis-2951_00.png", "figCaption": "", "figBox": {"x": 0.00870833091523394, "y": 0.11541697318218982, "width": 0.9868096162027215, "height": 0.4388655441047841}, "figVis": ["flow_diagram", "line_chart"], "relationText": "To support such analysis, the data flow visualization provides a hybrid visualization to illustrate how data flows through the network at the snapshot level (Fig. 1 (b)): correlate", "note": "(T, Q#): each cell is min/max/avg"}, {"viewId": "vis-2951_00_2", "viewFile": "vis-2951_00_2.png", "specification": {"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"aggregate": "variance", "field": "output", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": ["variance"], "actionTargets": ["query-identify:Graphs-nodes"], "figId": "vis-2951_00", "figFile": "vis-2951_00.png", "figCaption": "", "figBox": {"x": 0.0069782005896013195, "y": 0.5539989367736198, "width": 0.9885351946652129, "height": 0.44269974332892087}, "figVis": ["line_chart"], "relationText": "When an expert selects a layer, we aim to present the corresponding training dynamics to facilitate him or her in finding the neuron of interest.: correlate", "note": ""}, {"viewId": "vis-2952_00_0", "viewFile": "vis-2952_00_0.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "rank score", "type": "quantitative"}, "y": {"field": "rank index", "type": "ordinal"}}}, {"facet": {"column": {"field": "attribute", "type": "nominal"}}, "spec": {"layer": [{"mark": "bar", "encoding": {"x": {"field": "attribute value", "type": "quantitative"}, "y": {"field": "rank index", "type": "ordinal"}}}, {"mark": "tick", "encoding": {"x": {"field": "contribution value", "type": "quantitative"}, "y": {"field": "rank index", "type": "ordinal"}}}]}}]}, "marks": ["bar", "tick"], "channels": ["x", "y"], "dataTypes": ["quantitative", "ordinal"], "compositions": ["concat", "facet", "layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-order", "query-summarize:Attributes-values"], "figId": "vis-2952_00", "figFile": "vis-2952_00.png", "figCaption": "", "figBox": {"x": 0.20442793986607527, "y": 0.01786978335532647, "width": 0.7848252651793695, "height": 0.9616175987222957}, "figVis": ["bar_chart", "table"], "relationText": "The data are ordered by their ranking, and initially the rank scores are computed assuming all attributes are equally important (see Section 4.2.3 for how).: sort\n\n{suming all attributes}: compute derived value", "note": ""}, {"viewId": "vis-2952_00_1", "viewFile": "vis-2952_00_1.png", "specification": {"mark": "bar", "encoding": {"y": {"field": "attribute", "type": "nominal"}, "x": {"field": "weight", "type": "quantitative"}, "color": {"field": "positive/negative", "type": "nominal"}}}, "marks": ["bar"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2952_00", "figFile": "vis-2952_00.png", "figCaption": "", "figBox": {"x": 0.00407226978239591, "y": 0.3230728109815169, "width": 0.19534911069269834, "height": 0.38953264469214655}, "figVis": ["bar_chart"], "relationText": "The vertical positioning of the attribute weight bars allows users to easily make comparisons between values.: compare", "note": ""}, {"viewId": "vis-2954_00_0", "viewFile": "vis-2954_00_0.png", "specification": {"facet": {"row": {"field": "sequential pattern", "type": "nominal"}}, "spec": {"nested": {"parent": {"mark": "rect", "encoding": {"x": {"field": "sequential order", "type": "ordinal"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "others", "encoding": {"triangular glyph existence": {"field": "additional event or not", "type": "nominal"}, "triangular glyph size": {"aggregate": "count", "field": "insertion", "type": "quantitative"}, "height": {"aggregate": "count", "field": "events", "type": "quantitative"}, "color": {"field": "event type", "type": "nominal"}}}}}}}, "marks": ["rect", "others"], "channels": ["x", "triangular glyph existence", "triangular glyph size", "height", "color"], "dataTypes": ["ordinal", "nominal", "quantitative"], "compositions": ["facet", "nested"], "aggregates": ["count"], "actionTargets": ["produce:Attributes-values"], "figId": "vis-2954_00", "figFile": "vis-2954_00.png", "figCaption": "", "figBox": {"x": 0.2552729097164954, "y": 0.061992313987115195, "width": 0.3281513425555917, "height": 0.5832108698634558}, "figVis": ["others"], "relationText": "{Minimum Description Length (MDL)}\uff1a compute derived value", "note": "(sequences, events, event type, number of intertions)\nIn the summary view (Fig. 1 (A)), we vertically list all the sequential patterns identified by the algorithm. Each pattern represents a cluster of sequences. For each pattern, we layout the events from left to right and display them as rectangles. The color of the rectangles encodes the type of the event. Triangular glyphs are placed between adjacent events or at the beginning/end of the pattern. Their sizes are proportional to the number of insertions at the corresponding position, accumulated over all the sequences in the cluster. "}, {"viewId": "vis-2954_00_1", "viewFile": "vis-2954_00_1.png", "specification": {"facet": {"row": {"field": "sequence", "type": "nominal"}}, "spec": {"mark": "unit", "encoding": {"unit": {"field": "event", "type": "node"}, "color": {"field": "event type", "type": "nominal"}, "size": {"aggregate": "count", "field": "event matched", "type": "quantitative"}}}}, "marks": ["unit"], "channels": ["unit", "color", "size"], "dataTypes": ["node", "nominal", "quantitative"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2954_00", "figFile": "vis-2954_00.png", "figCaption": "", "figBox": {"x": 0.5955875259682892, "y": 0.06267251876572504, "width": 0.3951666511998141, "height": 0.9272788130875815}, "figVis": ["table"], "relationText": "A tabular display (B) shows the detailed information of the sequences linked with the summary view.", "note": "((Event type, index of the event), sequence)"}, {"viewId": "vis-2954_00_2", "viewFile": "vis-2954_00_2.png", "specification": {"mark": "point", "layout": "circular", "encoding": {"radius": {"field": "jacard index", "type": "quantitative"}, "theta": {"field": "category", "type": "nominal"}, "size": {"field": "frequency", "type": "quantitative"}, "color": {"field": "event type", "type": "nominal"}}}, "marks": ["point"], "channels": ["radius", "theta", "size", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-identify:Attributes-extremes"], "figId": "vis-2954_00", "figFile": "vis-2954_00.png", "figCaption": "", "figBox": {"x": 0.014682191009766364, "y": 0.3173989172567775, "width": 0.21357193300717256, "height": 0.4839431617550341}, "figVis": ["scatterplot", "donut_chart"], "relationText": "The event filter (C) shows the co-occurrence of events with a focus event at the center and allows users to select a set of highly correlated events.: filter, correlate\n\n{Jaccard Index}: compute derived value", "note": "(Jaccard Index, event type, event occur, category): The sizes of the circles represent how frequent the events occur overall. The events are arranged around the circle based on their category. The radial angles separate different categories of events as in [6]. The categorical labels are displayed along the sectors. The color of the cirle encode the type of the event. The co-occurrence is measured by Jaccard Index and is encoded as the radial distances to the focus event at the center of the display. "}, {"viewId": "vis-2955_00_0", "viewFile": "vis-2955_00_0.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"y": {"field": "cluster_type", "type": "nominal"}, "x": {"field": "count", "type": "quantitative"}, "color": {"field": "cluster_type", "type": "nominal"}}}, {"facet": {"row": {"field": "cluster_type", "type": "nominal"}}, "spec": {"mark": "radar", "encoding": {"theta": {"field": "metric_type", "type": "nominal"}, "radius": {"field": "metric_value", "type": "quantitative"}}}}]}, "marks": ["bar", "radar"], "channels": ["y", "x", "color", "theta", "radius"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values", "consume-discover:Attributes-clusters"], "figId": "vis-2955_00", "figFile": "vis-2955_00.png", "figCaption": "", "figBox": {"x": 0.01851150750965767, "y": 0.06377165859300922, "width": 0.22368137692007883, "height": 0.8338634190614936}, "figVis": ["bar_chart", "polar_plot"], "relationText": "Figure 1(a) shows the Ranked List of Clustering Results on the left, which lets users compare multiple clustering results: cluster, compare", "note": "([stacked bars (Q,N), radar chart (Q,N)], categories)"}, {"viewId": "vis-2955_00_1", "viewFile": "vis-2955_00_1.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimention1", "type": "quantitative"}, "y": {"field": "dimention2", "type": "quantitative"}, "color": {"field": "cluster_type", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-clusters"], "figId": "vis-2955_00", "figFile": "vis-2955_00.png", "figCaption": "", "figBox": {"x": 0.2683310181272653, "y": 0.06882817716491786, "width": 0.4387945467977087, "height": 0.4553601370075584}, "figVis": ["scatterplot"], "relationText": "The main use of the Projection view is to have a consistent and stable representation across all clustering results, as the positions of the data points remain stable across all clustering results.: cluster", "note": ""}, {"viewId": "vis-2955_00_2", "viewFile": "vis-2955_00_2.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "score", "type": "quantitative"}, "y": {"field": "class type", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "variable type", "type": "nominal"}, "y": {"field": "variable value", "type": "quantitative"}, "color": {"field": "cluster_type", "type": "nominal"}}}]}, "marks": ["bar", "line"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["produce:Attributes-order"], "figId": "vis-2955_00", "figFile": "vis-2955_00.png", "figCaption": "", "figBox": {"x": 0.25280201490403037, "y": 0.5406328577316089, "width": 0.44710499607308074, "height": 0.4461755558207912}, "figVis": ["parallel_coordinate"], "relationText": "This becomes even more evident when sorting the axes by their relevance to the cluster (Figure 4(c)).: sort", "note": ""}, {"viewId": "vis-2955_00_3", "viewFile": "vis-2955_00_3.png", "specification": {"facet": {"row": {"field": "feature_name", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "cluster_type", "type": "nominal"}, "y": {"field": "feature_value", "type": "quantitative"}, "color": {"field": "cluster_type", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["produce:Attributes-values"], "figId": "vis-2955_00", "figFile": "vis-2955_00.png", "figCaption": "", "figBox": {"x": 0.7559818275903443, "y": 0.14432975895067923, "width": 0.21176783481548514, "height": 0.39206893650987157}, "figVis": ["bar_chart"], "relationText": "{statistics and prototypes}: compute derived value", "note": ""}, {"viewId": "vis-2955_00_4", "viewFile": "vis-2955_00_4.png", "specification": {"facet": {"row": {"field": "feature_name", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature value", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2955_00", "figFile": "vis-2955_00.png", "figCaption": "", "figBox": {"x": 0.7564321900119324, "y": 0.5639838847837219, "width": 0.21011559020273196, "height": 0.41522368711247404}, "figVis": ["bar_chart"], "relationText": "However, this view also puts them in the context of other data points by presenting the distribution of values alongside each value.: distribution", "note": ""}, {"viewId": "vis-2956_00_0", "viewFile": "vis-2956_00_0.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "topic", "type": "nominal"}, "y": {"field": "attribute_type", "type": "nominal"}, "lightness": {"field": "behavioral abnormality", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["x", "y", "lightness"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-2956_00", "figFile": "vis-2956_00.png", "figCaption": "", "figBox": {"x": 0.10086618657966584, "y": 0.015919802407507757, "width": 0.12210126087391074, "height": 0.27434248785617}, "figVis": ["line_chart"], "relationText": "The summary table displays the name of the phenotype alongside a table of all summary measures, enabling for the detailed comparison of a single phenotype across all topics (Fig. 3A).: compare", "note": ""}, {"viewId": "vis-2956_00_1", "viewFile": "vis-2956_00_1.png", "specification": {"facet": {"row": {"field": "topic", "type": "nominal"}}, "spec": {"mark": "line", "encoding": {"x": {"field": "year", "type": "ordinal"}, "y": {"field": "probability", "type": "quantitative"}}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["ordinal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2956_00", "figFile": "vis-2956_00.png", "figCaption": "", "figBox": {"x": 0.10297762228820623, "y": 0.2874013012059652, "width": 0.11840996678856301, "height": 0.6414340537224199}, "figVis": ["line_chart"], "relationText": "A timeline chart for each topic displays how the probability of the phenotype changes with a patient\u2019s age. These timeline charts are vertically juxtaposed to facilitate comparisons along the temporal dimension of the evolving phenotype probabilities (Fig. 3B).", "note": ""}, {"viewId": "vis-2956_00_2", "viewFile": "vis-2956_00_2.png", "specification": {"facet": {"column": {"field": "topic", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "sunburst", "encoding": {"node": {"field": "keyword", "type": "node", "encoding": {"color": {"field": "trend", "type": "quantitative"}}}, "link": {"field": "link", "type": "relation"}}}, {"mark": "point", "encoding": {"x": {"field": "percentage", "type": "quantitative"}, "y": {"field": "probability", "type": "quantitative"}, "color": {"field": "trend", "type": "nominal"}}}, {"mark": "bar", "encoding": {"y": {"field": "keyword", "type": "nominal"}, "x": {"field": "probability", "type": "quantitative"}}}]}}, "marks": ["sunburst", "point", "bar"], "channels": ["node", "link", "color", "x", "y"], "dataTypes": ["node", "relation", "quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution", "produce:Attributes-order"], "figId": "vis-2956_00", "figFile": "vis-2956_00.png", "figCaption": "", "figBox": {"x": 0.2419772542034063, "y": 0.023163531181639788, "width": 0.6537240205125194, "height": 0.8982734637510588}, "figVis": ["bar_chart", "scatterplot", "sunburst_icicle"], "relationText": "We support these explorations through multiple visual representations (encode) that can be customized (arrange & change).: sort\n\nThis supports comparisons of explicitly encoded values between topics through a consistent representation of the hierarchy topology, supporting browse & explore search, through compare & summarize queries (Fig. 5B).: compare", "note": "([icicle plot, scatterplot, bar chart], topics)"}, {"viewId": "vis-2957_00_0", "viewFile": "vis-2957_00_0.png", "specification": {"facet": {"row": {"field": "feature_type", "type": "nominal"}, "column": {"field": "feature_type", "type": "nominal"}}, "spec": {"condition_1": {"test": "Categorical-Numerical", "value": {"facet": {"row": {"field": "feature_subtype", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "nominal", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}}}, "condition_2": {"test": "Numerical-Numerical", "value": {"mark": "point", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}, "y": {"field": "feature_value", "type": "quantitative"}}}}, "condition_3": {"test": "Categorical-Categorical", "value": {"mark": "point", "encoding": {"x": {"field": "feature_value", "type": "nominal"}, "y": {"field": "feature_value", "type": "nominal"}, "size": {"aggregate": "count", "type": "nominal"}}}}, "condition_4": {"test": "matrix involving aggregated attribute", "value": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "quantitative", "bin": true}, "y": {"field": "count", "type": "quantitative"}}}}}}, "marks": ["bar", "point"], "channels": ["x", "y", "size"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation", "query-compare:Attributes-distribution"], "figId": "vis-2957_00", "figFile": "vis-2957_00.png", "figCaption": "", "figBox": {"x": 0.004896649673306291, "y": 0.07391127375515111, "width": 0.3945880944343209, "height": 0.7609570108929088}, "figVis": ["bar_chart"], "relationText": "5.2.1 Joint Distribution Representation: distribution\n\n5.2.2 Brush and Highlight Users can hover over or brush through any dot, circle, bar, or matrix cell in the UPD-Matrix to highlight data records with certain attribute values.: filter\n\n5.2.3 Comparisons To compare the joint distributions of the original data and the processed data: compare\n\nTo do so, users can start by viewing the UPD-Matrix to find correlation between attributes: correlate", "note": "([bar chart (N, Q, Q) OR scatter plot (N, N, Q) OR area chart (N,N,Q) ], row, column)"}, {"viewId": "vis-2957_00_1", "viewFile": "vis-2957_00_1.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "group", "type": "node"}, "link": {"field": "link", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "rect", "encoding": {"x": {"field": "feature_type", "type": "nominal"}, "color": {"field": "feature_type", "type": "nominal"}, "lightness": {"field": "feature_value", "type": "quantitative"}}}}}}, "marks": ["graph", "rect"], "channels": ["node", "link", "x", "color", "lightness"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Graphs-graphs"], "figId": "vis-2957_00", "figFile": "vis-2957_00.png", "figCaption": "", "figBox": {"x": 0.41837953266566574, "y": 0.07386920203762629, "width": 0.572024783430808, "height": 0.7528547044410638}, "figVis": ["graph"], "relationText": "", "note": ""}, {"viewId": "vis-2958_00_0", "viewFile": "vis-2958_00_0.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "number of nodes", "type": "quantitative"}, "y": {"field": "F1-score", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "number of nodes", "type": "quantitative"}, "y": {"field": "F1-score", "type": "quantitative"}}}]}, "marks": ["line", "point"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution", "consume-discover:Attributes-clusters"], "figId": "vis-2958_00", "figFile": "vis-2958_00.png", "figCaption": "", "figBox": {"x": 0.26967355238925733, "y": 0.47524600660924715, "width": 0.18104321872894197, "height": 0.4870980411027145}, "figVis": ["line_chart", "scatterplot"], "relationText": "This provides an overview of the candidates in terms of quantitative characteristics and may reveal patterns such as discontinuities or clusters caused by distinct parameter settings, e.g., the inclusion of important features: cluster\n\nThe scatter plot then supports comparing the impact of parameter changes at three levels of locality: compare", "note": ""}, {"viewId": "vis-2958_00_1", "viewFile": "vis-2958_00_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"concat": {"layout": "horizontal"}, "spec": [{"mark": "sankey", "encoding": {"node": {"field": "age value range", "type": "node", "encoding": {"color": {"field": "matrital status", "type": "nominal"}}}, "link": {"field": "belonging", "type": "relation"}}}, {"mark": "rect", "encoding": {"y": {"field": "true class", "type": "nominal"}, "x": {"field": "predicted class", "type": "nominal"}, "color": {"aggregate": "count", "type": "nominal"}}}]}, {"facet": {"column": {"field": "pattern_type", "type": "nominal"}}, "spec": {"mark": "treemap", "encoding": {"node": {"field": "age value range", "type": "node", "encoding": {"color": {"field": "matrital status", "type": "nominal"}}}, "link": {"field": "belonging", "type": "relation"}}}}]}, "marks": ["sankey", "rect", "treemap"], "channels": ["node", "link", "color", "y", "x"], "dataTypes": ["node", "relation", "nominal"], "compositions": ["concat", "facet"], "aggregates": ["count"], "actionTargets": ["query-compare:Graphs-links/paths", "query-identify:Graphs-graphs"], "figId": "vis-2958_00", "figFile": "vis-2958_00.png", "figCaption": "", "figBox": {"x": 0.46887388266076807, "y": 0.09232240967265265, "width": 0.38119863371938817, "height": 0.8942141657090467}, "figVis": ["sankey_diagram", "treemap"], "relationText": "In order to foster a quick identification of suitable trees (G3), TreePOD supports an effective quantitative and qualitative comparison of model alternatives. In order to further increase the user confidence in the selected model (G4): {suitable trees} retrieve value, compare", "note": ""}, {"viewId": "vis-2964_00_0", "viewFile": "vis-2964_00_0.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "rule", "type": "node", "encoding": {"color": {"field": "rule_type", "type": "nominal"}}}, "link": {"field": "influence", "type": "relation", "encoding": {"width": {"aggregate": "count", "type": "quantitative"}}}}}, "marks": ["graph"], "channels": ["node", "link", "color", "width"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "consume-discover:Attributes-clusters"], "figId": "vis-2964_00", "figFile": "vis-2964_00.png", "figCaption": "", "figBox": {"x": 0.009332761804467985, "y": 0.0039091828522121825, "width": 0.6953458719177033, "height": 0.9864199052695402}, "figVis": ["graph"], "relationText": "To convey the density of information necessary for the accurate analysis of the data, we encode both data that is produced directly by the simulation and data derived from that simulation.: distribution\n\nClustering is helpful for grouping rules together and aids the user in\nunderstanding how rules operate together.: cluster\n\nInteractive Filtering We also allow for the interactive filtering of links by their influence value to help handle larger datasets.: filter", "note": ""}, {"viewId": "vis-2964_00_1", "viewFile": "vis-2964_00_1.png", "specification": {"facet": {"row": {"field": "feature_type", "type": "nominal"}}, "spec": {"mark": "line", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "feature_type2", "type": "nominal"}}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2964_00", "figFile": "vis-2964_00.png", "figCaption": "", "figBox": {"x": 0.7172984807871527, "y": 0.014171240675169923, "width": 0.2745271989600152, "height": 0.9647434438184176}, "figVis": ["bar_chart", "line_chart"], "relationText": "The Rule Influence Charts show global trends in the simulation for a single rule, rather than the entire system: correlate", "note": ""}, {"viewId": "vis-2965_03_0", "viewFile": "vis-2965_03_0.png", "specification": {"nested": {"parent": {"mark": "sankey", "encoding": {"node": {"field": "stage", "type": "node"}, "link": {"field": "stage clustering relation", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "unit", "encoding": {"unit": {"field": "events", "type": "node"}, "color": {"field": "event type", "type": "nominal"}}}}}}, "marks": ["sankey", "unit"], "channels": ["node", "link", "unit", "color"], "dataTypes": ["node", "relation", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["query-identify:Attributes-similarity", "consume-present:Attributes-correlation", "consume-present:Graphs-clusters/groups", "query-identify:Attributes-values", "query-compare:Graphs-clusters/groups"], "figId": "vis-2965_03", "figFile": "vis-2965_03.png", "figCaption": "", "figBox": {"x": 0.4940083022750976, "y": 0.08094214738941312, "width": 0.4867994652430802, "height": 0.6178746468843804}, "figVis": ["sankey_diagram"], "relationText": "T2 Differentiate between different thread evolution patterns. The visualization should be able to reveal the details about how threads evolve from stage to stage.: correlate\n\nGroups of threads may relate to similar sets of events and entities at various stages, so the visualization should be able to group similar threads and separate threads that are more distinct.: cluster\n\nThis design helps users identify latent stage categories within each stage, as well as distinguish between different evolution patterns as evidenced by the merging and diverging of categories. (T2).: compare", "note": "((timestamp, matrix row, matrix column, colors), overall evolution)"}, {"viewId": "vis-2965_03_1", "viewFile": "vis-2965_03_1.png", "specification": {"facet": {"row": {"field": "sequence", "type": "nominal"}}, "spec": {"mark": "unit", "encoding": {"unit": {"field": "event", "type": "node"}, "color": {"field": "event type", "type": "nominal"}, "length": {"field": "time span", "type": "quantitative"}}}}, "marks": ["unit"], "channels": ["unit", "color", "length"], "dataTypes": ["node", "nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2965_03", "figFile": "vis-2965_03.png", "figCaption": "", "figBox": {"x": 0.4994529049597775, "y": 0.7518560912837222, "width": 0.4851037373070755, "height": 0.24283183892778396}, "figVis": ["others"], "relationText": "More specifically, the event flow view (Fig. 4(2)) shows an aggregate representation of raw event sequence data for the selection. {raw event sequence} retrieve value", "note": "((timestamp, event type), sequence)"}, {"viewId": "vis-2965_03_2", "viewFile": "vis-2965_03_2.png", "specification": {"mark": "treemap", "encoding": {"node": {"field": "thread", "type": "node", "color": {"field": "event type", "type": "nominal"}}, "link": {"field": "thread inclusion", "type": "relation"}}}, "marks": ["treemap"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-2965_03", "figFile": "vis-2965_03.png", "figCaption": "", "figBox": {"x": 0.3325480620209192, "y": 0.07499389962217909, "width": 0.1586054263538238, "height": 0.32009209084883755}, "figVis": ["treemap"], "relationText": "We employ the visual design of DICON [5] in the overview panel (as shown in Fig. 4(6)) to simplify the comparison of event occurrence probabilities across threads (T3).: compare", "note": ""}, {"viewId": "vis-2965_03_3", "viewFile": "vis-2965_03_3.png", "specification": {"facet": {"row": {"field": "patient", "type": "nominal"}}, "spec": {"mark": "unit", "encoding": {"unit": {"field": "event", "type": "node"}, "color": {"field": "event type", "type": "nominal"}}}}, "marks": ["unit"], "channels": ["unit", "color"], "dataTypes": ["node", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2965_03", "figFile": "vis-2965_03.png", "figCaption": "", "figBox": {"x": 0.3287712105383004, "y": 0.40115701263421905, "width": 0.15912882304649612, "height": 0.5979209944502021}, "figVis": ["graph"], "relationText": "T4 Provide easy access to raw event data.\n\nEntity List. The entity list view provides users with easy access to entity profiles and raw event sequences (T4).: {entity profiles and raw event sequences} retrive value", "note": ""}, {"viewId": "vis-2966_00_0", "viewFile": "vis-2966_00_0.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "entity", "type": "node", "color": {"field": "entity type", "type": "nominal"}}, "link": {"field": "labelling", "type": "relation", "width": {"aggregate": "count", "field": "labelling", "type": "quantitative"}}}}, "marks": ["graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": ["count"], "actionTargets": ["search-lookup:Graphs-nodes"], "figId": "vis-2966_00", "figFile": "vis-2966_00.png", "figCaption": "", "figBox": {"x": 0.4512631058236578, "y": 0.008948008651667824, "width": 0.5441088792404257, "height": 0.4812512205906568}, "figVis": ["graph"], "relationText": "In addition, the analyst can select or filter a specific type of entity shown in the Graph view by using the check boxes for the entity types located at the top of the view.: filter", "note": ""}, {"viewId": "vis-2966_00_1", "viewFile": "vis-2966_00_1.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "graph", "encoding": {"node": {"field": "entity", "type": "node"}, "link": {"field": "labelling", "type": "relation"}}}]}, "marks": ["geoshape", "graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": ["layer"], "aggregates": [], "actionTargets": [], "figId": "vis-2966_00", "figFile": "vis-2966_00.png", "figCaption": "", "figBox": {"x": 0.45067635080238505, "y": 0.49963333392421566, "width": 0.542977175910648, "height": 0.2332721145579275}, "figVis": ["map", "graph"], "relationText": "In the Map view, an analyst or worker is able to identify and track the Location entities on a map.: {location entities} retrieve value", "note": ""}, {"viewId": "vis-2966_00_2", "viewFile": "vis-2966_00_2.png", "specification": {"facet": {"column": {"field": "time", "type": "temporal"}}, "spec": {"mark": "unit", "encoding": {"unit": {"field": "entity", "type": "node"}}}}, "marks": ["unit"], "channels": ["unit"], "dataTypes": ["node"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2966_00", "figFile": "vis-2966_00.png", "figCaption": "", "figBox": {"x": 0.4529907202811489, "y": 0.7413311077294289, "width": 0.5418062570116062, "height": 0.247112182305141}, "figVis": ["scatterplot"], "relationText": "The Timeline view focuses on visualizing the temporal aspects of each link.", "note": ""}, {"viewId": "vis-2966_00_3", "viewFile": "vis-2966_00_3.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "worker", "type": "nominal"}, "y": {"condition_1": {"test": "show the number of links created by workers", "value": {"field": "link"}}, "condition_2": {"test": "show the number of times an entity was included in a relationship", "value": {"field": "entity included"}}, "aggregate": "count", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["search-explore:Attributes-extremes", "consume-present:Attributes-order"], "figId": "vis-2966_00", "figFile": "vis-2966_00.png", "figCaption": "", "figBox": {"x": 0.06717542935632458, "y": 0.005019598432922909, "width": 0.38040172641318387, "height": 0.10564264504073494}, "figVis": ["bar_chart"], "relationText": "The visualization can show either the number of links created by each worker, sorted by count, or the number of times an entity was included in a relationship. This allows the analyst to look for important entities, or to evaluate the work of individual crowdworkers based on their productivity: find extremum", "note": ""}, {"viewId": "vis-2967_03_0", "viewFile": "vis-2967_03_0.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "graph", "encoding": {"node": {"field": "POI", "type": "node", "encoding": {"x": {"field": "person_position_x", "type": "quantitative"}, "y": {"field": "person_position_y", "type": "quantitative"}, "icon": {"field": "person", "type": "nominal", "remark": "though labels are not explicitly shown in the view, to keep coherent with the storyline view, we also mention it here."}}}, "link": {"field": "movement", "type": "relation", "encoding": {"color": {"field": "person_group", "type": "nominal"}}}}}]}, "marks": ["geoshape", "graph"], "channels": ["node", "link", "x", "y", "icon", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Graphs-links/paths"], "figId": "vis-2967_03", "figFile": "vis-2967_03.png", "figCaption": "", "figBox": {"x": 0.01072618373929186, "y": 0.5056079619229341, "width": 0.40908272384140176, "height": 0.48901816042631296}, "figVis": ["map"], "relationText": "The locations and trajectories of individuals are plotted on the map to provide geospatial context: view raw trajectories.: {locations, trajectories} retrieve value", "note": "(x, y, person, color for class)"}, {"viewId": "vis-2967_03_1", "viewFile": "vis-2967_03_1.png", "specification": {"mark": "line", "encoding": {"color": {"field": "person_group", "type": "nominal"}, "x": {"field": "time", "type": "temporal"}, "y": {"field": "interaction_context", "type": "nominal", "remark": "y-coordinate encodes the interaction context and has a consistent meaning over time"}}}, "marks": ["line"], "channels": ["color", "x", "y"], "dataTypes": ["nominal", "temporal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-correlation"], "figId": "vis-2967_03", "figFile": "vis-2967_03.png", "figCaption": "", "figBox": {"x": 0.011754530635054335, "y": 0.09103706707998879, "width": 0.9843132589040683, "height": 0.3926548143694348}, "figVis": ["storyline"], "relationText": "Entities\u2019 similarity over time are shown with the storyline visualization. In this view, the aesthetic design alternative is shown: cluster, correlate", "note": "(time, places (are abstracted from exact(x,y)coordinates to general neighborhoods), person, class)"}, {"viewId": "vis-2969_06_0", "viewFile": "vis-2969_06_0.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "line_of_text", "type": "node"}, "link": {"field": "alignment_of_lines", "type": "relation"}}}, "marks": ["graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Graphs-links/paths", "query-compare:Graphs-nodes"], "figId": "vis-2969_06", "figFile": "vis-2969_06.png", "figCaption": "", "figBox": {"x": 0.014169042487822987, "y": 0.01849115877159474, "width": 0.21949029962345556, "height": 0.2537520644109508}, "figVis": ["parallel_coordinate"], "relationText": "To produce a rough overview of alignmentpatterns throughout the observed text versions, we dimensionality reductionaw a miniature representation for each version in the form of a vertical bar reflecting its number of verse lines in contrast to the other shown versions: compare\n\nVia mouseclick on a vertical bar, the user jumps to a desired section of thecorresponding version, which also updates the meso reading view: filter", "note": ""}, {"viewId": "vis-2969_06_1", "viewFile": "vis-2969_06_1.png", "specification": {"nested": {"parent": {"mark": "sankey", "encoding": {"node": {"field": "line_of_text", "type": "node"}, "link": {"field": "alignment_of_lines", "type": "relation", "color": {"field": "alignment_iteration", "type": "nominal"}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "rect", "encoding": {"x": {"field": "word", "type": "nominal"}, "color": {"field": "word", "aggregate": "count", "type": "quantitative"}, "text": {"field": "is_stopword", "type": "nominal"}}}, {"mark": "text", "encoding": {"text": {"field": "line_of_text", "type": "ordinal"}}}]}}}}, "marks": ["sankey", "rect", "text"], "channels": ["node", "link", "x", "color", "text"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["nested", "concat"], "aggregates": ["count"], "actionTargets": ["consume-present:Graphs-graphs"], "figId": "vis-2969_06", "figFile": "vis-2969_06.png", "figCaption": "", "figBox": {"x": 0.2858779390111071, "y": 0.012820547342737248, "width": 0.5846691924372648, "height": 0.2636516904840203}, "figVis": ["heatmap", "graph"], "relationText": "The visualization is able to convey more complex patterns of textual relationship across versions that are impossible tobe visualized in a single text view: correlate?", "note": "[(column, row, cell value, flow), (row, meso reading)]"}, {"viewId": "vis-2969_06_2", "viewFile": "vis-2969_06_2.png", "specification": {"mark": "sankey", "encoding": {"node": {"field": "word", "type": "node", "x": {"field": "word", "type": "ordinal"}}, "link": {"field": "word_relation", "type": "relation", "color": {"field": "unknown", "type": "nominal"}}}}, "marks": ["sankey"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2969_06", "figFile": "vis-2969_06.png", "figCaption": "", "figBox": {"x": 0.6673178273312138, "y": 0.19191738814555795, "width": 0.31692802464535663, "height": 0.07124163911267291}, "figVis": ["flow_diagram"], "relationText": "The medievalist wanted both graphs to be juxtaposed in order to get an immediate justification for the computed alignment of variant spellings -> {computed alignment} retrieve value", "note": "The color of links is not described in the paper."}, {"viewId": "vis-2970_01_0", "viewFile": "vis-2970_01_0.png", "specification": {"mark": "rect", "encoding": {"y": {"field": "feature", "type": "nominal"}, "x": {"field": "time", "type": "temporal"}, "color": {"field": "feature_value", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "temporal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-values", "query-identify:Attributes-extremes"], "figId": "vis-2970_01", "figFile": "vis-2970_01.png", "figCaption": "", "figBox": {"x": 0.08408474203848151, "y": 0.04282476200332281, "width": 0.446638304204522, "height": 0.29893917955823524}, "figVis": ["heatmap"], "relationText": "Figure 2 (a-c) shows the three views depicting the time-varying statistics of respective nations: correlate\n\nR2. quickly identify important events in a game: extremum", "note": "heatmap"}, {"viewId": "vis-2970_01_1", "viewFile": "vis-2970_01_1.png", "specification": {"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "death", "aggregate": "count", "type": "quantitative"}, "color": {"field": "nation", "type": "nominal"}}}, "marks": ["area"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-values", "query-identify:Attributes-extremes"], "figId": "vis-2970_01", "figFile": "vis-2970_01.png", "figCaption": "", "figBox": {"x": 0.08843758153672167, "y": 0.8212846602099337, "width": 0.43939445523353865, "height": 0.09304939901953693}, "figVis": ["area_chart"], "relationText": "Figure 2 (a-c) shows the three views depicting the time-varying statistics of respective nations: correlate\n\nR2. quickly identify important events in a game: extremum", "note": "theme river"}, {"viewId": "vis-2970_01_2", "viewFile": "vis-2970_01_2.png", "specification": {"facet": {"row": {"field": "nation", "type": "nominal"}}, "spec": {"mark": "point", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"remark": "The vertical coordinate, however, is allocated only to prevent occlusions."}, "icon": {"field": "technique_or_building_type", "type": "nominal", "remark": "icons representing the developed techniques and the constructed buildings"}}}}, "marks": ["point"], "channels": ["x", "y", "icon"], "dataTypes": ["temporal", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-identify:Attributes-extremes"], "figId": "vis-2970_01", "figFile": "vis-2970_01.png", "figCaption": "", "figBox": {"x": 0.08552184524760605, "y": 0.33864806681910364, "width": 0.44010952272253023, "height": 0.4879310237704442}, "figVis": ["scatterplot"], "relationText": "Figure 2 (a-c) shows the three views depicting the time-varying statistics of respective nations: correlate\n\nR2. quickly identify important events in a game: extremum\n\nWhen users observe an interesting event in the status view such as a large number of dead, they can select a time span in the ThemeRiverand our system will switch to the battle view (R2): filter", "note": ""}, {"viewId": "vis-2970_01_3", "viewFile": "vis-2970_01_3.png", "specification": {"layer": [{"mark": "geoshape", "encoding": {"color": {"field": "height", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "map_x", "type": "quantitative"}, "y": {"field": "map_y", "type": "quantitative"}, "color": {"field": "nation", "type": "nominal"}}}]}, "marks": ["geoshape", "point"], "channels": ["color", "x", "y"], "dataTypes": ["quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2970_01", "figFile": "vis-2970_01.png", "figCaption": "", "figBox": {"x": -0.000827358588834352, "y": 0.5181803156984955, "width": 0.08581820620366677, "height": 0.28212070099939285}, "figVis": ["map"], "relationText": "The positions of units at the specified time span are indicated by scatter points on this map: raw data retrieval", "note": ""}, {"viewId": "vis-2970_01_4", "viewFile": "vis-2970_01_4.png", "specification": {"layer": [{"mark": "geoshape", "encoding": {"color": {"field": "height", "type": "quantitative"}}}, {"mark": "surface", "encoding": {"x": {"field": "map_x", "type": "quantitative"}, "y": {"field": "map_y", "type": "quantitative"}, "color": {"field": "nation", "type": "nominal"}, "surface": {"field": "unit", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "map_x", "type": "quantitative"}, "y": {"field": "map_y", "type": "quantitative"}, "icon": {"field": "resource_type", "type": "nominal"}}}, {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "unit_position_or_battle", "type": "node"}, "link": {"field": "trajectory", "type": "relation", "color_hue": {"field": "nation", "type": "nominal"}, "width": {"field": "military_strength", "type": "quantitative"}, "remark": "The shape of this curved arrow is computed by approximating a Bezier curve to the units\u2019 moving trajectories"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "military_strength", "type": "quantitative"}, "hue": {"field": "nation", "type": "nominal"}, "saturation": {"field": "ground_or_air_force", "type": "nominal"}}}}}}]}, "marks": ["geoshape", "surface", "point", "graph", "area"], "channels": ["color", "x", "y", "surface", "icon", "node", "link", "hue", "saturation"], "dataTypes": ["quantitative", "nominal", "node", "relation"], "compositions": ["layer", "nested"], "aggregates": [], "actionTargets": ["search-explore:Spatial Data-shape", "search-explore:Attributes-correlation"], "figId": "vis-2970_01", "figFile": "vis-2970_01.png", "figCaption": "", "figBox": {"x": 0.6207403017520468, "y": 0.09843544600504812, "width": 0.3783353273067233, "height": 0.8246804763475539}, "figVis": ["map", "heatmap", "glyph_based"], "relationText": "learn how to choose a good battlefield: compare\n\nFigure 2 (f) shows a map to describe the process of a battle: raw data\n\nWe visualize the battle in a hierarchical manner. When users zoom the map out, where dimensionality reductionawing individual units must result in serious visual clutter, we visualize the battle by shadings, glyphs, and trajectories: derived value", "note": "(x, y, [height, glyph:(nation, force, time, value), trajectory:(T, width), shading of nation: (N, Q)])"}, {"viewId": "vis-2970_01_5", "viewFile": "vis-2970_01_5.png", "specification": {"facet": {"row": {"field": "nation", "type": "nominal"}, "color": {"field": "nation", "type": "nominal"}}, "spec": {"facet": {"row": {"field": "type_of_unit", "type": "nominal"}}, "spec": {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "military_strength", "type": "quantitative"}}}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-2970_01", "figFile": "vis-2970_01.png", "figCaption": "", "figBox": {"x": 0.5317141316658786, "y": 0.0828396350966091, "width": 0.08129290919246539, "height": 0.48949883608437916}, "figVis": ["line_chart"], "relationText": "In addition, we apply a line chart to depict the military strength (derived value) of units of each type over time, and some icons to indicate respective techniques that can be used during battle (Figure 2 (g)): derived value, correlate", "note": ""}, {"viewId": "vis-2972_05_0", "viewFile": "vis-2972_05_0.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "message", "type": "nominal", "aggregate": "count"}, "color": {"field": "message", "type": "nominal", "aggregate": "count"}}}]}, "marks": ["bar", "rect"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["query-identify:Attributes-correlation", "query-compare:Attributes-correlation"], "figId": "vis-2972_05", "figFile": "vis-2972_05.png", "figCaption": "", "figBox": {"x": 0.4878259433904215, "y": 0.02432642605287139, "width": 0.48265370415810604, "height": 0.5640226348438698}, "figVis": ["bar_chart", "heatmap"], "relationText": "The temporal view (Figure 6b) allows users to examine the temporal patterns of individual keywords: correlate\n\nKeywords of an event are lined up vertically and ordered by the time they first appear: sort\n\nThe keywords are color-coded by their peaking time of appearance to aid in their comparison.", "note": "double encoding"}, {"viewId": "vis-2972_05_1", "viewFile": "vis-2972_05_1.png", "specification": {"mark": "others", "encoding": {"city": {"field": "discussion keyword"}, "town": {"field": "messages with high affiliations to a specific city"}, "region": {"field": "A region has only one city (one discussion keyword), but many affiliated towns (messages)."}, "continent_and_island": {"field": "Large connected regions form continents, while smaller, isolated regions create islands."}, "river": {"field": "A river in a map symbolizes the connection of heavy reposting relations between regions."}}}, "marks": ["others"], "channels": ["city", "town", "region", "continent_and_island", "river"], "dataTypes": [], "compositions": [], "aggregates": [], "actionTargets": [], "figId": "vis-2972_05", "figFile": "vis-2972_05.png", "figCaption": "", "figBox": {"x": 0.10456864768807908, "y": 0.0538328966645919, "width": 0.2541802155243165, "height": 0.5020071780153862}, "figVis": ["map"], "relationText": "In E-Map constructed from the unstructured social media messages, a city is represented by a keyword extracted from events, where color gradient conveys the temporal evolution of events (a). The towns surrounding the city are shaped by the messages of specific keywords. Rivers represent highlighted social media users\u2019 behaviors of reposting (e.g. retweeting) (b). Users\u2019trajectories and connections on the map encode the user behaviors of discussing different themes (curved black trajectories) and the information diffusion directions (straight gray connections). : The map is constructed using derived values\n\nUsers can brush a region on the map, or select cities or the trajectories to feed information to the keyword reposting view: filter\n\nGrouping messages based on their similarity: cluster\n\nreposting relationship: graph", "note": "((timestamp,topic,userId),repost relation)#. The original data is transformed with shape distortion for visual encoding."}, {"viewId": "vis-2972_05_2", "viewFile": "vis-2972_05_2.png", "specification": {"mark": "tree", "encoding": {"node": {"field": "keyword", "type": "node", "size": {"field": "message_contain_keyword", "aggregate": "count", "type": "quantitative"}}, "link": {"field": "hierarchy", "type": "relation"}}}, "marks": ["tree"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": ["count"], "actionTargets": ["query-identify:Graphs-links/paths"], "figId": "vis-2972_05", "figFile": "vis-2972_05.png", "figCaption": "", "figBox": {"x": 0.03715667006645964, "y": 0.03757775469939926, "width": 0.06951867911301236, "height": 0.5315149463407304}, "figVis": ["tree"], "relationText": "They can also select a particular town to see the raw message content, and when the message is posted and by whom (Figure 6e-S1, S2, S3): raw data\n\nThe size of a circle is tied to the number of messages containing the keyword. This view can show the information diffusion process involving different keywords (Figure 6e).: diffusion for graph-related", "note": "(parent/current/child, words, link, size of a circle)"}, {"viewId": "vis-2972_05_3", "viewFile": "vis-2972_05_3.png", "specification": {"facet": {"row": {"field": "user", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "message", "type": "nominal", "aggregate": "count"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["temporal", "nominal"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["search-explore:Attributes-correlation"], "figId": "vis-2972_05", "figFile": "vis-2972_05.png", "figCaption": "", "figBox": {"x": 0.3578251336052366, "y": 0.2687948421026438, "width": 0.12892435847109976, "height": 0.10360970099221962}, "figVis": ["bar_chart"], "relationText": "To enable detailed exploration, we provide a one-dimensional sequence view to visualize the trajectory of important users (Figure 6f). Each rectangle represents a city that an individual user visited. The x-axis reflects the temporal order, and the height represents the message amount from a specific visit: correlate", "note": "(user, ordered city, message)"}, {"viewId": "vis-2973_01_0", "viewFile": "vis-2973_01_0.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "machine", "type": "node", "encoding": {"color": {"field": "ratio_in_degree", "type": "quantitative"}, "size": {"field": "degree", "aggregate": "count", "type": "quantitative"}}}, "link": {"field": "communication", "type": "relation", "encoding": {"width": {"field": "message", "aggregate": "count", "type": "quantitative"}, "color": {"field": "user-selected_metric", "type": "quantitative"}}}}}, "marks": ["graph"], "channels": ["node", "link", "color", "size", "width"], "dataTypes": ["node", "relation", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Graphs-topology/structures"], "figId": "vis-2973_01", "figFile": "vis-2973_01.png", "figCaption": "", "figBox": {"x": 0.16768750820908143, "y": 0.037405026898054985, "width": 0.41940266283118477, "height": 0.9543201078334458}, "figVis": ["graph"], "relationText": "The communication view shows an overview of the communications:\n\nGraph related: network structure\nDerive value: total in/out degree, total number of message, ratio of in/out degree and etc.", "note": "(x, y, [Graph, (color node, size node), (color in_edge, color out_edge, width edge)])"}, {"viewId": "vis-2973_01_1", "viewFile": "vis-2973_01_1.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "user-selected_metric", "type": "quantitative"}, "color": {"field": "user-selected_metric", "type": "quantitative"}, "y": {"field": "rank", "type": "ordinal"}, "height": {"field": "rank", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["x", "color", "y", "height"], "dataTypes": ["quantitative", "ordinal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-extremes"], "figId": "vis-2973_01", "figFile": "vis-2973_01.png", "figCaption": "", "figBox": {"x": 0.0016841647128490753, "y": 0.06098122603968656, "width": 0.16769634087602278, "height": 0.925677334968899}, "figVis": ["bar_chart"], "relationText": "The metric rank view shows metrics related to communication, ranked by decreasing value: sort\n\nderived values: various metrics including length of routes, message size, and hop-bytes, as well as load on links and in-/out-degree of nodes\n\nThe metric rank view can also be used as an interface to filter the nodes, routes, and the links to be displayed in the other views: filter", "note": "(order, bar height, bar width)"}, {"viewId": "vis-2973_01_2", "viewFile": "vis-2973_01_2.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "machine", "type": "nominal"}, "y": {"field": "machine", "type": "nominal"}, "color": {"field": "source_and_destination", "type": "nominal"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-topology/structures"], "figId": "vis-2973_01", "figFile": "vis-2973_01.png", "figCaption": "", "figBox": {"x": 0.5922247561054805, "y": 0.17800084205386357, "width": 0.39208563697021265, "height": 0.7935343141271353}, "figVis": ["matrix"], "relationText": "The detailed route view conveys coordinates of compute nodes in the physical topology by using an adjacency matrix: raw values, correlate", "note": "((x, y, grey/white/black, color/shape of node), (G, color of edge))"}, {"viewId": "vis-2974_00_0", "viewFile": "vis-2974_00_0.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "variable", "type": "node", "encoding": {"border": {"field": "goodness_of_fit", "type": "quantitative"}}}, "link": {"field": "causality_relation", "type": "relation", "encoding": {"width": {"field": "strength", "type": "quantitative"}, "color": {"field": "type", "type": "nominal"}}}}}, "marks": ["graph"], "channels": ["node", "link", "border", "width", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["search-explore:Graphs-graphs"], "figId": "vis-2974_00", "figFile": "vis-2974_00.png", "figCaption": "", "figBox": {"x": 0.19983648679066554, "y": 0.0819669962764554, "width": 0.5029764025481905, "height": 0.48389224516928736}, "figVis": ["graph"], "relationText": " allow the visual analysis of both causation and correlation.: correlate", "note": ""}, {"viewId": "vis-2974_00_1", "viewFile": "vis-2974_00_1.png", "specification": {"mark": "line", "remark": "parallel coordinate plot", "encoding": {"x": {"field": "variable", "type": "nominal"}, "y": {"field": "variable_value", "type": "quantitative"}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-clusters"], "figId": "vis-2974_00", "figFile": "vis-2974_00.png", "figCaption": "", "figBox": {"x": 0.010173852862704226, "y": 0.6906447056865688, "width": 0.671883738544401, "height": 0.29203545896684474}, "figVis": ["parallel_coordinate"], "relationText": "To eliminate or at least reduce such disturbances and reveal the different causal models hiding in the data, an interactive parallel coordinates interface (Fig. 1c) is employed in our CSI framework. : correlate\n\nVia the parallel coordinates, users can directly observe potentially attractive data subdivisions and partition the data by adjusting the brushed value range of variables.\nConversely, data partitions can also be detected automatedly based on unique values of some variables or as data clusters recognized by clustering algorithms, using the interactive facilities shown in Fig. 1e.: cluster", "note": ""}, {"viewId": "vis-2974_00_2", "viewFile": "vis-2974_00_2.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "partition_1", "type": "nominal"}, "y": {"field": "partition_2", "type": "nominal"}, "color": {"field": "model_score", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-values"], "figId": "vis-2974_00", "figFile": "vis-2974_00.png", "figCaption": "", "figBox": {"x": 0.7068381502532664, "y": 0.5735151007958906, "width": 0.23715537009721793, "height": 0.3981574402813467}, "figVis": ["heatmap"], "relationText": "user can visually examine each model derived from a data subdivision as well as the pooled models, getting full support for decision making and hypothesis evaluation.: {model derived} compute derived value\n\nUsers can also examine other models by clicking on tiles of the heatmap.: filter", "note": ""}, {"viewId": "vis-2975_00_0", "viewFile": "vis-2975_00_0.png", "specification": {"layer": [{"facet": {"row": {"field": "date", "type": "temporal"}}, "spec": {"mark": "unit", "encoding": {"unit": {"field": "event", "type": "node"}, "color": {"field": "event type", "type": "nominal"}}}}, {"mark": "graph", "encoding": {"node": {"field": "event", "type": "node"}, "link": {"field": "connection among events", "type": "relation"}, "color": {"aggregate": "count", "field": "events encompassesing", "type": "quantitative"}}}]}, "marks": ["unit", "graph"], "channels": ["unit", "color", "node", "link"], "dataTypes": ["node", "nominal", "relation"], "compositions": ["layer", "facet"], "aggregates": ["count"], "actionTargets": ["query-identify:Graphs-links/paths", "query-identify:Graphs-nodes"], "figId": "vis-2975_00", "figFile": "vis-2975_00.png", "figCaption": "", "figBox": {"x": -4.3232959904943836e-05, "y": 0.04125169093555897, "width": 0.31444706909889364, "height": 0.9598060803585047}, "figVis": ["graph"], "relationText": "The future events overview (Figure 1A and Figure 4) is designed to present the identified events and the connections among events.: graph-related", "note": "((vertical timestamp, events), relations between the events)"}, {"viewId": "vis-2975_00_1", "viewFile": "vis-2975_00_1.png", "specification": {"layer": [{"mark": "geoshape"}, {"facet": {"x": {"field": "longitude", "type": "quantitative"}, "y": {"field": "latitude", "type": "quantitative"}}, "spec": {"mark": "arc", "encoding": {"theta": {"field": "proportion of event numbers", "type": "quantitative"}, "color": {"field": "time difference", "type": "nominal"}, "size": {"aggregate": "count", "field": "event", "type": "nominal"}}}}]}, "marks": ["geoshape", "arc"], "channels": ["theta", "color", "size"], "dataTypes": ["quantitative", "nominal"], "compositions": ["layer", "facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-2975_00", "figFile": "vis-2975_00.png", "figCaption": "", "figBox": {"x": 0.31677743607394615, "y": 0.03809243709303823, "width": 0.4722672855608026, "height": 0.578086377309015}, "figVis": ["donut_chart", "map"], "relationText": "The Map view presents information pertaining to the locations of the future events (Figure 1B): {raw information} retrive value", "note": "the ring at each location is designed to present information on how far in the future the events in one location will occur. The color assignment of the ring segments ranges from dark blue (tomorrow) to off-white (more than a month away). The number of event locations shown on the map is deter- mined by the zoom level.\n\n((pie rings, ring values, size), place)"}, {"viewId": "vis-2975_00_2", "viewFile": "vis-2975_00_2.png", "specification": {"mark": "word_cloud", "encoding": {"word": {"field": "word", "type": "nominal"}, "size": {"aggregate": "count", "field": "keyword", "type": "quantitative"}}}, "marks": ["word_cloud"], "channels": ["word", "size"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": ["count"], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-2975_00", "figFile": "vis-2975_00.png", "figCaption": "", "figBox": {"x": 0.31589255239303593, "y": 0.6245796718770186, "width": 0.2341786692677038, "height": 0.37180274808272107}, "figVis": ["word_cloud"], "relationText": "To allow users to get an overview of what the future events are about without having to read the tweets, the CrystalBall visual interface includes a Word Cloud View showing a set of keywords summarizing the events (Figure 1C). : {keywords}: retrieve value", "note": "(word, frequency)"}, {"viewId": "vis-2975_00_3", "viewFile": "vis-2975_00_3.png", "specification": {"mark": "tree", "encoding": {"node": {"field": "user", "type": "node", "color": {"field": "follower-friend ratio", "type": "quantitative"}}, "link": {"field": "social network", "type": "relation"}}}, "marks": ["tree"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-links/paths", "consume-present:Graphs-clusters/groups"], "figId": "vis-2975_00", "figFile": "vis-2975_00.png", "figCaption": "", "figBox": {"x": 0.5509732907178323, "y": 0.6234110109992349, "width": 0.23830105064159615, "height": 0.3689379032847849}, "figVis": ["graph"], "relationText": "To present relationship between the Twitter users who posted information related to future events, we construct a social network.: graph-related\n\nAt a glance, the Social Network view provides clusters of different sizes indicating the \u201cpopularity\u201d of various future events.", "note": ""}, {"viewId": "vis-2979_00_0", "viewFile": "vis-2979_00_0.png", "specification": {"layer": [{"concat": {"layout": "horizontal"}, "spec": [{"facet": {"row": {"field": "word", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "hidden_state_cluster", "type": "nominal"}, "y": {"field": "percentage_information_flowing_in", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "hidden_state_cluster", "type": "nominal"}, "bold_bound": {"field": "average_aggregate_information", "type": "quantitative"}, "y_upper": {"field": "positive_information", "type": "quantitative"}, "y_lower": {"field": "negative_information", "type": "quantitative"}, "hat_upper": {"field": "positive_updated_information", "type": "quantitative"}, "hat_lower": {"field": "negative_updated_information", "type": "quantitative"}}}]}}, {"facet": {"row": {"field": "hidden_state_unit", "type": "nominal"}}, "spec": {"mark": "unit", "encoding": {"unit": {"field": "word", "type": "node"}, "color": {"field": "response_value", "type": "quantitative"}}}}, {"facet": {"row": {"field": "word_cluster", "type": "nominal"}}, "spec": {"mark": "word_cloud", "encoding": {"word": {"field": "word", "type": "nominal"}, "size": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "POS", "type": "nominal"}}}}]}, {"mark": "sankey", "encoding": {"node": {"field": "component_type", "type": "node"}, "link": {"field": "most_responsive_cluster", "type": "relation"}, "link_width": {"field": "absolute_value_of_average_updated_information", "type": "relation"}, "link_color": {"field": "updated_information", "type": "nominal"}}}]}, "marks": ["bar", "unit", "word_cloud", "sankey"], "channels": ["x", "y", "bold_bound", "y_upper", "y_lower", "hat_upper", "hat_lower", "unit", "color", "word", "size", "node", "link", "link_width", "link_color"], "dataTypes": ["nominal", "quantitative", "node", "relation"], "compositions": ["layer", "concat", "facet"], "aggregates": ["count"], "actionTargets": ["consume-discover:Attributes-correlation", "search-explore:Attributes-values", "query-summarize:Attributes-distribution", "query-identify:Attributes-distribution"], "figId": "vis-2979_00", "figFile": "vis-2979_00.png", "figCaption": "", "figBox": {"x": 0.26277503855639556, "y": 0.04911581485066633, "width": 0.7239833321697395, "height": 0.9196361795365602}, "figVis": ["heatmap", "sankey_diagram", "word_cloud"], "relationText": "To enable sequence-level analysis of RNN (R3), we design a glyph- based sequence visualization.\nR3: That is, how does the internal memory updating mechanism of an RNN result in its specific behavior when dealing with sequences.: correlate\n\nWe visualize each hidden state unit as a small square-shaped memory cell and pack memory cells in the same cluster into a rectangular memory chip to allow exploration of details (R4). All the memory chips are vertically stacked and aligned by their centers (Fig. 1C) to present an overview of RNN\u2019s hidden state mechanisms (R2).: cluster\n\nR2: Provide the overall information distribution in hidden states. \nR4:  Examine detailed statistics of individual states. Experts also suggested that concise and detailed information, such as the distribution of hidden state values or gate activations, is required for quantitatively analysis.", "note": ""}, {"viewId": "vis-2979_00_1", "viewFile": "vis-2979_00_1.png", "specification": {"mark": "line", "encoding": {"x": {"field": "dim", "type": "ordinal"}, "y": {"field": "response", "type": "quantitative"}, "color": {"field": "word_type", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2979_00", "figFile": "vis-2979_00.png", "figCaption": "", "figBox": {"x": 0.001444399660216723, "y": 0.566990685347607, "width": 0.24233212028200063, "height": 0.19356910049282303}, "figVis": ["line_chart"], "relationText": "we show the distributions of a two-layer LSTM\u2019s responses.", "note": ""}, {"viewId": "vis-2979_00_2", "viewFile": "vis-2979_00_2.png", "specification": {"facet": {"column": {"field": "dimension", "type": "nominal"}}, "spec": {"mark": "boxplot", "encoding": {"y": {"field": "word", "type": "nominal"}, "x": {"field": "activation_distribution", "type": "quantitative"}}}}, "marks": ["boxplot"], "channels": ["y", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-2979_00", "figFile": "vis-2979_00.png", "figCaption": "", "figBox": {"x": 0.0030237077530939046, "y": 0.8081563146564403, "width": 0.2359616782222129, "height": 0.19286198044864292}, "figVis": ["box_plot"], "relationText": "When users select a hidden state unit, the activation distribution of a hidden state unit on different words will be displayed as box plots, as shown in Fig. 1(E)", "note": "(n, q#) => q# is box plot"}, {"viewId": "vis-2980_00_0", "viewFile": "vis-2980_00_0.png", "specification": {"facet": {"column": {"field": "theta", "type": "nominal"}}, "spec": {"mark": "others", "encoding": {"column": {"field": "solver", "type": "nominal"}, "row": {"field": "angle_category", "type": "nominal"}, "height": {"aggregate": "sum", "type": "quantitative"}, "color": {"field": "accuracy", "type": "quantitative"}}}}, "marks": ["others"], "channels": ["column", "row", "height", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": ["sum"], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-2980_00", "figFile": "vis-2980_00.png", "figCaption": "", "figBox": {"x": 0.14569310762371682, "y": 0.054375896470666624, "width": 0.6416290520691526, "height": 0.5937557467106206}, "figVis": ["treemap"], "relationText": "In the \u2018Question Space Angles\u2019 panel, users perform prismatic analysis; this panel allows users to filter and zoom into a finer set of questions: filter\n\nIn addition, putting evaluations as segments next to each other greatly facilitates\ncomparisons between evaluations and reflects challenge C1.: compare", "note": "each row: (n, q, q) - column, color, height"}, {"viewId": "vis-3060_00_0", "viewFile": "vis-3060_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "confusion_type", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "prediction_score", "type": "quantitative"}}}]}, "marks": ["bar", "point"], "channels": ["x", "color", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["query-summarize:Attributes-outliers", "query-summarize:Attributes-clusters", "search-browse:Attributes-values"], "figId": "vis-3060_00", "figFile": "vis-3060_00.png", "figCaption": "", "figBox": {"x": 0.014091026020296197, "y": 0.0450915299634547, "width": 0.19678005870077164, "height": 0.4590334186749335}, "figVis": ["scatterplot", "matrix"], "relationText": "As we design the Data Overview mainly for users to obtain an overall picture on data clusters and outliers (T5), we select dimension reduction methods to display the training data for a better scalability. : cluster, anomaly\n\nThen, we dimensionality reductionaw a confusion matrix to help users observe the model\u2019s performance on these data and enable users to filter certain data subsets (T7). Finally, we display a data table that allows users to easily browse the whole training dataset.: filter", "note": ""}, {"viewId": "vis-3060_00_1", "viewFile": "vis-3060_00_1.png", "specification": {"facet": {"row": {"field": "feature_type", "type": "nominal"}, "color": {"field": "feature_type", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "split_point", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "feature_values", "type": "quantitative"}, "y": {"field": "predict_score", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "feature_values", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}}]}}, "marks": ["bar", "line"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["query-identify:Attributes-extremes", "query-identify:Attributes-correlation"], "figId": "vis-3060_00", "figFile": "vis-3060_00.png", "figCaption": "", "figBox": {"x": 0.2113070797186808, "y": 0.012202257023898844, "width": 0.17657749453999386, "height": 0.9734590711588502}, "figVis": ["bar_chart", "line_chart"], "relationText": "For example, users may want to know which features are most important for a model and how feature values affect predictions (T1). In addition, the split point distribution of each feature (T2) and the training data value distribution (T6) also reflect the relationships between features and predictions. Therefore, we design the Feature View to reveal such information and facilitate users\u2019 understanding of random forest models.", "note": ""}, {"viewId": "vis-3060_00_2", "viewFile": "vis-3060_00_2.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "prediction_score", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-similarity"], "figId": "vis-3060_00", "figFile": "vis-3060_00.png", "figCaption": "", "figBox": {"x": 0.3937697701862737, "y": 0.040591722528723465, "width": 0.15026606110669513, "height": 0.3441209755297384}, "figVis": ["scatterplot"], "relationText": "Decision Path Projection. Since a single prediction in random forests is generated based on the results of many individual decision paths, we aim to provide users with an overview of these decision paths (T3). Similar to the Data Overview, we use t-SNE to project all the decision paths onto a 2D plane (Fig. 3a) as circles so that users can easily observe their similarities. ", "note": ""}, {"viewId": "vis-3060_00_3", "viewFile": "vis-3060_00_3.png", "specification": {"facet": {"row": {"field": "feature_type", "type": "nominal"}, "color": {"field": "feature_type", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "quantitative", "bin": "true"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["query-summarize:Graphs-links/paths"], "figId": "vis-3060_00", "figFile": "vis-3060_00.png", "figCaption": "", "figBox": {"x": 0.54468908874245, "y": 0.0405526359688229, "width": 0.09029452935283341, "height": 0.3399263190628257}, "figVis": ["bar_chart"], "relationText": "Feature Summary. For the decision paths that have been selected in the Decision Path Projection, their features and corresponding ranges are summarized in Feature Summary. Specially, each feature occurred in the selected paths is represented using a Feature Cell in a list format (Fig. 3b). ", "note": ""}, {"viewId": "vis-3060_00_4", "viewFile": "vis-3060_00_4.png", "specification": {"nested": {"parent": {"mark": "sankey", "encoding": {"node": {"field": "attribute_type", "type": "node"}, "link": {"field": "decision_path", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "bar", "encoding": {"x": {"field": "attribute_value", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}}}}}, "marks": ["sankey", "bar"], "channels": ["node", "link", "x", "y"], "dataTypes": ["node", "relation", "quantitative"], "compositions": ["nested"], "aggregates": ["count"], "actionTargets": ["consume-present:Graphs-topology/structures", "query-identify:Attributes-clusters"], "figId": "vis-3060_00", "figFile": "vis-3060_00.png", "figCaption": "", "figBox": {"x": 0.6354674085196714, "y": 0.04051354940892257, "width": 0.3584512329484645, "height": 0.33573166259591514}, "figVis": ["bar_chart", "sankey_diagram", "pie_chart"], "relationText": "Decision Path Flow. The Decision Path Flow aims at revealing the structures and properties of multiple decision paths at the layer level. This enables users to examine the orders of the features appeared in different decision paths, which is critical in measuring feature importance. ", "note": ""}, {"viewId": "vis-3061_00_0", "viewFile": "vis-3061_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-clusters"], "figId": "vis-3061_00", "figFile": "vis-3061_00.png", "figCaption": "", "figBox": {"x": 0.20509626176626386, "y": 0.5839548454932729, "width": 0.13609590114251038, "height": 0.2894390631591551}, "figVis": ["scatterplot", "contour_graph"], "relationText": "The scatterplot provides a two-dimensional projection of the data obtained using dimensionality reduction and encodes clustering assignments through color. Since clustering algorithms divide data into discrete groups based on similarity, projections are a natural way to represent different degrees of variation within and between groups\nas distance between elements (D1). Each cluster of points can also be identified by a colored convex hull, simplifying the visualization in cases with larger numbers of data points (D8).", "note": ""}, {"viewId": "vis-3061_00_1", "viewFile": "vis-3061_00_1.png", "specification": {"mark": "rect", "encoding": {"y": {"field": "feature", "type": "nominal"}, "x": {"field": "cluster", "type": "nominal"}, "color": {"field": "feature_distribution", "aggregate": "average", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": ["average"], "actionTargets": ["query-summarize:Attributes-clusters", "consume-present:Attributes-distribution"], "figId": "vis-3061_00", "figFile": "vis-3061_00.png", "figCaption": "", "figBox": {"x": 0.33893616507176777, "y": 0.5831342755950939, "width": 0.15141931909601766, "height": 0.3045599557092782}, "figVis": ["heatmap", "matrix"], "relationText": "The heatmap visualizes each cluster based on the aggregate feature values of the data points in the cluster. Each column of the matrix represents a cluster; rows represent data features (dimensions). The color of each cell encodes the average value of cluster members for a specific feature with respect to the feature distribution.", "note": ""}, {"viewId": "vis-3061_00_2", "viewFile": "vis-3061_00_2.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, {"mark": "rect", "encoding": {"y": {"field": "feature", "type": "nominal"}, "x": {"field": "cluster", "type": "nominal"}, "color": {"field": "feature distribution", "type": "quantitative"}}}]}, "marks": ["point", "rect"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["search-explore:Attributes-clusters"], "figId": "vis-3061_00", "figFile": "vis-3061_00.png", "figCaption": "", "figBox": {"x": 0.5076273100573606, "y": 0.5278092694985603, "width": 0.2929268272758167, "height": 0.35936527792244755}, "figVis": ["heatmap", "matrix", "scatterplot", "table"], "relationText": "With this concept in mind, we introduce a Clustering Tour feature to help the user quickly explore the space of possible clustering outcomes. The interface shown in Fig. 6 contains (a) a list of previously explored solutions, (b) a scatterplot and a heatmap representing the current solution, (c) a set of\nbuttons for the user to give feedback, and (d) a choice of modalities by which the user can constrain how parameters are updated.: {previously solution} retrieve value", "note": "(scatter, matrix)"}, {"viewId": "vis-3062_00_0", "viewFile": "vis-3062_00_0.png", "specification": {"facet": {"column": {"field": "class (Ck)", "type": "nominal"}, "row": {"field": "model_pair (Mi, Mj)", "type": "nominal"}}, "spec": {"mark": "point", "encoding": {"x": {"field": "Mi_prediction_score", "type": "quantitative"}, "y": {"field": "Mj_prediction_score", "type": "quantitative"}, "color": {"field": "ground_truth_is_Ck_or_not", "type": "nominal"}}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3062_00", "figFile": "vis-3062_00.png", "figCaption": "", "figBox": {"x": 0.011860632384827199, "y": 0.01315952751428564, "width": 0.34270923281872706, "height": 0.9319666954388206}, "figVis": ["scatterplot", "matrix"], "relationText": "Manifold visualizes this multi-dimensional space with an emphasis on the visual comparison of model pairs as pair-wise comparison is an intuitive form of comparison and requires relatively little cognitive workload. The knowledge gathered from multiple model pairs can then be composed to generate a holistic understanding of the entire model space.", "note": ""}, {"viewId": "vis-3062_00_1", "viewFile": "vis-3062_00_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"facet": {"column": {"field": "class (Ck)", "type": "nominal"}}, "spec": {"mark": "area", "encoding": {"y": {"field": "KL-divergence", "type": "quantitative"}}}}, {"facet": {"column": {"field": "class (Ck)", "type": "nominal"}, "row": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "y": {"field": "gt_or_not", "type": "nominal"}, "color": {"field": "gt_or_not", "type": "nominal"}}}}]}, "marks": ["area", "bar"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "facet"], "aggregates": ["count"], "actionTargets": ["query-identify:Attributes-extremes"], "figId": "vis-3062_00", "figFile": "vis-3062_00.png", "figCaption": "", "figBox": {"x": 0.37260508768241946, "y": 0.013159527514285632, "width": 0.34649964148357826, "height": 0.9319666954388196}, "figVis": ["area_chart", "bar_chart"], "relationText": "This sorting operation allows the user to identify prominent features of the selected subset.: sort", "note": ""}, {"viewId": "vis-3063_03_0", "viewFile": "vis-3063_03_0.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "model_node", "type": "node"}, "link": {"field": "model_overview", "type": "relation"}}}, "child": {"child_type": "exemplified", "canvas": "node", "example": [{"mark": "point", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}}}, {"mark": "surface", "encoding": {"x": {"field": "dimension_3", "type": "quantitative"}, "y": {"field": "dimension_4", "type": "quantitative"}, "surface": {"field": "probability_density", "type": "quantitative"}}}]}}}, "marks": ["graph", "point", "surface"], "channels": ["node", "link", "x", "y", "surface"], "dataTypes": ["node", "relation", "quantitative"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "query-summarize:Graphs-topology/structures"], "figId": "vis-3063_03", "figFile": "vis-3063_03.png", "figCaption": "", "figBox": {"x": 0.010354781934589842, "y": 0.16542124920466286, "width": 0.5032766927145865, "height": 0.8217688942997022}, "figVis": ["flow_diagram", "scatterplot", "heatmap", "surface_graph"], "relationText": "Our visualization technique aligns with the continuous scatterplots idea [3] that generalizes scatterplots to continuous data by computing the density of data samples in the scatterplot space.: {density} distribution", "note": ""}, {"viewId": "vis-3063_03_1", "viewFile": "vis-3063_03_1.png", "specification": {"layer": [{"mark": "surface", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}, "surface": {"field": "probability_density", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}}}]}, "marks": ["surface", "point"], "channels": ["x", "y", "surface"], "dataTypes": ["quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["query-identify:Attributes-correlation", "query-compare:Attributes-distribution"], "figId": "vis-3063_03", "figFile": "vis-3063_03.png", "figCaption": "", "figBox": {"x": 0.5430484429361021, "y": 0.16542124920466275, "width": 0.28718342268564395, "height": 0.8217688942997017}, "figVis": ["scatterplot", "surface_graph"], "relationText": "In complex models like GANs, it is a key to understanding relationships among several elements of the models. For example, users may want to check how the distribution of fake samples are similar to those of real samples.: correlate\n\nIt helps users to determine whether the two distributions are similar or not, which is the main goal of GANs.: compare, distribution", "note": "[surface graph, scatter]"}, {"viewId": "vis-3063_03_2", "viewFile": "vis-3063_03_2.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "epoch", "type": "quantitative"}, "y": {"field": "loss", "type": "quantitative"}, "color": {"field": "loss_type", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "epoch", "type": "quantitative"}, "y": {"field": "divergence", "type": "quantitative"}, "color": {"field": "divergence_type", "type": "nominal"}}}]}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3063_03", "figFile": "vis-3063_03.png", "figCaption": "", "figBox": {"x": 0.832525861872252, "y": 0.165097624781019, "width": 0.15821032663650253, "height": 0.7491626746466529}, "figVis": ["line_chart"], "relationText": "GAN Lab provides Kullback-Leibler (KL) and Jensen-Shannon (JS) divergence values.", "note": ""}, {"viewId": "vis-3064_00_0", "viewFile": "vis-3064_00_0.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "point", "encoding": {"x": {"field": "geo_x", "type": "quantitative"}, "y": {"field": "geo_y", "type": "quantitative"}}}, {"mark": "bar", "layout": "circular", "encoding": {"x": {"field": "hour", "type": "nominal"}, "y": {"field": "flow_magnitude", "type": "quantitative", "aggregate": "sum"}, "color": {"field": "flow_magnitude", "type": "quantitative", "aggregate": "average"}, "ring": {"field": "focus_interval", "type": "quantitative"}}}, {"mark": "graph", "encoding": {"node_x": {"field": "OD_x", "type": "quantitative"}, "node_y": {"field": "OD_y", "type": "quantitative"}, "link": {"field": "OD_path", "type": "relation"}, "link_color": {"field": "time", "type": "temporal"}}}]}, "marks": ["geoshape", "point", "bar", "graph"], "channels": ["x", "y", "color", "ring", "node_x", "node_y", "link", "link_color"], "dataTypes": ["quantitative", "relation", "temporal"], "compositions": ["layer"], "aggregates": ["sum", "average"], "actionTargets": ["consume-present:Attributes-distribution", "query-summarize:Graphs-links/paths"], "figId": "vis-3064_00", "figFile": "vis-3064_00.png", "figCaption": "", "figBox": {"x": 0.18274014587643106, "y": 0.04999449360171396, "width": 0.5345011536961312, "height": 0.7180343506207009}, "figVis": ["map", "bar_chart"], "relationText": "The temporal flow magnitude information is encoded by bar charts located outside of the\nflow wheel. There are 24 bars distributed on the flow wheel and each bar represents an hour in a day. \n\nIn order to further highlight the flow interactions in a local area surrounded by the flow wheel, the trajectory segments selected by users in the matrix map are aggregated into meaningful curves.: filter", "note": ""}, {"viewId": "vis-3064_00_1", "viewFile": "vis-3064_00_1.png", "specification": {"mark": "rect", "encoding": {"row": {"field": "trajectory_segments_1", "type": "nominal"}, "column": {"field": "trajectory_segments_2", "type": "nominal"}, "color": {"field": "flow_magnitude_value", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["row", "column", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-distribution"], "figId": "vis-3064_00", "figFile": "vis-3064_00.png", "figCaption": "", "figBox": {"x": 0.18274014587643087, "y": 0.7736648108873544, "width": 0.5345011536961304, "height": 0.21523924829561109}, "figVis": ["heatmap", "matrix"], "relationText": "In the matrix map, each column of flows represent a trajectory segments that persons move across. The trajectory segments are arranged in rows enabling users to easily capture the distribution of flow interactions and select trajectories of interest.: distribution", "note": ""}, {"viewId": "vis-3064_00_2", "viewFile": "vis-3064_00_2.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "community", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-correlation", "query-compare:Graphs-graphs", "search-explore:Graphs-graphs", "produce:Attributes-clusters"], "figId": "vis-3064_00", "figFile": "vis-3064_00.png", "figCaption": "", "figBox": {"x": 0.7204939908201474, "y": 0.052952044949567144, "width": 0.27177582289687535, "height": 0.4935546854174673}, "figVis": ["scatterplot"], "relationText": "In order to construct a compact correlation between the vectorized representations and corresponding OD flows, a word embedding view is provided to represent the semantic difference of OD flows (T.2).: correlate\n\n(1) The single point selection allows users to quickly focus on an independent OD flow, and establish a visual connection between the points in word embedding view and lines in map view, which is much helpful for a detailed exploration and comparison of a small number of OD flows.: compare, filter\n\n(3) Community detection is able to classify the OD flows into different communities. : cluster", "note": ""}, {"viewId": "vis-3064_00_3", "viewFile": "vis-3064_00_3.png", "specification": {"mark": "radar", "encoding": {"theta": {"field": "metric_type", "type": "nominal"}, "radius": {"field": "metric_value", "type": "quantitative"}, "color": {"field": "method", "type": "nominal"}}}, "marks": ["radar"], "channels": ["theta", "radius", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3064_00", "figFile": "vis-3064_00.png", "figCaption": "", "figBox": {"x": 0.720493990820145, "y": 0.5479494500803094, "width": 0.271775822896875, "height": 0.44329120999011357}, "figVis": ["polar_plot"], "relationText": "A radar chart is designed to visually present the difference between the original and\nsimplified flow maps, with a set of attributes taken into consideration.", "note": ""}, {"viewId": "vis-3064_00_4", "viewFile": "vis-3064_00_4.png", "specification": {"facet": {"row": {"field": "method", "type": "nominal"}}, "spec": {"mark": "rect", "encoding": {"row": {"field": "flow_1", "type": "nominal"}, "column": {"field": "flow_2", "type": "nominal"}, "color": {"field": "flow_coverage", "type": "quantitative"}}}}, "marks": ["rect"], "channels": ["row", "column", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3064_00", "figFile": "vis-3064_00.png", "figCaption": "", "figBox": {"x": 0.006258001862233732, "y": 0.5763080921230285, "width": 0.17822926564490693, "height": 0.19111751097503216}, "figVis": ["matrix", "heatmap"], "relationText": "Furthermore, a pixel map is designed to present the distribution of flow coverage of different sampling strategies as shown in Fig.1 (e), which can be used to measure the visual perception of simplified flow map. ", "note": ""}, {"viewId": "vis-3064_00_5", "viewFile": "vis-3064_00_5.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "EB", "type": "quantitative", "bin": true}, "y": {"field": "frequency", "type": "quantitative"}, "xoffset": {"field": "method", "type": "nominal"}, "color": {"field": "method", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "xoffset", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": ["bin"], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3064_00", "figFile": "vis-3064_00.png", "figCaption": "", "figBox": {"x": 0.006258001862233729, "y": 0.7955793150145425, "width": 0.17822926564490674, "height": 0.18874135072464782}, "figVis": ["bar_chart"], "relationText": "A group histogram is applied to present the retaining of edge betweenness through different sampling schemes as shown in Fig.1 (f), according to which the users can find whether important flows are preserved in the simplified flow map.", "note": ""}, {"viewId": "vis-3065_00_0", "viewFile": "vis-3065_00_0.png", "specification": {"facet": {"column": {"field": "metric_type", "type": "nominal"}}, "spec": {"mark": "line", "encoding": {"x": {"field": "epoch", "type": "quantitative"}, "y": {"field": "metric_value", "type": "quantitative"}}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3065_00", "figFile": "vis-3065_00.png", "figCaption": "", "figBox": {"x": 0.010236748557867006, "y": 0.05742510041867045, "width": 0.6439334520926054, "height": 0.19671956923806444}, "figVis": ["line_chart"], "relationText": "The line charts (revealing the trend of different summary statistics over the training) are presented as small-multiples [49] (R1.1, R1.3).", "note": ""}, {"viewId": "vis-3065_00_1", "viewFile": "vis-3065_00_1.png", "specification": {"facet": {"row": "action/reward", "type": "nominal"}, "spec": {"mark": "area", "encoding": {"x": {"field": "epoch", "type": "quantitative"}, "y": {"aggregate": "sum", "field": "count", "stack": "normalize"}, "color": {"field": "action/reward_type", "type": "nominal"}}}}, "marks": ["area"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["sum"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3065_00", "figFile": "vis-3065_00.png", "figCaption": "", "figBox": {"x": 0.010236748557867003, "y": 0.255408208724826, "width": 0.643933452092605, "height": 0.2051459352388017}, "figVis": ["area_chart"], "relationText": "The two stacked area charts demonstrate the distribution of actions and rewards over time (R1.2). ", "note": ""}, {"viewId": "vis-3065_00_2", "viewFile": "vis-3065_00_2.png", "specification": {"facet": {"row": "action/reward", "type": "nominal"}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "arc", "encoding": {"theta": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "action/reward_type", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "epoch", "type": "ordinal", "sort": {"op": "count", "ordinal": "descending"}}, "y": {"aggregate": "count"}, "color": {"field": "action/reward_type", "type": "nominal"}}}]}}, "marks": ["arc", "bar"], "channels": ["theta", "color", "x", "y"], "dataTypes": ["quantitative", "nominal", "ordinal"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "query-identify:Attributes-order"], "figId": "vis-3065_00", "figFile": "vis-3065_00.png", "figCaption": "", "figBox": {"x": 0.6647278944129016, "y": 0.00909539614084194, "width": 0.3247239081565895, "height": 0.4455076160148203}, "figVis": ["donut_chart", "line_chart"], "relationText": "The pie chart shows the action/reward distribution of all steps in the current epoch; whereas the stacked bar chart presents the action/reward distribution of each individual episode in the epoch. \n\nAs shown in Figure 1-b2, there are 20 episodes in the current epoch (one stacked bar for one episode), and the stacked bars are sorted decreasingly from left to right to help users quickly identify the episode with the maximum number of steps/rewards.", "note": "([pie, bar], category)"}, {"viewId": "vis-3065_00_3", "viewFile": "vis-3065_00_3.png", "specification": {"facet": {"row": "episode", "type": "nominal"}, "spec": {"layer": [{"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "displacement", "type": "quantitative"}, "color": {"field": "action_type", "type": "nominal"}}}, {"mark": "rule", "encoding": {"x": {"field": "step", "type": "ordinal"}, "color": {"field": "reward_type", "type": "nominal"}}}, {"mark": "area", "encoding": {"x": {"field": "step", "type": "ordinal"}, "color": {"field": "q_value", "type": "nominal"}}}]}}, "marks": ["line", "rule", "area"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["consume-present:Graphs-links/paths", "query-summarize:Attributes-values"], "figId": "vis-3065_00", "figFile": "vis-3065_00.png", "figCaption": "", "figBox": {"x": 0.013939731981322697, "y": 0.46473407367955594, "width": 0.9721205360373522, "height": 0.5298062857514189}, "figVis": ["line_chart", "bar_chart"], "relationText": "((x-axis, [line, area]), rows)", "note": ""}, {"viewId": "vis-3067_04_0", "viewFile": "vis-3067_04_0.png", "specification": {"layer": [{"facet": {"layout": "circular", "sector": {"field": "topic", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "text", "encoding": {"text": "topic"}}, {"mark": "text", "encoding": {"text": "sub-topic"}}, {"mark": "line", "encoding": {"frequency": "noiseness"}}]}}, {"nested": {"parent": {"mark": "tree", "encoding": {"node": {"field": "topic", "type": "node"}, "link": {"field": "tree_hierarchy", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "arc", "encoding": {"theta": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "document-authors", "type": "nominal"}, "size": {"field": "text_amount", "type": "quantitative"}}}}}}]}, "marks": ["text", "line", "tree", "arc"], "channels": ["text", "frequency", "node", "link", "theta", "color", "size"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["layer", "facet", "concat", "nested"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "query-identify:Graphs-nodes"], "figId": "vis-3067_04", "figFile": "vis-3067_04.png", "figCaption": "", "figBox": {"x": 0.30694592808228643, "y": 0.01437367919230221, "width": 0.34421851092670425, "height": 0.7035832655048548}, "figVis": ["tree", "pie_chart"], "relationText": "The same concept is applied to branches using squiggly-lines on the outside of the tree. Line-segments showing higher frequency and amplitude indicate noisiness or higher variance in sub-topic branches.: {noisiness, variance}: derive value, distribution\n\nIn addition, the most similar nodes along this path are highlighted.: compare", "note": "[(node:(category, value), tree relation), ((line graph: distribution),category)]"}, {"viewId": "vis-3067_04_1", "viewFile": "vis-3067_04_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "inserted_document", "type": "nominal"}, "y": {"field": "measure_value_normalized", "type": "quantitative"}, "color": {"field": "measure", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "inserted_document", "type": "nominal"}, "y": {"field": "text_length", "type": "quantitative"}, "color": {"field": "document-authors", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"x": {"field": "inserted_document", "type": "nominal"}, "color": {"field": "insert_certainty", "type": "quantitative"}}}, {"mark": "icon", "encoding": {"x": {"field": "inserted_document", "type": "nominal"}, "icon": {"field": "provenance", "type": "nominal"}}}]}, "marks": ["line", "bar", "rect", "icon"], "channels": ["x", "y", "color", "icon"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-distribution"], "figId": "vis-3067_04", "figFile": "vis-3067_04.png", "figCaption": "", "figBox": {"x": 0.011461248204479354, "y": 0.7248579100815331, "width": 0.8095189719561497, "height": 0.25604552044494316}, "figVis": ["bar_chart", "line_chart", "heatmap"], "relationText": "Monitoring the quality of the topic modeling is a vital guidance-element of our visual analytics approach.\n\nThe IHTM algorithm issues an update for the twelve model quality measures during every insert-loop (Algo 1, line 8). To visualize and interact with these measures, we include a timeline view, as depicted in Fig. 3: {measures}: derive value, timeline: correlate\n\nTo facilitate comparison, all measures are adjusted to be optimized towards 100%,i.e., a rising line for a measure indicates an improvement in quality.: compare", "note": "[line graph:(T,Q,N), bar chart: (T,Q,N), heatmap: (T,Q)]"}, {"viewId": "vis-3069_00_0", "viewFile": "vis-3069_00_0.png", "specification": {"mark": "area", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "y": {"field": "rule", "type": "ordinal"}, "color": {"field": "label_of_data", "type": "nominal"}}}, "marks": ["area"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "ordinal", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3069_00", "figFile": "vis-3069_00.png", "figCaption": "", "figBox": {"x": 0.23991581596463882, "y": 0.0853714343196686, "width": 0.06820931871259181, "height": 0.7344022906178492}, "figVis": ["area_chart"], "relationText": "The visualization design. A: The data flow visualizes the data that satisfies a rule as a flow into the rule, providing an overall sense of the order of the rules.\nThe user can identify the amount of data satisfying a rule through the width of the flow, which helps the user decide to trust or reject the rule (Q2). ", "note": ""}, {"viewId": "vis-3069_00_1", "viewFile": "vis-3069_00_1.png", "specification": {"facet": {"row": {"field": "feature_name", "type": "categorical", "sort": "importance_score"}, "column": {"field": "rule", "type": "ordinal"}}, "spec": {"condition_1": {"test": "feature type is continuous", "value": {"mark": "area", "encoding": {"x": {"field": "feature_value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "condition_2": {"test": "feature type is discrete", "value": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "condition_3": {"test": "a clause is using feature j", "value": {"mark": "rect", "encoding": {"x": {"field": "start interval in the clause", "type": "quantitative"}, "x2": {"field": "end interval in the clause", "type": "quantitative"}}}}}}, "marks": ["area", "bar", "rect"], "channels": ["x", "y", "x2"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["query-compare:Attributes-values", "search-browse:Attributes-values"], "figId": "vis-3069_00", "figFile": "vis-3069_00.png", "figCaption": "", "figBox": {"x": 0.3065075610449454, "y": 0.05573389247867947, "width": 0.2746883042965835, "height": 0.7702885094591347}, "figVis": ["area_chart", "bar_chart", "matrix"], "relationText": "The advantage of the matrix representation is that it allows users to verify and compare different rules quickly. This also allows easier verification and evaluation of the model's predictions (Q3).\nThis combination of the compact view of data distribution and the range constraint helps users quickly grasp the properties of different clauses in a rule (Q1)\nThe features are also sorted according to their importance scores, which is computed by the number of instances that a feature has been used to discriminate.", "note": "The area chart is expanded after interactions. Thus I do not label it."}, {"viewId": "vis-3069_00_2", "viewFile": "vis-3069_00_2.png", "specification": {"facet": {"row": {"field": "rule", "type": "ordinal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"y": {"field": "output", "type": "quantitative"}, "color": {"field": "level", "type": "nominal"}}}, {"mark": "arc", "encoding": {"theta": {"field": "fidelity", "type": "quantitative"}, "color": {"field": "level", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "level", "type": "nominal"}}}]}}, "marks": ["bar", "arc"], "channels": ["y", "color", "theta", "x"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["query-identify:Attributes-outliers"], "figId": "vis-3069_00", "figFile": "vis-3069_00.png", "figCaption": "", "figBox": {"x": 0.5806795351440802, "y": 0.035655064612629774, "width": 0.18469484307703024, "height": 0.7929920613389716}, "figVis": ["bar_chart"], "relationText": "When the error between the original model and the real data is high, the users should be notified that the model\u2019s prediction should not be fully trusted", "note": ""}, {"viewId": "vis-3070_00_0", "viewFile": "vis-3070_00_0.png", "specification": {"nested": {"parent": {"mark": "line", "encoding": {"x": {"field": "year_month", "type": "temporal"}, "y": {"field": "exchange", "type": "nominal"}, "color": {"field": "continent", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "axis", "configuration": {"mark": "rect", "encoding": {"x": {"field": "year_month", "type": "temporal"}, "xoffset": {"field": "day", "type": "temporal"}, "y": {"field": "exchange", "type": "nominal"}, "width": {"field": "client", "aggregate": "count", "type": "quantitative"}, "color": {"field": "transaction_volume", "type": "quantitative"}}}}}}, "marks": ["line", "rect"], "channels": ["x", "y", "color", "xoffset", "width"], "dataTypes": ["temporal", "nominal", "quantitative"], "compositions": ["nested"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-correlation", "query-identify:Attributes-extremes"], "figId": "vis-3070_00", "figFile": "vis-3070_00.png", "figCaption": "", "figBox": {"x": 0.008191172129968241, "y": 0.06817795224165783, "width": 0.8156429458496934, "height": 0.4517401980444644}, "figVis": ["parallel_coordinate", "heatmap"], "relationText": "Generally speaking, this view first provides users a handy comparison of exchange transaction patterns, and second, it provides a zoom-and-expand feature which supports more detailed visual analysis on a specific exchange (T5, T6). Moreover, through this view users can quickly identify the big exchanges in the Bitcoin market (T5).", "note": ""}, {"viewId": "vis-3070_00_1", "viewFile": "vis-3070_00_1.png", "specification": {"facet": {"row": {"field": "exchange", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "transaction_volume", "type": "quantitative"}, "x": {"field": "time", "type": "temporal"}, "color": {"field": "continent", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "temporal", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["search-explore:Attributes-correlation"], "figId": "vis-3070_00", "figFile": "vis-3070_00.png", "figCaption": "", "figBox": {"x": 0.8406944589422582, "y": 0.1264574037533688, "width": 0.15160042214559508, "height": 0.8601313725566124}, "figVis": ["bar_chart"], "relationText": "We provide an exchanges list panel (Fig. 1B) for users to quickly select a certain exchange and observe its historical transaction volume in USD.\n\nWhen the entry-time sorting criteria is selected, the newest incomers will be stacked on the top, while the most aged players will appear at the bottom", "note": ""}, {"viewId": "vis-3070_00_2", "viewFile": "vis-3070_00_2.png", "specification": {"mark": "rect", "encoding": {"y": {"field": "exchange", "type": "nominal"}, "x": {"field": "time", "type": "temporal"}, "color": {"field": "volume_send_receive", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "temporal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-correlation", "query-summarize:Attributes-correlation"], "figId": "vis-3070_00", "figFile": "vis-3070_00.png", "figCaption": "", "figBox": {"x": 0.20779420716642635, "y": 0.5254399641173261, "width": 0.3393337302533332, "height": 0.37661654579802506}, "figVis": ["heatmap"], "relationText": "The massive sequence view (MSV) (Fig. 1C) provides a compact and comprehensive overview of the temporal transaction patterns of all the examined exchanges, which further reflects the whole market evolution of Bitcoin.  Based on this view, we can answer the analytical questions about the overall market (T1, T2) as well as \n interexchange relationships (T3).\n\nThis view also supports analysis on two types of transaction data, i.e., the transactions between exchanges and clients (\u201cSurplus\u201d), and the aggregated transaction behavior between exchanges (\u201cInter-exchange\u201d).", "note": ""}, {"viewId": "vis-3070_00_3", "viewFile": "vis-3070_00_3.png", "specification": {"layer": [{"mark": "graph", "encoding": {"node": {"field": "exchange", "type": "node", "encoding": {"color": {"field": "continent", "type": "nominal"}, "opacity": {"field": "country", "type": "nominal"}}}, "link": {"field": "business_connection", "type": "relation", "encoding": {"width": {"field": "business_connection_strength", "type": "quantitative"}, "arrow_color": {"field": "send_or_receive", "type": "nominal"}, "arrow_position": {"field": "time", "type": "temporal"}, "arrow_size": {"field": "transaction_volume", "type": "quantitative"}}}}}, {"mark": "arc", "encoding": {"theta": {"field": "market_share", "type": "quantitative"}, "color": {"field": "continent", "type": "nominal"}}}, {"mark": "arc", "encoding": {"theta": {"field": "market_share", "type": "quantitative"}, "color": {"field": "country", "type": "nominal"}}}]}, "marks": ["graph", "arc"], "channels": ["node", "link", "color", "opacity", "width", "arrow_color", "arrow_position", "arrow_size", "theta"], "dataTypes": ["node", "relation", "nominal", "quantitative", "temporal"], "compositions": ["layer"], "aggregates": [], "actionTargets": [], "figId": "vis-3070_00", "figFile": "vis-3070_00.png", "figCaption": "", "figBox": {"x": 0.5528089396304823, "y": 0.5452606195603146, "width": 0.27163679705019367, "height": 0.4448238894552508}, "figVis": ["graph", "donut_chart"], "relationText": "The connection view, which is essentially a graph, aims at visualizinginter-exchange behavior with geographic information(T3, T6), helpingusers better understand the exchange relationships, and demonstratingthe transaction patterns of an ego-exchange with respect to its partners(T2).", "note": "((Share, In/Out Ring, Continent, Exchange, In/Out Arrow, In/Out Value), G)"}, {"viewId": "vis-3071_03_0", "viewFile": "vis-3071_03_0.png", "specification": {"layer": [{"facet": {"row": {"field": "ensemble_components_1", "type": "nominal"}, "column": {"field": "ensemble_components_2", "type": "nominal"}}, "spec": {"condition_1": {"test": "row index is larger than column index", "value": {"layer": [{"facet": {"layout": "mirrored", "column": {"field": "component_name", "type": "nominal"}, "color": {"field": "Kendall's_tau_correlation", "type": "quantitative"}}, "spec": {"mark": "bar", "layout": "circular", "encoding": {"x": {"field": "anomaly_data_point_1", "type": "nominal"}, "y": {"field": "rank_changing_amplitude", "type": "quantitative"}, "color": {"field": "rank_change_of_data_point", "type": "nominal"}}}}, {"mark": "graph", "encoding": {"node": {"field": "anomaly_data_point_2", "type": "node"}, "link": {"field": "the_same_anomaly_data_point", "type": "relation"}}}]}}, "condition_2": {"test": "row index is equal to column index", "value": {"mark": "circle", "encoding": {"color": {"field": "importance_weight", "type": "quantitative"}}}}}}, {"mark": "circle", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "correlation", "type": "quantitative", "aggregate": "average"}}}, {"mark": "graph", "encoding": {"node": {"field": "ensemble_components", "type": "node"}, "link": {"field": "the_same_component", "type": "relation"}}}]}, "marks": ["bar", "graph", "circle"], "channels": ["x", "y", "color", "node", "link"], "dataTypes": ["nominal", "quantitative", "node", "relation"], "compositions": ["layer", "facet"], "aggregates": ["average"], "actionTargets": ["query-summarize:Attributes-clusters", "produce:Attributes-similarity", "query-summarize:Attributes-outliers", "consume-present:Attributes-order"], "figId": "vis-3071_03", "figFile": "vis-3071_03.png", "figCaption": "", "figBox": {"x": 0.18761103770179471, "y": 0.07726873832049867, "width": 0.25517455481217854, "height": 0.45694749072747787}, "figVis": ["glyph_based", "bar_chart"], "relationText": "(1) the global inspection view displays the overall clustering of different ensemble components at the top right (T1); (2) the correlation matrix view depicts the correlation between different pairs of ensemble components at the bottom left (T3).\nWe first construct a vector for each component based on their outlier scores. Then, we compute the similarity between each pair of components based on the Euclidean distance of the ensemble vectors.\nAs shown in Fig. 5(5), two colors are used in this glyph to show the direction of a data point\u2019s rank change compared with the opposite side. (compare task)", "note": "bottom left: (Component, Component, (C1/C2, (point, rank, rise/fall), correlation, link of the same point), algorithm weight)\ntop right: not a Euclidean (Pos1, Pos2, Pos3, Correlation, Ave correlation, link)"}, {"viewId": "vis-3071_03_1", "viewFile": "vis-3071_03_1.png", "specification": {"layer": [{"facet": {"column": {"field": "component", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "outlier score", "bin": "true", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"x": {"field": "data point", "type": "nominal"}, "y": {"field": "attributes", "type": "nominal"}, "color": {"field": "attribute difference", "type": "quantitative"}, "height": {"field": "rank variance", "type": "quantitative"}, "width": {"field": "outlier score", "type": "quantitative"}, "gap": {"field": "outlier score difference", "type": "quantitative"}}}]}}, {"mark": "graph", "encoding": {"node": {"field": "data point", "type": "node"}, "link": {"field": "the same data point", "type": "relation"}}}]}, "marks": ["bar", "rect", "graph"], "channels": ["x", "y", "color", "height", "width", "gap", "node", "link"], "dataTypes": ["nominal", "quantitative", "node", "relation"], "compositions": ["layer", "facet", "concat"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-outliers"], "figId": "vis-3071_03", "figFile": "vis-3071_03.png", "figCaption": "", "figBox": {"x": 0.4491102356030271, "y": 0.08003040265631461, "width": 0.2719257609189863, "height": 0.4865074593168859}, "figVis": ["heatmap", "bar_chart"], "relationText": "Outlier score distribution: on the top of each ranking list, a histogram is dimensionality reductionawn to show the outlier score distributions of the corresponding ensemble component.", "note": "(two list, (id, feature, value, variance), (distribution), gap, rank change)"}, {"viewId": "vis-3071_03_2", "viewFile": "vis-3071_03_2.png", "specification": {"layer": [{"facet": {"layout": "circular", "sector": {"field": "model", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "calculated weight", "type": "quantitative"}}}}, {"nested": {"parent": {"mark": "radar", "encoding": {"theta": {"field": "model", "type": "nominal"}, "radius": {"field": "parameter weight", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "axis", "configuration": {"mark": "area", "encoding": {"x": {"field": "sensitivity interval", "type": "quantitative"}, "y": {"field": "sensitivity value", "type": "quantitative"}}}}}}]}, "marks": ["bar", "radar", "area"], "channels": ["y", "theta", "radius", "x"], "dataTypes": ["quantitative", "nominal"], "compositions": ["layer", "facet", "nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-values"], "figId": "vis-3071_03", "figFile": "vis-3071_03.png", "figCaption": "", "figBox": {"x": 0.008162426629800464, "y": 0.07672707821735082, "width": 0.16265993530290876, "height": 0.2869042318236426}, "figVis": ["area_chart", "bar_chart", "polar_plot"], "relationText": "", "note": "(model, (weight, sensitivity, parameter))"}, {"viewId": "vis-3071_03_3", "viewFile": "vis-3071_03_3.png", "specification": {"facet": {"row": {"field": "component_id", "type": "ordinal"}}, "spec": {"layer": [{"mark": "radar", "encoding": {"theta": {"field": "feature", "type": "nominal"}, "radius": {"field": "feature weight", "type": "quantitative"}}}, {"mark": "others", "layout": "circular", "encoding": {"theta": {"field": "feature", "type": "nominal"}, "opacity": {"field": "variance", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}}}]}}, "marks": ["radar", "others", "point"], "channels": ["theta", "radius", "opacity", "x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3071_03", "figFile": "vis-3071_03.png", "figCaption": "", "figBox": {"x": 0.001323237063307963, "y": 0.40059946822535586, "width": 0.16806936929754596, "height": 0.5626278499600806}, "figVis": ["glyph_based"], "relationText": "The feature subspace view(Fig. 4(ii))shows the selected features for each ensemble component to provide a visual reasoning for the ensemble analysis results (T4)", "note": "Don't know the meaning of the polygon."}, {"viewId": "vis-3071_03_4", "viewFile": "vis-3071_03_4.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "aggregate perspectives", "type": "nominal"}, "y": {"field": "perspective value", "type": "quantitative"}, "color": {"field": "ensemble component", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "score", "type": "quantitative"}, "y": {"field": "anomaly id", "type": "nominal", "sort": "-x"}}}]}, "marks": ["line", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["query-identify:Attributes-correlation"], "figId": "vis-3071_03", "figFile": "vis-3071_03.png", "figCaption": "", "figBox": {"x": 0.45541236757438563, "y": 0.6146299985900548, "width": 0.5310094965772784, "height": 0.3649536216714272}, "figVis": ["parallel_coordinate"], "relationText": "A validation view (Fig. 4(v)) takes the parallel coordinates design to record each combination result in terms of algorithms and their parameters, used features, and final combined top detected anomalies.\n\nA parallel coordinates view in Fig. 4(v) is designed to describe the general relationships among the generated ensemble components, which helps in determining the final combination results.", "note": ""}, {"viewId": "vis-3072_00_0", "viewFile": "vis-3072_00_0.png", "specification": {"mark": "others", "encoding": {"y": {"field": "cluster_side_1"}, "x": {"field": "cluster_side_2"}, "height": {"field": "node_side_1", "aggregate": "count"}, "width": {"field": "node_side_2", "aggregate": "count"}, "fill_height": {"field": "edge_density"}, "color": {"field": "cluster_side_2"}, "texture": {"field": "cluster_side_2", "remark": "work together with color"}}}, "marks": ["others"], "channels": ["y", "x", "height", "width", "fill_height", "color", "texture"], "dataTypes": [], "compositions": [], "aggregates": ["count"], "actionTargets": ["query-summarize:Graphs-clusters/groups"], "figId": "vis-3072_00", "figFile": "vis-3072_00.png", "figCaption": "", "figBox": {"x": 0.29874348215082813, "y": 0.17006798734820358, "width": 0.5847713936155555, "height": 0.7742095867469841}, "figVis": ["others"], "relationText": "VIBRallows users to gainan overview of large scale bipartite relations with the summary graph(T.a1-4)", "note": ""}, {"viewId": "vis-3074_00_0", "viewFile": "vis-3074_00_0.png", "specification": {"mark": "rect", "encoding": {"y": {"field": "worker_label_class", "type": "nominal"}, "x": {"field": "model_label_class", "type": "nominal"}, "color": {"field": "percentage_of_matching", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["search-explore:Attributes-correlation"], "figId": "vis-3074_00", "figFile": "vis-3074_00.png", "figCaption": "", "figBox": {"x": 0.02508519383393526, "y": 0.05629210081252112, "width": 0.07881697186019218, "height": 0.1300168290442815}, "figVis": ["heatmap"], "relationText": "used to explore the relationship between worker labeling and model estimates", "note": "confusion matrix?"}, {"viewId": "vis-3074_00_1", "viewFile": "vis-3074_00_1.png", "specification": {"layer": [{"mark": "arc", "encoding": {"theta": {"field": "number_of_class", "type": "quantitative"}, "color": {"field": "worker_label_class", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "tsne_dimension_1", "type": "quantitative"}, "y": {"field": "tsne_dimension_2", "type": "quantitative"}, "color": {"field": "worker_label_class", "type": "quantitative"}}}, {"layer": [{"mark": "point", "encoding": {"theta": {"field": "worker_label_class", "type": "quantitative"}, "color": {"field": "worker_label_class", "type": "quantitative"}}}, {"mark": "image"}, {"mark": "arc", "encoding": {"theta": {"field": "number_of_class", "type": "quantitative"}, "color": {"field": "worker_label_class", "type": "nominal"}}}]}, {"mark": "graph", "encoding": {"node": {"field": "uncertain_instance", "type": "node", "encoding": {"x": {"field": "tsne_dimension_1", "type": "quantitative"}, "y": {"field": "tsne_dimension_2", "type": "quantitative"}}}, "link": {"field": "influence", "type": "relation", "width": {"field": "influence_strength", "type": "quantitative"}}}}]}, "marks": ["arc", "point", "image", "graph"], "channels": ["theta", "color", "x", "y", "node", "link"], "dataTypes": ["quantitative", "nominal", "node", "relation"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["search-explore:Attributes-outliers"], "figId": "vis-3074_00", "figFile": "vis-3074_00.png", "figCaption": "", "figBox": {"x": 0.03281928576167331, "y": 0.06864713258337567, "width": 0.5189365180162775, "height": 0.897789032094289}, "figVis": ["scatterplot", "donut_chart", "glyph_based"], "relationText": "The instance visualization uses a constrained t-SNE projection to visualize the instances of interest and highlights the most informative ones using uncertain glyphs (T2).\n\nThe uncertain glyph, as shown in Fig. 1B, consists of a centered dot indicating the inferred class, the surrounding colored arcs denoting the distribution of worker assignments, arrowhead markers pointing towards corresponding class arcs (marked by the workers) on the outer circle, and an optional snapshot providing a quick spot of the instance (Fig. 1C). ", "note": "(Outer ring: class, number, (t-sne:x, y, (glyph: distribution, class), (flow: graph, similarity))"}, {"viewId": "vis-3074_00_2", "viewFile": "vis-3074_00_2.png", "specification": {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "spammer_score", "type": "quantitative"}, "y": {"field": "accuracy", "type": "quantitative"}, "size": {"field": "number_of_labeled_instance", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"remark": "The dot size matches the number of instances the worker labeled among the selected ones and the area of the sector represents the ratio of the class labels the worker assigned to these instances. The color of each sector matches the color of the corresponding class", "mark": "arc", "encoding": {"theta": {"field": "class ratio", "type": "quantitative"}, "color": {"field": "class", "type": "nominal"}, "size": {"aggregate": "count", "type": "quantitative"}}}}}}, "marks": ["point", "arc"], "channels": ["x", "y", "size", "theta", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["nested"], "aggregates": ["count"], "actionTargets": ["query-identify:Attributes-clusters"], "figId": "vis-3074_00", "figFile": "vis-3074_00.png", "figCaption": "", "figBox": {"x": 0.5798368140017179, "y": 0.03413684544839216, "width": 0.4190871090113783, "height": 0.37948922258683354}, "figVis": ["heatmap", "scatterplot"], "relationText": "Analyze the reliability of each worker, form an assumptionof the spammer degree of the worker, verify the formed assumptionby checking the corresponding annotation results, and recognize spammers in order to improve the labeling accuracy", "note": "(x, y, size/matrix, flow) Colors' encoding is unknown."}, {"viewId": "vis-3074_00_3", "viewFile": "vis-3074_00_3.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "round", "type": "ordinal"}, "y": {"type": "quantitative", "aggregate": "count"}, "xoffset": {"field": "before_after", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "xoffset"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3074_00", "figFile": "vis-3074_00.png", "figCaption": "", "figBox": {"x": 0.5765520886838699, "y": 0.4287897270031379, "width": 0.10420568638240278, "height": 0.17880322463480267}, "figVis": ["bar_chart"], "relationText": "Fig. 1(d) shows the validation trail after a few rounds of validation and propagation. Each round isrepresented by two bars, where the left bar represents the number ofverified instances and the right bar indicates the number of impactedinstances.", "note": ""}, {"viewId": "vis-3075_00_0", "viewFile": "vis-3075_00_0.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "stability", "type": "quantitative"}}}, {"mark": "line", "encoding": {"y": {"field": "quantity (tons)", "type": "quantitative"}, "x": {"field": "time", "type": "temporal"}, "color": {"field": "export/import", "type": "nominal"}}}], "resolve": {"scale": {"y": "independent"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "consume-present:Attributes-outliers", "consume-present:Attributes-values"], "figId": "vis-3075_00", "figFile": "vis-3075_00.png", "figCaption": "", "figBox": {"x": 0.08141760984891111, "y": 0.03548560821720285, "width": 0.9112943741556278, "height": 0.16031780213866545}, "figVis": ["line_chart"], "relationText": "The time series view (Fig. 1(1)) that displays the trend and anomalies of trades and stability measures for the selected country (R4)", "note": ""}, {"viewId": "vis-3075_00_1", "viewFile": "vis-3075_00_1.png", "specification": {"mark": "geoshape", "encoding": {"color": {"field": "quantity (tonnes) exported of selected good", "type": "quantitative", "bin": true}}}, "marks": ["geoshape"], "channels": ["color"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": ["bin"], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3075_00", "figFile": "vis-3075_00.png", "figCaption": "", "figBox": {"x": 0.08313269705181799, "y": 0.19927965410062212, "width": 0.41799113370160706, "height": 0.4133384940597034}, "figVis": ["map"], "relationText": "The choropleth map view (Fig. 1(2)) that displays the trade profile of a selected country (R2)", "note": ""}, {"viewId": "vis-3075_00_2", "viewFile": "vis-3075_00_2.png", "specification": {"facet": {"field": "country", "type": "nominal"}, "spec": {"mark": "geoshape", "encoding": {"color": {"field": "display the first order trade relationships centering on selected countries", "type": "ordinal"}}}}, "marks": ["geoshape"], "channels": ["color"], "dataTypes": ["ordinal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3075_00", "figFile": "vis-3075_00.png", "figCaption": "", "figBox": {"x": 0.5201455829982421, "y": 0.19671002023820572, "width": 0.46564331205330184, "height": 0.40342958596541145}, "figVis": ["map"], "relationText": "along with a small multiple of choropleth maps (Fig. 1(3)) used to compare the trade profiles of related countries to the selected one (R5).", "note": "The N here is a double-encoding (small multiples && inside map)"}, {"viewId": "vis-3075_00_3", "viewFile": "vis-3075_00_3.png", "specification": {"layer": [{"nested": {"parent": {"mark": "tree", "encoding": {"node": {"field": "country set", "type": "node"}, "link": {"field": "hierarchy", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "unit", "encoding": {"unit": {"field": "country", "type": "node"}, "color": {"field": "model type", "type": "quantitative"}}}}}}, {"facet": {"field": "group", "type": "nominal"}, "spec": {"mark": "boxplot", "encoding": {"x": {"field": "count", "type": "quantitative"}, "y": {"field": "triad configuration", "type": "nominal"}}}}]}, "marks": ["tree", "unit", "boxplot"], "channels": ["node", "link", "unit", "color", "x", "y"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["layer", "nested", "facet"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-clusters", "query-compare:Attributes-values"], "figId": "vis-3075_00", "figFile": "vis-3075_00.png", "figCaption": "", "figBox": {"x": 0.13902145125577348, "y": 0.5968384062910695, "width": 0.3438961688358655, "height": 0.390307415322029}, "figVis": ["tree"], "relationText": "The clustering view (Fig. 1(4)) and scatter plot view (Fig. 7(3)) are used to explore the similarities and differences of each country\u2019s trade profiles and compare trade profiles to stability measures (R5)", "note": ""}, {"viewId": "vis-3075_00_4", "viewFile": "vis-3075_00_4.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "country", "type": "node"}, "link": {"field": "import dependency", "type": "relation", "width": {"field": "strength of dependencies", "type": "quantitative"}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "others", "encoding": {"icon": {"field": "national_flag", "type": "nominal"}}}}}}, "marks": ["graph", "others"], "channels": ["node", "link", "icon"], "dataTypes": ["node", "relation", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Graphs-links/paths"], "figId": "vis-3075_00", "figFile": "vis-3075_00.png", "figCaption": "", "figBox": {"x": 0.6610922065127512, "y": 0.5940922083947877, "width": 0.18189682517794478, "height": 0.40496451341423617}, "figVis": ["tree"], "relationText": "The trade diffusion graph (Fig.1(5)) displays the trade flow of the selected food products from the selected country to the countries whose disruption in trade are affected or affecting the selected country (R3).", "note": ""}, {"viewId": "vis-3076_03_0", "viewFile": "vis-3076_03_0.png", "specification": {"facet": {"row": {"field": "sequence_index", "type": "nominal", "remark": "each row is a sequence"}, "column": {"field": "stage_index", "type": "ordinal", "remark": "each sequence (Fig. 5(a)) is organized into columns aligned with K stages"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "text", "encoding": {"text": {"field": "start_event", "type": "nominal"}}, "remark": "Each stage segment is depicted using a pair of labels (Fig. 5(c)) indicating the first and last events in the sequence segment"}, {"mark": "rect", "encoding": {"width": {"field": "duration", "type": "quantitative", "remark": "The length of the duration bar encodes the duration of the segment within the sequence"}, "color": {"field": "event_type", "type": "nominal", "remark": "The bar is color-coded with the event category"}}}, {"mark": "text", "encoding": {"text": {"field": "end_event", "type": "nominal"}}, "remark": "Each stage segment is depicted using a pair of labels (Fig. 5(c)) indicating the first and last events in the sequence segment"}]}}, "marks": ["text", "rect"], "channels": ["text", "width", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3076_03", "figFile": "vis-3076_03.png", "figCaption": "", "figBox": {"x": 0.24928816468963041, "y": 0.2517948607707196, "width": 0.3076953181192527, "height": 0.6961959249386726}, "figVis": ["matrix"], "relationText": "The sequence view displays the segmentation results for each individual sequence in a scrollable list, with additional details such as the duration, starting event, and end event for each segment (T2).", "note": "(N, Q) each cell. \nO alogn the axis (sorted because this is event sequence). \nN for each row (non sorted)."}, {"viewId": "vis-3076_03_1", "viewFile": "vis-3076_03_1.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "cluster", "type": "node"}, "link": {"field": "cluster_dependency_path", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"encoding": {"height": {"field": "count", "type": "quantitative", "remark": "The height of each cluster node is proportional to the number of event sequence segments contained in the cluster"}}, "concat": {"layout": "horizontal"}, "spec": [{"mark": "treemap", "encoding": {"size": {"field": "frequency", "type": "quantitative"}, "color": {"field": "event type", "type": "nominal"}}, "remark": "The frequencies of starting and ending events are displayed at the left and right end of the node, respectively. We use treemaps to encode this 1-D data"}, {"concat": {"layout": "vertical"}, "spec": [{"mark": "rect", "encoding": {"width": {"field": "avg duration", "type": "quantitative", "remark": "The average duration of the segments within a cluster is encoded using the length of the bar located at the top of each stage"}}}, {"mark": "rect", "encoding": {"row": {"field": "unique sequential pattern", "type": "nominal", "remark": "Each row represents a unique sequential pattern"}, "column": {"field": "sequence_id", "type": "ordinal", "remark": "length-two sequence"}, "color": {"field": "event type", "type": "nominal", "remark": "color-coded bars representing key events within the pattern"}}}]}, {"mark": "treemap", "encoding": {"size": {"field": "frequency", "type": "quantitative"}, "color": {"field": "event type", "type": "nominal"}}, "remark": "The frequencies of starting and ending events are displayed at the left and right end of the node, respectively. We use treemaps to encode this 1-D data"}]}}}}, "marks": ["graph", "treemap", "rect"], "channels": ["node", "link", "height", "size", "color", "width", "row", "column"], "dataTypes": ["node", "relation", "quantitative", "nominal", "ordinal"], "compositions": ["nested", "concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters", "query-summarize:Attributes-values"], "figId": "vis-3076_03", "figFile": "vis-3076_03.png", "figCaption": "", "figBox": {"x": 0.6330792879779409, "y": 0.0612734887862568, "width": 0.3600652386587955, "height": 0.3711260405084219}, "figVis": ["tree"], "relationText": "The cluster view aggregates segments within each stage into clusters and presents the evolution pattern between clusters across the different stages. An overview of the starting and ending events and the frequent subsequences is provided as the context of each cluster (T3)", "note": "In each cell, left/right: \"treemaps to encode this 1-D data (frequency)\". Middle: Q for the top bar, ((C, O), N) for matrix in the middle (C, O) is x-axis for an event sequence, N is y-axis for non-sorted).\nTherefore, each node is (Q#, [Q, ((C, O), N)], Q#).\nThe node is fed into a graph."}, {"viewId": "vis-3076_03_2", "viewFile": "vis-3076_03_2.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "stage", "type": "node"}, "link": {"field": "dependency", "type": "relation", "remark": "The stages are linked with directed edges showing various progression paths that entities follow as they transit into and out of the stage", "encoding": {"width": {"field": "number of entities", "type": "quantitative", "remark": "The width of each edge is proportional to the number of entities that follow the corresponding transition"}}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "treemap", "remark": "Each stage is represented by a treemap which shows the frequency of events associated with a specific stage.", "encoding": {"node": {"field": "event", "type": "node", "encoding": {"size": {"field": "frequency", "type": "quantitative"}, "color": {"field": "event type", "type": "nominal"}}}, "link": {"field": "hierarchy", "type": "relation"}}}}}}, "marks": ["graph", "treemap"], "channels": ["node", "link", "width", "size", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Graphs-topology/structures"], "figId": "vis-3076_03", "figFile": "vis-3076_03.png", "figCaption": "", "figBox": {"x": 0.256863403072502, "y": 0.12400426576347205, "width": 0.3560926767282007, "height": 0.13585863505347143}, "figVis": ["graph", "treemap"], "relationText": "The stage transition view further aggregates the clusters in the same stage, showing the event distribution and transition patterns across different stages (T4).", "note": "Each stage is represented by a treemap which shows the frequency of events associated with a specific stage. The stages are linked with directed edges showing various progression paths that entities follow as they transit into and out of the stage. The width of each edge is proportional to the number of entities that follow the corresponding transition.      \nQ# is for a treemap."}, {"viewId": "vis-3076_03_3", "viewFile": "vis-3076_03_3.png", "specification": {"mark": "point", "remark": "The event overview illustrates the contextual in- formation of each event through t-SNE projections of the event vectors defined in Section 4. Each event is represented using a color-coded circle based on the event category.", "encoding": {"x": {"field": "tsne_x", "type": "quantitative"}, "y": {"field": "tsne_y", "type": "quantitative"}, "color": {"field": "event type", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3076_03", "figFile": "vis-3076_03.png", "figCaption": "", "figBox": {"x": 0.13538310623483132, "y": 0.10257837012472434, "width": 0.11226451204789378, "height": 0.31596774070661676}, "figVis": ["scatterplot"], "relationText": "The event overview (Fig. 4(6)) provides a t-SNE projection of event vectors, which allows users to compare how events co-occur within the given stage (T5).", "note": ""}, {"viewId": "vis-3076_03_4", "viewFile": "vis-3076_03_4.png", "specification": {"mark": "unit", "remark": "The entity list view, as shown in Fig. 4(7), pro- vides users with detailed information about individual entities, includ- ing the raw low-level event sequence data", "encoding": {"unit": {"field": "events", "type": "node"}, "color": {"field": "event type", "type": "nominal"}}}, "marks": ["unit"], "channels": ["unit", "color"], "dataTypes": ["node", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-3076_03", "figFile": "vis-3076_03.png", "figCaption": "", "figBox": {"x": 0.06267524381506219, "y": 0.4508109899422905, "width": 0.06148400728401743, "height": 0.2874880976996472}, "figVis": ["table"], "relationText": "Finally, the entity list view (Fig. 4(7)) presents a detailed profile of individual entities as determined by the current selection. This provides users with easy access to the raw underlying events within a given sequence (T5).", "note": "(O, N) for event sequence"}, {"viewId": "vis-3080_01_0", "viewFile": "vis-3080_01_0.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"facet": {"column": {"field": "type1", "type": "nominal"}}, "spec": {"mark": "area", "encoding": {"y": {"field": "time", "type": "ordinal"}, "x": {"field": "aggregate", "type": "quantitative"}}}}, {"mark": "bar", "encoding": {"x": {"field": "aggregate", "type": "quantitative"}, "y": {"field": "time", "type": "ordinal"}}}, {"mark": "bar", "encoding": {"x": {"field": "aggregate", "type": "quantitative"}, "y": {"field": "phrase type", "type": "nominal"}}}]}, "marks": ["area", "bar"], "channels": ["y", "x"], "dataTypes": ["ordinal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": [], "actionTargets": ["search-locate:Attributes-outliers", "consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-3080_01", "figFile": "vis-3080_01.png", "figCaption": "", "figBox": {"x": 0.13316779173637056, "y": 0.055659628551115614, "width": 0.3670645649977489, "height": 0.6932243279681286}, "figVis": ["bar_chart", "area_chart"], "relationText": "By perusing both the tag description and the encompassed text samples (Fig. 2(B.3)), the physician may be able to identify tagging mistakes on the go (G2).: anomaly\n\nBehind the time axis (Fig. 2(B.4)), a document histogram shows the number of documents at specified time intervals.: distribution\n\nThe Timeline provides a time-oriented overview of lists of tagged content encompassed by FCs (G5 G6), organized in three levels of detail (G3) (Fig. 4).: correlate", "note": ""}, {"viewId": "vis-3081_00_0", "viewFile": "vis-3081_00_0.png", "specification": {"nested": {"parent": {"mark": "sankey", "encoding": {"node": {"field": "partition", "type": "node"}, "link": {"field": "flow", "type": "relation", "remark": "", "encoding": {"width": {"field": "count", "type": "quantitative"}}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "rect", "remark": "Each stage is represented by a treemap which shows the frequency of events associated with a specific stage.", "encoding": {"y": {"field": "partition", "type": "nominal"}, "color": {"field": "deviation", "type": "quantitative"}}}}}}, "marks": ["sankey", "rect"], "channels": ["node", "link", "width", "y", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Graphs-clusters/groups"], "figId": "vis-3081_00", "figFile": "vis-3081_00.png", "figCaption": "", "figBox": {"x": -0.0023354100614195344, "y": 0.04154351269516276, "width": 0.988516510958415, "height": 0.5057062576630601}, "figVis": ["tree"], "relationText": "TPFlow supports a steerable and iterative workflow such that analysts can progressively divide the data into smaller subsets (R4) along different dimensions. To support this workflow, we visualize the successive subdivision of the tensor along different dimensions similar as in decision trees (R5). Each node in the tree represents a subset of data created in the partitioning process. Analysts can directly interact with the tree nodes to partition them further or select a few nodes to compare the latent patterns across different partitions.", "note": "(Q, C, N) for each node. Q: color. N: name. Q: count/height."}, {"viewId": "vis-3081_00_1", "viewFile": "vis-3081_00_1.png", "specification": {"facet": {"column": {"field": "data partition", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "value", "type": "quantitative"}, "y": {"field": "product", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3081_00", "figFile": "vis-3081_00.png", "figCaption": "", "figBox": {"x": 0.02693124846964727, "y": 0.5485938490161458, "width": 0.46340873508854813, "height": 0.22099192557230168}, "figVis": ["bar_chart"], "relationText": "", "note": "Q# = distribution + min/max. \n(Q#, N) for a view. "}, {"viewId": "vis-3081_00_2", "viewFile": "vis-3081_00_2.png", "specification": {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "value", "type": "quantitative"}, "color": {"field": "partition", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-correlation"], "figId": "vis-3081_00", "figFile": "vis-3081_00.png", "figCaption": "", "figBox": {"x": 0.023145767033697702, "y": 0.7757034144791003, "width": 0.4643279235986267, "height": 0.2091792298625291}, "figVis": ["line_chart"], "relationText": "", "note": ""}, {"viewId": "vis-3081_00_3", "viewFile": "vis-3081_00_3.png", "specification": {"layer": [{"mark": "geoshape"}, {"nested": {"parent": {"mark": "point", "encoding": {"longitude": {"field": "longitude", "type": "quantitative"}, "latitude": {"field": "latitude", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"mark": "arc", "encoding": {"size": {"field": "count", "type": "quantitative"}, "color": {"field": "type_category", "type": "nominal"}}}}}}]}, "marks": ["geoshape", "point", "arc"], "channels": ["longitude", "latitude", "size", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["layer", "nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-3081_00", "figFile": "vis-3081_00.png", "figCaption": "", "figBox": {"x": 0.5022657279776123, "y": 0.31649359554258905, "width": 0.49625212814187514, "height": 0.6838442137753278}, "figVis": ["map"], "relationText": "", "note": ""}, {"viewId": "vis-3088_00_0", "viewFile": "vis-3088_00_0.png", "specification": {"mark": "point", "remark": "The MDS projection of the embedding vectors", "encoding": {"x": {"field": "mds_x", "type": "quantitative"}, "y": {"field": "mds_x", "type": "quantitative"}, "color": {"field": "Anomaly Score", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-distribution", "query-summarize:Attributes-outliers"], "figId": "vis-3088_00", "figFile": "vis-3088_00.png", "figCaption": "", "figBox": {"x": 0.1696035417040568, "y": 0.004092443736263728, "width": 0.3221121240840947, "height": 0.5320725207937175}, "figVis": ["scatterplot"], "relationText": "To support visual analysis task T1, the scores of all CSTrees are visualized as points in a scatter plot (Fig. 6 (a)). \nT1: Gain an overview of the anomaly distribution.", "note": ""}, {"viewId": "vis-3088_00_1", "viewFile": "vis-3088_00_1.png", "specification": {"facet": {"field": "tree_id", "type": "ordinal", "columns": 4}, "spec": {"nested": {"parent": {"mark": "tree", "encoding": {"node": {"field": "topic", "type": "node"}, "link": {"field": "tree_hierarchy", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "point", "remark": "The area and color of a tree vertex encode the vertex weight and function name, respectively.", "encoding": {"color": {"field": "function name", "type": "nominal"}, "size": {"field": " vertex weight", "type": "quantitative"}}}}}}}, "marks": ["tree", "point"], "channels": ["node", "link", "color", "size"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["facet", "nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-order"], "figId": "vis-3088_00", "figFile": "vis-3088_00.png", "figCaption": "", "figBox": {"x": 0.4896600712919884, "y": 0.008111370119819933, "width": 0.5007798245255705, "height": 0.5307757617470408}, "figVis": ["tree"], "relationText": "To support visual analysis task T2, candidates are ranked according to their anomaly scores.\n\nT2: Order the CSTrees to focus on the top anomalies. The candidate anomaly list shows the summary structures of CSTrees with lowest anomaly scores.", "note": "a graph is repeated along O"}, {"viewId": "vis-3088_00_2", "viewFile": "vis-3088_00_2.png", "specification": {"nested": {"parent": {"mark": "tree", "encoding": {"node": {"field": "topic", "type": "node"}, "link": {"field": "tree_hierarchy", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"layer": [{"mark": "point", "remark": "The area and color of a tree vertex encode the vertex weight and function name, respectively.", "encoding": {"color": {"field": "function name", "type": "nominal"}, "size": {"field": "vertex weight", "type": "quantitative"}}}, {"mark": "graph", "encoding": {"node": {"field": "function", "type": "node"}, "link": {"field": "connection with root function", "type": "relation"}}}]}}}}, "marks": ["tree", "point", "graph"], "channels": ["node", "link", "color", "size"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["nested", "layer"], "aggregates": [], "actionTargets": ["consume-discover:Graphs-topology/structures"], "figId": "vis-3088_00", "figFile": "vis-3088_00.png", "figCaption": "", "figBox": {"x": 0.003158525379360001, "y": 0.5390921092694552, "width": 0.2988665925162694, "height": 0.4435764354228581}, "figVis": ["tree"], "relationText": "For this purpose we have devised both a subtree (T3) ... \nT3: Examine the detailed invocation structure of a CSTree of interest. \n\nFor a selected CSTree T , the complete structure is presented (see the left two views of Fig. 7). The area and color of a tree vertex encode the vertex weight and function name, respectively.", "note": "(q, n) == The area and color of a tree vertex. "}, {"viewId": "vis-3088_00_3", "viewFile": "vis-3088_00_3.png", "specification": {"layer": [{"mark": "icicle", "remark": "Each invoked function in the CSTree is shown as a rectangle whose horizontal start and end positions encode its entry and exit timestamps in the stack", "encoding": {"node": {"field": "start_time", "type": "node", "encoding": {"x": {"field": "start_time", "type": "temporal"}, "x2": {"field": "end_time", "type": "temporal"}, "color": {"field": "function type", "type": "nominal"}}}, "link": {"field": "hierarchy", "type": "relation"}}}, {"mark": "others", "remark": "messages are visualized as arrowed lines", "encoding": {"type": "link", "field": "messages"}}]}, "marks": ["icicle", "others"], "channels": ["node", "link", "x", "x2", "color", "type", "field"], "dataTypes": ["node", "relation", "temporal", "nominal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation"], "figId": "vis-3088_00", "figFile": "vis-3088_00.png", "figCaption": "", "figBox": {"x": 0.4180648178098612, "y": 0.5363920975097651, "width": 0.5699972247750602, "height": 0.4476282401981521}, "figVis": ["table"], "relationText": "T4: Examine the temporal patterns of a CSTree, including the message passings and execution durations. \nFor this purpose we have devised a timeline visualization (T4) to support the exploration of the structural and temporal pattern of a selected CSTree, respectively.", "note": "\u00a0(T,T,N) == start time,end time,color. "}, {"viewId": "vis-3089_00_0", "viewFile": "vis-3089_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "positionx", "type": "quantitative"}, "y": {"field": "positiony", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3089_00", "figFile": "vis-3089_00.png", "figCaption": "", "figBox": {"x": 0.5151921661946648, "y": 0.04129186096261819, "width": 0.19340972427104947, "height": 0.42705254741518067}, "figVis": ["scatterplot"], "relationText": "Figure 3 (A) shows that Overview depicts patients\u2019 differences by the distance between points.\nIn scatter plot, users can dimensionality reductionaw a polygonal area with a lasso dimensionality reductionawing tool. Once users complete dimensionality reductionawing, the points surrounded by the dimensionality reductionawn region are highlighted. In addition, other views quickly show a summary of the highlighted points", "note": ""}, {"viewId": "vis-3089_00_1", "viewFile": "vis-3089_00_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"facet": {"column": {"field": "disease", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}}, {"mark": "bar", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "y": {"field": "gender", "type": "nominal"}}}, {"mark": "area", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "y": {"field": "age", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"y": {"field": "diagnosis risks", "type": "quantitative"}}}]}, "marks": ["bar", "area"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["concat", "facet"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3089_00", "figFile": "vis-3089_00.png", "figCaption": "", "figBox": {"x": 0.7376888896332998, "y": 0.03240089064131378, "width": 0.23651630726394093, "height": 0.45166243945852147}, "figVis": ["area_chart", "bar_chart"], "relationText": "Users can see the distributions of age and gender in gender bar chart and age area chart, respectively. ", "note": ""}, {"viewId": "vis-3089_00_2", "viewFile": "vis-3089_00_2.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "area", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "aggregate", "type": "quantitative"}, "color": {"field": "medical code", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "disease", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}]}, "marks": ["area", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["search-locate:Attributes-extremes"], "figId": "vis-3089_00", "figFile": "vis-3089_00.png", "figCaption": "", "figBox": {"x": 0.03640616759620069, "y": 0.03467987113801748, "width": 0.45461541689529456, "height": 0.31845013044368026}, "figVis": ["area_chart", "line_chart", "table"], "relationText": "name of top contributing medical code\nIn contribution progress chart, users can see a temporal overview of nine selected medical contribution scores over sequences or time.\nBy clicking on one of the nine codes, users can also sort Patient List by the contribution scores of it.", "note": ""}, {"viewId": "vis-3089_00_3", "viewFile": "vis-3089_00_3.png", "specification": {"mark": "point", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "patient", "type": "nominal"}, "color": {"field": "rist", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3089_00", "figFile": "vis-3089_00.png", "figCaption": "", "figBox": {"x": 0.02842081790220012, "y": 0.37688344156410036, "width": 0.46208087897553857, "height": 0.28386003679864436}, "figVis": ["heatmap"], "relationText": "Patient List provides a list of selected patients, where users can explore and compare multiple patients.", "note": ""}, {"viewId": "vis-3089_00_4", "viewFile": "vis-3089_00_4.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "value1", "type": "quantitative"}, "y": {"field": "value2", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "value1", "type": "quantitative"}, "y": {"field": "value3", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "category1", "type": "nominal"}, "y": {"field": "variable1", "type": "quantitative"}}}]}, "marks": ["line", "bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3089_00", "figFile": "vis-3089_00.png", "figCaption": "", "figBox": {"x": 0.5093432344601002, "y": 0.5410758103952997, "width": 0.43847003637178966, "height": 0.43297784384464055}, "figVis": ["bar_chart", "line_chart"], "relationText": "In this way, users are able to observe correlation between contribution scores of medical codes and prediction risks. ", "note": ""}, {"viewId": "vis-3089_00_5", "viewFile": "vis-3089_00_5.png", "specification": {"mark": "unit", "encoding": {"x": {"field": "time", "type": "ordinal"}, "unit": {"field": "patient", "type": "node"}, "shape": {"field": "category1", "type": "nominal"}}}, "marks": ["unit"], "channels": ["x", "unit", "shape"], "dataTypes": ["ordinal", "node", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-values", "produce:Attributes-order"], "figId": "vis-3089_00", "figFile": "vis-3089_00.png", "figCaption": "", "figBox": {"x": 0.029473765995563925, "y": 0.6967057540913053, "width": 0.4392434668511545, "height": 0.20740543903643024}, "figVis": ["bar_chart"], "relationText": "In Patient Editor, users can provide feedback to the model (T7) by requesting to increase contribution scores of selected medical codes. In such activities mentioned above, users can test hypothetical scenarios.\n\nUser can sort medical codes of a visit either by contribution score (default) or by the code type. This layout enables users to easily select medical codes to make changes for interaction.", "note": "model steering -> compute derived value"}, {"viewId": "vis-3090_00_0", "viewFile": "vis-3090_00_0.png", "specification": {"nested": {"parent": {"mark": "bar", "encoding": {"y": {"field": "subnetwork", "type": "nominal"}, "x": {"field": "proportional to the total number of vulnerabilities", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "bar", "configuration": {"mark": "treemap", "encoding": {"node": {"field": "node_type", "type": "node"}, "link": {"field": "partition", "type": "relation"}}}}}}, "marks": ["bar", "treemap"], "channels": ["y", "x", "node", "link"], "dataTypes": ["nominal", "quantitative", "node", "relation"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["produce:Attributes-order", "search-locate:Attributes-outliers"], "figId": "vis-3090_00", "figFile": "vis-3090_00.png", "figCaption": "", "figBox": {"x": 0.054536563693916344, "y": 0.039077899122118176, "width": 0.9199695915202745, "height": 0.6217439534241076}, "figVis": ["bar_chart", "treemap"], "relationText": "The visualization prioritizes the sub-networks with highest number of vulnerabilities ordering them from the top to the bottom of the screen. \nThis visual encoding allows security managers to relate several values by looking at the visual elements, quickly identifying problematic nodes from a multidimensional point of view.\nOnce the security manager has made a selection, he or she can analyze the frequency distribution (Figure 1.E) of the vulnerabilities of the active selection (or the ones of the whole network if there is no active selection). Mouse-overing on a vulnerability triggers the list of its scores (Figure 1.H) and their plotting on the the radar-chart (Figure 1.G). ", "note": ""}, {"viewId": "vis-3090_00_1", "viewFile": "vis-3090_00_1.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "network vulnerabilities", "type": "nominal"}, "y": {"field": "frequency", "type": "quantitative"}, "color": {"field": "network vulnerabilities", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3090_00", "figFile": "vis-3090_00.png", "figCaption": "", "figBox": {"x": 0.33258344470159995, "y": 0.6944183533841343, "width": 0.31620549578135065, "height": 0.17986906652449047}, "figVis": ["bar_chart"], "relationText": "Once the security manager has made a selection, he or she can analyze the frequency distribution (Figure 1.E) of the vulnerabilities of the active selection (or the ones of the whole network if there is no active selection).", "note": ""}, {"viewId": "vis-3090_00_2", "viewFile": "vis-3090_00_2.png", "specification": {"mark": "radar", "layout": "circular", "encoding": {"theta": {"field": "metric_type", "type": "nominal"}, "radius": {"field": "metric_value", "type": "quantitative"}, "color": {"field": "network", "type": "nominal"}}}, "marks": ["radar"], "channels": ["theta", "radius", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3090_00", "figFile": "vis-3090_00.png", "figCaption": "", "figBox": {"x": 0.649601139782527, "y": 0.7046928237398459, "width": 0.1558003166619639, "height": 0.27298515527442324}, "figVis": ["polar_plot"], "relationText": "This mechanism allows for easily comparing multiple vulnerabilities by their representations in the radar-chart.", "note": ""}, {"viewId": "vis-3090_00_3", "viewFile": "vis-3090_00_3.png", "specification": {"facet": {"column": {"field": "metric", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "rect", "encoding": {"x": {"field": "score", "type": "nominal"}, "color": {"field": "selected", "type": "nominal"}}}, {"mark": "boxplot", "encoding": {"x": {"field": "flow_2", "type": "nominal"}}}]}}, "marks": ["rect", "boxplot"], "channels": ["x", "color"], "dataTypes": ["nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3090_00", "figFile": "vis-3090_00.png", "figCaption": "", "figBox": {"x": 0.3329186128320385, "y": 0.8829271523002673, "width": 0.3148914345555427, "height": 0.09945599981186166}, "figVis": ["box_plot", "matrix"], "relationText": "The metrics are divided in five intervals and their distribution is shown on box-plots; clicking on these elements permits filtering out the vulnerabilities that do not have a score belonging to the selected intervals.", "note": ""}, {"viewId": "vis-3091_00_0", "viewFile": "vis-3091_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"facet": {"row": {"field": "metric type", "type": "nominal"}}, "spec": {"mark": "area", "layout": "horizontal graph", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "value", "type": "quantitative"}}}}]}, "marks": ["bar", "area"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": ["bin", "count"], "actionTargets": ["search-locate:Attributes-outliers", "consume-present:Attributes-distribution"], "figId": "vis-3091_00", "figFile": "vis-3091_00.png", "figCaption": "", "figBox": {"x": 0.04357418223872687, "y": 0.1488664531720481, "width": 0.9187050729881253, "height": 0.29617905920711585}, "figVis": ["area_chart", "bar_chart"], "relationText": "The Event Search Page, shown in Fig. 3 presents the user with a visual\noverview of the data via a collection of scented widgets [53] that show\nthe data distribution of the most important fields while providing a\nway to quickly filter data in multiple coordinated views. \nA temporal histogram at the top of the page allows initial selection of a time range of\ninterest. ", "note": "IP detail page"}, {"viewId": "vis-3091_00_1", "viewFile": "vis-3091_00_1.png", "specification": {"facet": {"field": "metric type", "type": "nominal"}, "spec": {"mark": "bar", "encoding": {"x": {"field": "metric value", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["search-lookup:Attributes-values"], "figId": "vis-3091_00", "figFile": "vis-3091_00.png", "figCaption": "", "figBox": {"x": 0.053361410120170816, "y": 0.4593462886542712, "width": 0.3882091470153315, "height": 0.4933498271468223}, "figVis": ["bar_chart"], "relationText": "The selections in the bar charts/histograms determine which individual events are shown in the table", "note": ""}, {"viewId": "vis-3091_00_2", "viewFile": "vis-3091_00_2.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "node_type", "type": "node", "encoding": {"color": {"field": "ip type", "type": "nominal"}, "size": {"field": "distance to center", "type": "quantitative"}}}, "link": {"field": "network link", "type": "relation"}}}, "marks": ["graph"], "channels": ["node", "link", "color", "size"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-graphs"], "figId": "vis-3091_00", "figFile": "vis-3091_00.png", "figCaption": "", "figBox": {"x": 0.5417742595816208, "y": 0.48076719160029885, "width": 0.32786451413180334, "height": 0.46837113127450747}, "figVis": ["graph"], "relationText": "", "note": ""}, {"viewId": "vis-3094_03_0", "viewFile": "vis-3094_03_0.png", "specification": {"layer": [{"facet": {"layout": "mirrored", "row": {"field": "team", "type": "nominal"}}, "spec": {"mark": "sankey", "encoding": {"node": {"field": "player_type", "type": "node"}, "link": {"field": "transfer", "type": "relation"}}}}, {"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "defensive score", "type": "quantitative"}}}]}, "marks": ["sankey", "bar"], "channels": ["node", "link", "x", "y"], "dataTypes": ["node", "relation", "temporal", "quantitative"], "compositions": ["layer", "facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3094_03", "figFile": "vis-3094_03.png", "figCaption": "", "figBox": {"x": 0.28367856106121075, "y": 0.06991566712760623, "width": 0.6683599736793446, "height": 0.3873916872222923}, "figVis": ["graph", "sankey_diagram", "bar_chart"], "relationText": "In the formation view (Fig. 4(A)), we use a narrative timeline\n(Fig. 4(E)) to present the evolvement of game situations (G1).\n\nWe propose a novel design called formation\nflow (Fig. 4(F)) to intuitively exhibit the dynamic changing process of a\nteam\u2019s formations (G2)", "note": ""}, {"viewId": "vis-3094_03_1", "viewFile": "vis-3094_03_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "rect", "encoding": {"x": {"field": "team1", "type": "nominal"}, "y": {"field": "team2", "type": "nominal"}, "color": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"aggregate": "count", "type": "quantitative"}, "y": {"field": "formation_type", "type": "nominal"}, "color": {"field": "team", "type": "nominal"}}}]}, "marks": ["rect", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-values", "consume-present:Attributes-distribution"], "figId": "vis-3094_03", "figFile": "vis-3094_03.png", "figCaption": "", "figBox": {"x": 0.022427320002427982, "y": 0.06991566712760627, "width": 0.24630274215249945, "height": 0.38739168722229206}, "figVis": ["bar_chart", "matrix"], "relationText": "A confrontation matrix (Fig. 4(B)) is provided to show the frequencies of\nformations utilized by two teams and the distribution of formation pairs,\nwhich assists users in summarizing the difference between the formations of two teams (G4)", "note": ""}, {"viewId": "vis-3094_03_2", "viewFile": "vis-3094_03_2.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"facet": {"row": {"field": "play id", "type": "ordinal"}}, "spec": {"layer": [{"mark": "geoshape"}, {"mark": "point", "encoding": {"x": {"field": "x_position", "type": "quantitative"}, "y": {"field": "y_position", "type": "quantitative"}, "color": {"field": "team", "type": "nominal"}}}]}}, {"layer": [{"mark": "geoshape"}, {"mark": "point", "encoding": {"x": {"field": "x_position", "type": "quantitative"}, "y": {"field": "y_position", "type": "quantitative"}, "color": {"field": "team", "type": "nominal"}}}]}]}, "marks": ["geoshape", "point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "facet", "layer"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3094_03", "figFile": "vis-3094_03.png", "figCaption": "", "figBox": {"x": 0.027364725155918028, "y": 0.5171386780309354, "width": 0.5887576092243235, "height": 0.46946234649482943}, "figVis": ["graph", "scatterplot"], "relationText": "The display view\n(Fig. 4(G)) contains two parts: a display pitch and a statistical dashboard. The display pitch (Fig. 4(H)) supports the dynamic exhibition of the positions of players (G4).", "note": ""}, {"viewId": "vis-3094_03_3", "viewFile": "vis-3094_03_3.png", "specification": {"mark": "line", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "metric value", "type": "quantitative"}, "color": {"field": "team", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3094_03", "figFile": "vis-3094_03.png", "figCaption": "", "figBox": {"x": 0.6197606494181316, "y": 0.5138837773789718, "width": 0.3582409998361938, "height": 0.17110840346184006}, "figVis": ["line_chart"], "relationText": "The statistical dashboard (Fig. 4(I)) provides statistical analysis based on several key performance indicators\nand is coordinated with the display pitch (G4 and G5).", "note": ""}, {"viewId": "vis-3094_03_4", "viewFile": "vis-3094_03_4.png", "specification": {"mark": "radar", "layout": "circular", "encoding": {"x": {"field": "metric type", "type": "nominal"}, "y": {"field": "metric value", "type": "quantitative"}, "color": {"field": "team", "type": "nominal"}}}, "marks": ["radar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3094_03", "figFile": "vis-3094_03.png", "figCaption": "", "figBox": {"x": 0.6218395212917894, "y": 0.7185390200954387, "width": 0.3614547642563627, "height": 0.26196499858166344}, "figVis": ["polar_plot"], "relationText": "The statistical dashboard (Fig. 4(I)) provides statistical analysis based on several key performance indicators and is coordinated with the display pitch (G4 and G5).", "note": ""}, {"viewId": "vis-3097_00_0", "viewFile": "vis-3097_00_0.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "sankey", "encoding": {"node": {"field": "word", "type": "node"}, "link": {"field": "weight flow", "type": "relation"}}}, {"facet": {"column": {"field": "word", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "prediction score", "type": "nominal"}, "y": {"field": "sentence", "type": "nominal"}}}}]}, "marks": ["sankey", "bar"], "channels": ["node", "link", "x", "y"], "dataTypes": ["node", "relation", "nominal"], "compositions": ["concat", "facet"], "aggregates": [], "actionTargets": ["query-compare:Graphs-links/paths", "produce:Graphs-graphs"], "figId": "vis-3097_00", "figFile": "vis-3097_00.png", "figCaption": "", "figBox": {"x": 0.0575672481632294, "y": 0.23014819367139752, "width": 0.4261142663863433, "height": 0.47726071504383477}, "figVis": ["bar_chart", "sankey_diagram"], "relationText": "In the translation view (Fig. 7a), each functional stage of the seq2seq\nmodel is mapped to a visual encoding (T1, T2, G1).\n\nIn the upper part, the translation view provides a visual encoding for each of the model stages and fosters understanding and comparison tasks.", "note": ""}, {"viewId": "vis-3097_00_1", "viewFile": "vis-3097_00_1.png", "specification": {"layer": [{"mark": "point", "encoding": {"x": {"field": "word embedding projection x", "type": "quantitative"}, "y": {"field": "word embedding projection y", "type": "quantitative"}}}, {"mark": "graph", "encoding": {"node": {"field": "word", "type": "node"}, "link": {"field": "word order", "type": "relation"}}}]}, "marks": ["point", "graph"], "channels": ["x", "y", "node", "link"], "dataTypes": ["quantitative", "node", "relation"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["query-compare:Graphs-graphs", "query-identify:Attributes-values"], "figId": "vis-3097_00", "figFile": "vis-3097_00.png", "figCaption": "", "figBox": {"x": 0.4288828274140382, "y": 0.24326203948633113, "width": 0.19641216685363508, "height": 0.7398185745367032}, "figVis": ["graph"], "relationText": "To enable this comparison, we precompute the hidden states of a large set of example sentences (we use 50k sentences from the training set). ", "note": ""}, {"viewId": "vis-3181_01_0", "viewFile": "vis-3181_01_0.png", "specification": {"layer": [{"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, {"facet": {"field": "selected cells", "type": "nominal"}, "spec": {"facet": {"column": {"field": "feature types", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature value", "type": "quantitative", "bin": true}, "y": {"field": "relative frequency", "type": "quantitative"}, "color": {"field": "target/others", "type": "nominal"}}}}}]}, "marks": ["point", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["layer", "facet"], "aggregates": ["bin"], "actionTargets": ["search-lookup:Attributes-values", "query-identify:Attributes-clusters", "query-compare:Attributes-distribution"], "figId": "vis-3181_01", "figFile": "vis-3181_01.png", "figCaption": "", "figBox": {"x": 0.17736100094970872, "y": 0.019786782344276714, "width": 0.6370918180346588, "height": 0.9700368762482872}, "figVis": ["bar_chart", "scatterplot"], "relationText": "The feature contributions view (b) shows the measures of each feature\u2019s contribution to contrasting each cluster with the others: {contribution}: distribution, compare\n\nThe dimensionality reduction (DR) view (a) visualizes a result after DR and clustering: clustering\nFor a manual selection of a cluster, the system supports a rectangle selection: filter", "note": ""}, {"viewId": "vis-3181_01_1", "viewFile": "vis-3181_01_1.png", "specification": {"mark": "rect", "encoding": {"y": {"field": "feature", "type": "nominal"}, "x": {"field": "cluster", "type": "nominal"}, "color": {"field": "feature_contribution", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values", "search-explore:Attributes-outliers"], "figId": "vis-3181_01", "figFile": "vis-3181_01.png", "figCaption": "", "figBox": {"x": 0.8196110324370756, "y": 0.011391700638930025, "width": 0.17354867024223705, "height": 0.9724113782537179}, "figVis": ["heatmap"], "relationText": "The two remaining processes (i.e., finding features contrasting each cluster and comparing the features\u2019 values in detail) are performed with the features\u2019 contributions (FCs) view shown in Fig. 2b: compare, retrieve (values in detail)\n\nTo help find these patterns, our system applies reordering of the features (i.e, rows) and clusters (i.e., columns) based on the FCs: sort\n\nWe use a hierarchical clustering, specificallythe complete-linkage method [52], with the optimal-leaf-ordering [9]: cluster", "note": ""}, {"viewId": "vis-3184_00_0", "viewFile": "vis-3184_00_0.png", "specification": {"facet": {"row": {"field": "cluster", "type": "nominal", "sort": "relevance"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"y": {"field": "session", "aggregate": "count", "type": "quantitative"}, "x": {"field": "user", "type": "nominal", "sort": "y"}, "color": {"field": "anomaly_score", "aggregate": "median", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "task", "type": "nominal"}, "size": {"field": "user", "aggregate": "count", "type": "quantitative"}}}]}}, "marks": ["bar", "point"], "channels": ["y", "x", "color", "size"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": ["count", "median"], "actionTargets": ["consume-present:Attributes-clusters", "query-compare:Attributes-clusters"], "figId": "vis-3184_00", "figFile": "vis-3184_00.png", "figCaption": "", "figBox": {"x": -0.0019230826649488872, "y": -0.0011176618273988274, "width": 0.29643113686561656, "height": 0.5595825148886572}, "figVis": ["bar_chart", "scatterplot"], "relationText": "we display the number of users as text and the 10 most relevant users as rectangular glyphs: sort\n\nThis section discusses the visual design of user clusters to provide a summary of a cluster (addimensionality reductionessing T1) and to support comparison of multiple clusters (addimensionality reductionessing T2): compare, cluster", "note": "(group, [(user, height, lightness), (task, magnitude)])"}, {"viewId": "vis-3184_00_1", "viewFile": "vis-3184_00_1.png", "specification": {"facet": {"column": {"field": "feature", "type": "nominal"}, "row": {"field": "user", "type": "nominal", "sort": "relevance"}}, "spec": {"condition_1": {"test": "feature is per-profile feature", "value": {"mark": "bar", "encoding": {"x": {"field": "session_or_unique_action", "aggregate": "count", "type": "quantitative"}}}}, "condition_2": {"test": "feature is per-session quantitative feature", "value": {"layer": [{"mark": "area", "encoding": {"x": {"field": "feature_value", "bin": true, "type": "quantitative"}, "y": {"field": "density", "type": "quantitative"}}, "remark": "KDE is applied"}, {"mark": "point", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}, "y": {"field": "random_noise", "type": "quantitative", "remark": "A random noise is added to the vertical position of the dots to avoid overplotting"}}}]}}, "condition_3": {"test": "feature is per-session nominal feature", "value": {"layer": [{"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}, "y": {"field": "random_noise", "type": "quantitative", "remark": "A random noise is added to the vertical position of the dots to avoid overplotting"}}}]}}}}, "marks": ["bar", "area", "point"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet", "layer"], "aggregates": ["count", "bin"], "actionTargets": ["search-browse:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3184_00", "figFile": "vis-3184_00.png", "figCaption": "", "figBox": {"x": 0.29422907466524306, "y": 0.005771521368406322, "width": 0.6895805932002512, "height": 0.5444033484693048}, "figVis": ["bar_chart", "line_chart", "scatterplot"], "relationText": "Thus, it is essential for analysts to observe many features of user profile concurrently (addimensionality reductionessing T3): derived features\nThe visual profiles are then stacked together to enable comparison (Fig. 4) (addimensionality reductionessingT4,T5) and are sorted using the same relevance metric described: compare, sort\nIt is also possible to brush a range of sessions, possibly from multiple users, to explore and compare their features (addimensionality reductionessing T7): filter", "note": ""}, {"viewId": "vis-3184_00_2", "viewFile": "vis-3184_00_2.png", "specification": {"mark": "bar", "encoding": {"y": {"field": "session", "aggregate": "count", "type": "quantitative"}, "x": {"field": "time", "type": "temporal", "sort": "y"}, "color": {"field": "anomaly_score", "aggregate": "median", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "temporal"], "compositions": [], "aggregates": ["count", "median"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3184_00", "figFile": "vis-3184_00.png", "figCaption": "", "figBox": {"x": -0.0038528541559443154, "y": 0.5545083409745161, "width": 0.9962674056128401, "height": 0.14452812307207905}, "figVis": ["bar_chart"], "relationText": "Fig. 1 (middle row) shows a distribution of all ses-sions in the entire dataset over time with a histogram: distribution, correlate\n", "note": "\nA little confused how to represent this histogram with \"#\""}, {"viewId": "vis-3184_00_3", "viewFile": "vis-3184_00_3.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "action_time", "type": "temporal"}, "y": {"field": "session", "type": "nominal"}, "color": {"field": "action_type", "type": "nominal"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["search-explore:Attributes-values"], "figId": "vis-3184_00", "figFile": "vis-3184_00.png", "figCaption": "", "figBox": {"x": 0.004237649231477543, "y": 0.7129737586765699, "width": 0.8707963601162985, "height": 0.22863084485331128}, "figVis": ["unit_visualization"], "relationText": " This Session timeline view (Fig. 1 \u2013 bottom) allows exploration of the sessions {in detail} to investigate the actions that took place and to gain a closer understanding of how user tasks are accomplished: retrieve value", "note": "(ordered task, type)"}, {"viewId": "vis-3184_00_4", "viewFile": "vis-3184_00_4.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"layer": [{"mark": "bar", "encoding": {"y": {"field": "task", "type": "nominal"}, "x": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"y": {"field": "task", "type": "nominal"}, "x": {"aggregate": "count", "type": "quantitative"}}}]}, {"mark": "bar", "encoding": {"y": {"field": "task", "type": "nominal"}, "x": {"field": "action", "aggregate": "count", "type": "quantitative"}, "color": {"field": "action_type", "type": "nominal"}}}]}, "marks": ["bar"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat", "layer"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3184_00", "figFile": "vis-3184_00.png", "figCaption": "", "figBox": {"x": 0.8728872969719353, "y": 0.7110971674646764, "width": 0.12089680286871436, "height": 0.23478087808115128}, "figVis": ["bar_chart"], "relationText": "With this view here, we provide a detailed view of tasks and facilitate task comparison: compare", "note": "(left:[2, distribution], right:[task, group, number])"}, {"viewId": "vis-3186_00_0", "viewFile": "vis-3186_00_0.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "data_subset", "type": "node"}, "link": {"field": "belong_to", "type": "relation"}}}, "child": {"child_type": "configured", "configuration": {"mark": "bar", "encoding": {"y": {"field": "cell", "aggregate": "count", "type": "quantitative"}, "color": {"field": "subset", "type": "nominal"}}}}}}, "marks": ["graph", "bar"], "channels": ["node", "link", "y", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["nested"], "aggregates": ["count"], "actionTargets": ["search-lookup:Graphs-links/paths"], "figId": "vis-3186_00", "figFile": "vis-3186_00.png", "figCaption": "", "figBox": {"x": 0.006279045680494761, "y": 0.041274595126274675, "width": 0.1531928909298467, "height": 0.6179396944098297}, "figVis": ["tree", "bar_chart"], "relationText": "This allows users to track their progress, and to maintain an overview of their data faceting and analysis steps they have performed (T5) (i.e., allowing users to look up results from past analysis steps to recover or re-execute them with a different image or in a different setting).", "note": "(node: (color, shadow area), tree)\ntask: interaction"}, {"viewId": "vis-3186_00_1", "viewFile": "vis-3186_00_1.png", "specification": {"nested": {"parent": {"mark": "line", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}, "y": {"field": "feature", "type": "nominal"}, "color": {"field": "subset", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "axis", "configuration": {"mark": "area", "encoding": {"x": {"field": "feature_value", "bin": true, "type": "quantitative", "remark": "square root scaling"}, "y": {"field": "density", "type": "quantitative"}}}}}}, "marks": ["line", "area"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["nested"], "aggregates": ["bin"], "actionTargets": ["search-explore:Attributes-distribution"], "figId": "vis-3186_00", "figFile": "vis-3186_00.png", "figCaption": "", "figBox": {"x": 0.6769249470156525, "y": 0.04243896961820063, "width": 0.10844096291581101, "height": 0.7532241605811}, "figVis": ["parallel_coordinate", "area_chart"], "relationText": "For the exploration of each chan-nel\u2019s distribution, we integrated a ridgeplot (see Fig. 6) that comprises multiple area charts alongside relevant information about the variablebeing examined (T5): distribution\n\nEach ridge is equipped with range sliders, allowing to filter theunderlying data with visual feedback at the level of the distribution (T3): filter", "note": "PCP + ridge plot\n(line, y, color, ridge plot)\nridge plot is #Q"}, {"viewId": "vis-3186_00_2", "viewFile": "vis-3186_00_2.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "subset", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-clusters"], "figId": "vis-3186_00", "figFile": "vis-3186_00.png", "figCaption": "", "figBox": {"x": 0.7998371027293382, "y": 0.04483943577077759, "width": 0.19752917681937432, "height": 0.5642643668183551}, "figVis": ["scatterplot"], "relationText": "We vi-sualize higher-order similarities and differences between data subsets(T5) using dimensionality reduction techniques and subsequent displayin a 2D scatterplot: cluster\n\nWe support filtering ofcell groupings in our projection views by polygon selection, similar tothe image-based selection mechanisms (Section 5.2): filter", "note": ""}, {"viewId": "vis-3186_00_3", "viewFile": "vis-3186_00_3.png", "specification": {"facet": {"column": {"field": "different_rendering_channel_combination", "type": "nominal"}}, "spec": {"mark": "point", "encoding": {"y": {"field": "rendering_channel_1", "type": "quantitative"}, "x": {"field": "rendering_channel_2", "type": "quantitative"}, "color": {"field": "subset", "type": "nominal"}}}}, "marks": ["point"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3186_00", "figFile": "vis-3186_00.png", "figCaption": "", "figBox": {"x": 0.7978550834259152, "y": 0.6274339864490311, "width": 0.1908658394044449, "height": 0.15999539631958726}, "figVis": ["scatterplot"], "relationText": "Small-multiple scatterplots show correlations of active rendering channels: correlate", "note": ""}, {"viewId": "vis-3186_00_4", "viewFile": "vis-3186_00_4.png", "specification": {"facet": {"column": {"field": "feature", "type": "nominal"}, "row": {"field": "cell", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}, "color": {"field": "subset", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["search-lookup:Attributes-values"], "figId": "vis-3186_00", "figFile": "vis-3186_00.png", "figCaption": "", "figBox": {"x": 0.0025483714404631653, "y": 0.8048408077140337, "width": 0.9895895691081844, "height": 0.1836180954661735}, "figVis": ["bar_chart"], "relationText": "Experts can sort, inspect, select,and manipulate individual values for each feature of a cell using theinteractive visual tabular display (see Fig. 1f): sort, filter\nThe main goal of the tabular view is a) detailed analysis and direct manipulation of individualcells, and b) allowing users access to the original data table: retrieve value", "note": "(x, y, color, bar length)"}, {"viewId": "vis-3187_00_0", "viewFile": "vis-3187_00_0.png", "specification": {"facet": {"row": {"field": "sentence", "type": "nominal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"facet": {"column": {"field": "word", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"y": {"field": "alignment_score", "type": "quantitative"}, "color": {"field": "type_of_event", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "importance_score", "type": "quantitative"}}}]}}, {"mark": "bar", "encoding": {"x": {"field": "label", "type": "nominal"}, "y": {"field": "importance", "type": "quantitative"}, "color": {"field": "label", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "instance", "aggregate": "count", "type": "quantitative"}, "color": {"field": "label", "type": "nominal"}, "texture": {"field": "correct_or_incorrect_prediction", "type": "nominal"}}}]}}, "marks": ["bar"], "channels": ["y", "color", "x", "texture"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["search-explore:Attributes-values"], "figId": "vis-3187_00", "figFile": "vis-3187_00.png", "figCaption": "", "figBox": {"x": 0.017253725391326996, "y": 0.015754587632710915, "width": 0.7845257505247875, "height": 0.5695807410627441}, "figVis": ["bar_chart", "glyph_based"], "relationText": "On the \u201cweight\u201d column wedisplay the relative importance of each prototype in determining thedifferent possible model outputs: importance -> derived value\n\nWe show a summary of the model decisions on those nearest neighbors as a stacked horizontal bar displayed on the \u201cprediction\u201d column (Fig. 4C): performance -> derived value\n\nThe list of prototypes can be sorted based on several different criteria to addimensionality reductioness a variety of analytic tasks.By default, the system sorts the prototypes based on their similarity.It performs a hierarchical clustering of the prototypes based on their distances in the latent space and obtains a linear order accordingly,similar as in [12]. Sorting based on similarity groups prototypes that resemble each other and it is therefore easier to spot redundancy (Q2).The user can also sort the prototypes by the accuracy of the prediction results. The most problematic ones can be brought to attention for further analysis (Q4): sort and cluster\n\nFilter the prototypes: filter\n\n", "note": "(N-row, [(word, color, alignment, importance), (color, height), (#prediction result)])"}, {"viewId": "vis-3187_00_1", "viewFile": "vis-3187_00_1.png", "specification": {"layer": [{"mark": "surface", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}, "surface": {"field": "probability_density", "type": "quantitative", "remark": "the contour maps which summarize the hidden state distribution of their neighborhoods"}, "color": {"field": "sentence", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}, "color": {"field": "sentence", "type": "nominal"}}}, {"mark": "graph", "encoding": {"node": {"field": "word", "type": "node", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}, "color": {"field": "sentence", "type": "nominal"}}}, "link": {"field": "word order", "type": "relation", "encoding": {"color": {"field": "sentence", "type": "nominal"}}}}, "remark": "The projected hidden states of a prototype are connected to form a trajectory"}]}, "marks": ["surface", "point", "graph"], "channels": ["x", "y", "surface", "color", "node", "link"], "dataTypes": ["quantitative", "nominal", "node", "relation"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["search-explore:Attributes-values"], "figId": "vis-3187_00", "figFile": "vis-3187_00.png", "figCaption": "", "figBox": {"x": 0.6840891204568121, "y": 0.43271346319818077, "width": 0.3055750711417437, "height": 0.5464769710758574}, "figVis": ["line_chart", "contour_graph"], "relationText": "The projected hidden states of a prototype are connected to form a trajectory. The trajectories help users identify significant changes in the hidden state vector, which usually indicate the occurrences of key events or substructures in a sequence [21] (Q5): anomalies\n\nWe design a projection visualization which combines the trajectories of the prototypes and the contour maps which summarize the hidden state distribution of their neighborhoods: distribution", "note": "(x, y, sequence of word, color)"}, {"viewId": "vis-3191_00_0", "viewFile": "vis-3191_00_0.png", "specification": {"facet": {"row": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "point", "aggregate": "count", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}, "y": {"field": "feature_value", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "color", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3191_00", "figFile": "vis-3191_00.png", "figCaption": "", "figBox": {"x": 0.008391401775787451, "y": 0.548037290472082, "width": 0.20011242584404357, "height": 0.4145745723589062}, "figVis": ["bar_chart"], "relationText": "The Point Selector, depicted in Figure 1 (D), provides a faceted filtering capability that allows users to dimensionality reductionill-down to specific sets of points based on feature attribute values: filter", "note": "(group of bar, (two player, #count of XX))"}, {"viewId": "vis-3191_00_1", "viewFile": "vis-3191_00_1.png", "specification": {"facet": {"row": {"field": "point", "type": "ordinal"}, "column": {"field": "set", "type": "ordinal"}}, "spec": {"layer": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "left_or_right_position", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "left_or_right_position", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}, "fill": {"field": "backhand_or_forehand", "type": "nominal"}}}]}}, "marks": ["line", "point"], "channels": ["x", "y", "color", "fill"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["query-identify:Attributes-correlation"], "figId": "vis-3191_00", "figFile": "vis-3191_00.png", "figCaption": "", "figBox": {"x": 0.22113165148235725, "y": 0.003600680107039153, "width": 0.7696200064693792, "height": 0.5090548032777075}, "figVis": ["line_chart"], "relationText": "\nEach chart also servesas a toggle button that includes or excludes that point from the ShotAnalyzer, allowing users to focus on a specific subset of points for amore detailed analysis: filter\n\nThe second is the Point Analyzer(B) that presents the user with several alternative small multiples views of every point in the match, including the ability to view points sequentially in a match or to cluster similarpoints using user-specified feature: cluster", "note": "(order of game, order of score, (left line, right line, x, y, lines:((color, circle type, line type), 4 lines))"}, {"viewId": "vis-3191_00_2", "viewFile": "vis-3191_00_2.png", "specification": {"facet": {"row": {"field": "point", "type": "ordinal"}, "column": {"field": "stroke type", "type": "nominal"}}, "spec": {"layer": [{"mark": "point", "encoding": {"longitude": {"field": "longitude", "type": "quantitative"}, "latitude": {"field": "latitude", "type": "quantitative"}, "color": {"field": "player", "type": "nominal"}, "fill": {"field": "backhand_or_forehand", "type": "nominal"}}}, {"mark": "line", "encoding": {"longitude": {"field": "court x", "type": "quantitative"}, "latitude": {"field": "court y", "type": "quantitative"}, "strokedash": {"field": "serve", "type": "nominal"}}, "remark": "ball trajectory"}]}}, "marks": ["point", "line"], "channels": ["longitude", "latitude", "color", "fill", "strokedash"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["query-identify:Attributes-values"], "figId": "vis-3191_00", "figFile": "vis-3191_00.png", "figCaption": "", "figBox": {"x": 0.2271401978703067, "y": 0.5337630905130919, "width": 0.7695587117179753, "height": 0.4186993850823792}, "figVis": ["map"], "relationText": "The Shot Analyzer, depicted in Figure 1 (C), helps them see the why by displaying individual shots for the points selected in the Point Analyzer: raw data", "note": "(n charts, (x, y, color, circle type, line type))"}, {"viewId": "vis-3192_04_0", "viewFile": "vis-3192_04_0.png", "specification": {"mark": "tree", "encoding": {"node": {"field": "player", "type": "node", "encoding": {"text": {"field": "win rate", "type": "quantitative"}}}, "link": {"field": "subdivision by types", "type": "relation"}}}, "marks": ["tree"], "channels": ["node", "link", "text"], "dataTypes": ["node", "relation", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-3192_04", "figFile": "vis-3192_04.png", "figCaption": "", "figBox": {"x": 0.025140813636472335, "y": 0.0701528764411009, "width": 0.30543504253738785, "height": 0.4572259123994678}, "figVis": ["tree"], "relationText": "Given the simple topology of the hierarchical structure, we employ a node-link tree rather than space-filling methods such as a treemap to present the hierarchical structure of matches in the player view (G1).\n\nG1: Visual organization of all matches for overview (R1). Since the result and players of a match are the most important information for experts to select matches to be analyzed(R1), an overview of all matches specified by the match score and characteristics of the players involved can facilitate the identification of matches of interest.", "note": "(Q, N): each person and score.\nFed into a graph"}, {"viewId": "vis-3192_04_1", "viewFile": "vis-3192_04_1.png", "specification": {"facet": {"row": {"field": "tactic", "type": "ordinal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "others", "encoding": {"text": {"field": "tec type"}, "column": {"field": "stroke number"}, "highlight_position": {"field": "stroke placement"}}}, {"mark": "arc", "encoding": {"theta": {"field": "scoring rate", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "usage rate", "type": "quantitative"}}}]}}, "marks": ["others", "arc", "bar"], "channels": ["text", "column", "highlight_position", "theta", "x"], "dataTypes": ["quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-order", "query-compare:Attributes-values"], "figId": "vis-3192_04", "figFile": "vis-3192_04.png", "figCaption": "", "figBox": {"x": 0.03047242292018138, "y": 0.5462395009171288, "width": 0.29946483469975993, "height": 0.4461719718219954}, "figVis": ["glyph_based", "bar_chart", "donut_chart"], "relationText": "The tactic view is a tactic list consisting of all the tactics used by the targeted player in the selected matches. These tactics are presented by icons of strokes (G6). They can be sorted based on scoring rates or utilization rates (G2) and classified according to rally phases.\n\nG2: Visual sorting and filtering of tactics for navigation (R2).: filter, sort\n\nG6: Representative icons of strokes and tactics (R2, R3, R4, R5, R6). Icons are effective for depicting physical objects and concepts [19]. Therefore, icon-based visualizations can facilitate exploration of strokes and tactics along with their utilization rates and scoring rates (R2, R3, and R5). In this manner, the adjustments can be evaluated and compared efficiently (R4), and the coaches and the players can easily understand the processes and results(R6).: compare", "note": "(N, Q, Q): tactic, scoring rate, utilization rate"}, {"viewId": "vis-3192_04_2", "viewFile": "vis-3192_04_2.png", "specification": {"facet": {"column": {"field": "stroke index", "type": "ordinal", "remark": "This view presents adjustment options for three consecutive strokes (a tactic) at a time "}}, "spec": {"facet": {"row": {"field": "tatic stroke", "type": "nominal", "remark": "Each item in the optional stroke list"}}, "spec": {"remark": "Each item in the optional stroke list consists of three components, namely, the stroke attributes, the scoring rate, and the adjustability from left to right (R3).", "concat": {"layout": "horizontal"}, "spec": [{"mark": "text", "encoding": {"text": {"field": "stroke attributes", "type": "nominal"}}}, {"mark": "others", "encoding": {"text": {"field": "tec type"}, "highlight_position": {"field": "stroke placement"}}}, {"mark": "arc", "encoding": {"theta": {"field": "scoring rate", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "adjustability", "type": "quantitative"}}}]}}}, "marks": ["text", "others", "arc", "bar"], "channels": ["text", "highlight_position", "theta", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-identify:Attributes-order"], "figId": "vis-3192_04", "figFile": "vis-3192_04.png", "figCaption": "", "figBox": {"x": 0.4261741939535652, "y": 0.08331807904021796, "width": 0.561306986418597, "height": 0.6254421342554094}, "figVis": ["glyph_based", "bar_chart", "donut_chart"], "relationText": "The simulation view consists of an exploration component (G3) (Fig. 5(D)).\nG3: Visual enumeration of stroke for exploration (R3). The explo- ration space of adjustments is enormous due to the diversity of strokes. Experts hope to explore the adjustments flexibly and efficiently. There- fore, the system should visually enumerate all optional adjustments in a particular order for experts to choose freely and support convenient sorting and filtering techniques to facilitate exploration.: sort, filter", "note": "(N, Q, Q, O): tactic, scoring rate, util rate, column"}, {"viewId": "vis-3192_04_3", "viewFile": "vis-3192_04_3.png", "specification": {"facet": {"row": {"field": "strategy index", "type": "ordinal", "remark": "displays the three optimum strategies generated by the system"}}, "spec": {"concat": {"layout": "vertical", "remark": "Each row contains an adjustment strategy and its effect and adjustability (Fig. 5(E1))."}, "spec": [{"mark": "others", "encoding": {"shape": {"field": "adjustment strategy", "type": "nominal"}}}, {"mark": "text", "encoding": {"text": {"field": "effect", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "adjustability", "type": "quantitative"}}}]}}, "marks": ["others", "text", "bar"], "channels": ["shape", "text", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3192_04", "figFile": "vis-3192_04.png", "figCaption": "", "figBox": {"x": 0.3406262770178052, "y": 0.7152498720415551, "width": 0.6452469067368849, "height": 0.2370383699965339}, "figVis": ["glyph_based", "bar_chart"], "relationText": "G4: Visual recording of adjustments for evaluation (R4). The effect of an adjustment strategy is important for evaluation (R4). Experts hope to simultaneously evaluate both the effect and feasibility of each strategy. Besides, they also require to compare different strategies to identify the optimal or practical one. Therefore, it is necessary to have an independent view to save the applied adjustments for subsequent evaluation and comparison.: compare", "note": "(O, N): the strategy in each cell (a sequence)\n((O, N), O): each row.\n(((O, N), O), Q, Q): each row with the rightmost two charts\nrepeated along row => O"}, {"viewId": "vis-3197_00_0", "viewFile": "vis-3197_00_0.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "plan", "type": "node"}, "link": {"field": "difference between plans", "type": "relation", "encoding": {"color": {"field": "plan type", "type": "nominal"}, "shape_color": {"field": "configure/infinite", "type": "nominal"}}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "performance indicators type", "type": "nominal", "remark": "The upper part is a bar chart that shows the four key performance indicators suggested by the domain experts, including order delay rate (red), the production cost (blue), the inventory cost (green), and the smoothing rate of production capacity use (purple)"}, "y": {"field": "performance indicators value", "type": "quantitative"}, "color": {"field": "performance indicators type", "type": "nominal"}}}, {"mark": "point", "encoding": {"x": {"field": "configuration data type", "type": "nominal", "remark": "The lower part uses light orange circles to represent four kinds of configuration data. These circles, from left to right, indicate the order demand, the initial inventory of raw materials, the available production capacity, and the number of holidays, respectively.)"}, "size": {"field": "configuration data value", "type": "quantitative"}}}]}}}}, "marks": ["graph", "bar", "point"], "channels": ["node", "link", "color", "shape_color", "x", "y", "size"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["nested", "concat"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3197_00", "figFile": "vis-3197_00.png", "figCaption": "", "figBox": {"x": 0.1991259545187751, "y": 0.008251216159260262, "width": 0.7963789784969924, "height": 0.18585639675935092}, "figVis": ["bar_chart", "graph"], "relationText": "The plan overview utilizes timeline-based glyphs to present the sum- marized information of various production plans and their differences. The view can reveal the macroscopic impact of configuration changes, including improving the plan and simulating unanticipated incidents in the market or the plant (R6, R7). In addition, it displays the recorded planning history which enables users to progressively optimize the plan (R1). The visual design is composed of plan glyphs and the links between them. For visual comparison [11], we adopt juxtaposition between plan glyphs and explicit encoding in links (R8).: compare", "note": "[(N, Q), (N, Q)] => upper bar and lower circle.\nInto a node-link graph"}, {"viewId": "vis-3197_00_1", "viewFile": "vis-3197_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "product metric type", "type": "nominal"}, "y": {"field": "product metric value", "type": "quantitative"}}}, {"facet": {"field": "router id", "columns": 5, "type": "ordinal"}, "spec": {"mark": "others", "encoding": {"theta_1": {"field": "product properties", "type": "nominal"}, "color_1": {"field": "product properties", "type": "nominal"}, "sector_line": {"field": "performance indicator", "aggregate": "average", "type": "nominal"}, "saturation": {"field": "", "type": "nominal"}, "radius": {"field": "", "type": "nominal"}}}}]}, "marks": ["line", "others"], "channels": ["x", "y", "theta_1", "color_1", "sector_line", "saturation", "radius"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": ["average"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3197_00", "figFile": "vis-3197_00.png", "figCaption": "", "figBox": {"x": 0.1998453140585235, "y": 0.18542016384379106, "width": 0.7977919940333876, "height": 0.2838394092912528}, "figVis": ["parallel_coordinate", "pie_chart"], "relationText": "The view can display the distribution of all the products (R2) and support filtering and selecting for further exploration (R3).: filter, distribution\n\nIt provides mesoscopic information on the product level for comparative analysis of two plans (R8), and gives support to the improvement and simulation of production planning (R6, R7).: compare", "note": "the middle is a parallel coordinates plot.\nRight glyph:\n(N,Q,Q,Q,Q) => each sector (performance indicator, avg., difference, variance).\nDo not mark it as q# due to the special consideration"}, {"viewId": "vis-3197_00_2", "viewFile": "vis-3197_00_2.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "graph", "encoding": {"node": {"field": "router", "type": "node"}, "link": {"field": "router relation", "type": "relation"}}}, {"facet": {"row": {"field": "router", "type": "ordinal"}}, "spec": {"encoding": {"x": {"field": "time", "type": "temporal"}}, "concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "remark": "In each plant, the downward bars indicate the daily production output of the product and the upward bars indicate the use of the corresponding capacity set", "encoding": {"color": {"field": "order delay", "type": "nominal"}, "x": {"field": "time", "type": "temporal"}, "y": {"field": "order delay rate", "type": "quantitative"}}}, {"facet": {"row": {"field": "daily performance indicator type", "type": "nominal", "remark": "daily performance indicators, namely, the order delay rate, the production cost, the inventory cost, and the smoothing rate of production capacity use, from top to bottom"}}, "spec": {"mark": "rect", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "daily performance indicator value", "type": "quantitative"}, "color": {"field": "daily performance indicator type", "type": "nominal"}}}}, {"mark": "line", "encoding": {"color": {"field": "last plan or current plan", "type": "nominal", "remark": ""}, "x": {"field": "time", "type": "temporal"}, "y": {"field": "daily production in a plant", "type": "quantitative"}}}, {"mark": "bar", "remark": "In each plant, the downward bars indicate the daily production output of the product and the upward bars indicate the use of the corresponding capacity set", "encoding": {"color": {"field": "daily production or use of the corresponding capacity set", "type": "nominal", "remark": ""}, "x": {"field": "time", "type": "temporal"}, "y": {"field": "production value", "type": "quantitative"}}}]}}]}, "marks": ["graph", "bar", "rect", "line"], "channels": ["node", "link", "x", "color", "y"], "dataTypes": ["node", "relation", "temporal", "nominal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": [], "actionTargets": ["consume-discover:Graphs-topology/structures", "query-compare:Attributes-similarity"], "figId": "vis-3197_00", "figFile": "vis-3197_00.png", "figCaption": "", "figBox": {"x": 0.19935920214815342, "y": 0.46979405805916863, "width": 0.7977187133422204, "height": 0.5098304196482801}, "figVis": ["graph", "bar_chart", "line_chart", "heatmap"], "relationText": "The production detail view can be divided into the left and right parts. The left side is a dependency tree visualization, which reveals the dependency between products (R4). : graph-related\n\nThe right side is extended bar charts, which visualize the daily production information of the selected product in related factories (R5). The visual design discloses the microscopic differences between two production planning strategies (R8). It can further help guide the improvement of the production plan (R6) and reveal the impact of an unanticipated incident (R7).: {difference} compare", "note": "(Q,Q,Q,Q,Q): each cell => last plan, current plan, prod volume, capacity, change"}, {"viewId": "vis-3198_03_0", "viewFile": "vis-3198_03_0.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "frequency", "type": "ordinal"}, "y": {"field": "time", "type": "temporal"}, "color": {"field": "level", "type": "ordinal"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "temporal"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-correlation"], "figId": "vis-3198_03", "figFile": "vis-3198_03.png", "figCaption": "", "figBox": {"x": 0.18591803980275254, "y": 0.08155670432898174, "width": 0.8037415450633938, "height": 0.147849480101123}, "figVis": ["heatmap"], "relationText": "Situation monitoring view adopts the design idea of level-progressive heatmap to present an overview of the current electromagnetic situation and its recent change trend (Figure 4(b)).: {monitor raw data} retrieve value, {trend} correlate", "note": "(T, O, O): x-ordinal, y-time, cell-ordinal (1-5 score)"}, {"viewId": "vis-3198_03_1", "viewFile": "vis-3198_03_1.png", "specification": {"nested": {"parent": {"mark": "line", "encoding": {"x": {"field": "frequency", "type": "ordinal"}, "y": {"field": "time", "type": "temporal"}}}, "child": {"child_type": "configured", "canvas": "line", "configuration": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "STR", "type": "quantitative"}, "color": "blue"}}, {"mark": "line", "encoding": {"color": {"field": "is_authorized", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "SNR", "type": "quantitative"}, "color": "grey"}}]}}}}, "marks": ["line", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "temporal"], "compositions": ["nested", "concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3198_03", "figFile": "vis-3198_03.png", "figCaption": "", "figBox": {"x": 0.1895146166163091, "y": 0.22758342583702562, "width": 0.8076492045154718, "height": 0.7673458530191652}, "figVis": ["area_chart"], "relationText": "Signal monitoring view depicts the distribution of all signals in time and frequency as well as the time-varying patterns of the signals\u2019 char- acteristics.: ditribution", "note": "(Q,Q,N,Q): each cell. STR, SNR, is_authorized, bandwith\nfor x-axis (frequency) and y (time)"}, {"viewId": "vis-3199_00_0", "viewFile": "vis-3199_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "return", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-clusters"], "figId": "vis-3199_00", "figFile": "vis-3199_00.png", "figCaption": "", "figBox": {"x": 0.008822534896872264, "y": 0.06479192082548497, "width": 0.24942135324816847, "height": 0.36094717875090265}, "figVis": ["scatterplot"], "relationText": "We provide a portfolio cluster view for users to observe similar portfolios efficiently. The market changes every day, which means different time periods may have different patterns and insights, such as different portfolio clustering results (T3).", "note": ""}, {"viewId": "vis-3199_00_1", "viewFile": "vis-3199_00_1.png", "specification": {"nested": {"parent": {"mark": "rect", "encoding": {"x": {"field": "factor types", "type": "nominal", "remark": "The x- and y-axes of the heat map encode the factor types, from right to left and from top to bottom, respectively in the same order."}, "y": {"field": "factor types", "type": "temporal"}, "color": {"field": "correlation", "type": "quantitative", "remark": "The color of each block, in the heat map, encodes the correlation between the corresponding two factors"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "line", "remark": "the trends of the correlations in greater details", "encoding": {"x": {"field": "time", "type": "quantitative"}, "y": {"field": "value", "type": "quantitative"}}}}}}, "marks": ["rect", "line"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "temporal", "quantitative"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation"], "figId": "vis-3199_00", "figFile": "vis-3199_00.png", "figCaption": "", "figBox": {"x": 0.01125370353782025, "y": 0.42827303449276727, "width": 0.2470102988323537, "height": 0.2869320684669223}, "figVis": ["line_chart", "matrix", "heatmap"], "relationText": "The factor correlation view (Fig.1B) shows the market performance of the risk factors, in terms of the cumulative market return of each factor and the correlations between these factor returns. This information helps the user to see the effectiveness of a factor model in a specified time period (T1), as well as any investment trends among fund man- agers for potential factor crowding (T2), which may affect the return of a portfolio in the near future (T6).: correlate", "note": "((O,Q), Q): each cell is a line (O,Q) and background (Q)"}, {"viewId": "vis-3199_00_2", "viewFile": "vis-3199_00_2.png", "specification": {"facet": {"column": {"field": "cluster_id", "type": "nominal", "remark": "Each region is dedicated to one cluster of portfolios, which is formerly selected in the portfolio cluster view."}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "remark": "Within a region, the cumulative returns of all the portfolios are displayed at the top", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "cumulative returns", "type": "quantitative"}}}, {"facet": {"row": {"field": "protofolio_id", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"remark": "ten co-centrical circular axes, in the factor signature, representing the factor exposure values of the ten risk factors", "mark": "line", "layout": "circular", "encoding": {"x": {"field": "risk factors", "type": "nominal"}, "y": {"field": "factor exposure value", "type": "quantitative"}}}, {"remark": "a horizon graph that encodes seven portions of a portfolio", "shape": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "value of portions", "type": "quantitative"}, "row": {"field": "one of seven portions", "type": "nominal"}}}]}}]}}, "marks": ["line"], "channels": ["x", "y", "row"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3199_00", "figFile": "vis-3199_00.png", "figCaption": "", "figBox": {"x": 0.2631091420794671, "y": 0.06980515049359891, "width": 0.725790047852558, "height": 0.6295618562973527}, "figVis": ["polar_plot", "line_chart", "area_chart"], "relationText": "The comparison view provides overviews of various portfolios, which reveals the general patterns in the portfolios, at a glance (T3) and enabling users to compare risk and industry preference quickly between portfolios (T4).", "note": "(N, Q, N) => circular parallel coordinate in the upper\nlower is a horizon graph (T, Q, N)\no => the comparison view is divided into regions that are horizontally juxtaposed to each other and that extend from left to right. "}, {"viewId": "vis-3199_00_3", "viewFile": "vis-3199_00_3.png", "specification": {"layer": [{"mark": "area", "remark": "In the background, the height of the theme river represents the portion of the total investment.", "encoding": {"y": {"type": "quantitative", "field": "portion of the total investment"}, "x": {"type": "temporal", "field": "time"}}}, {"mark": "point", "encoding": {"y": {"field": "stock", "type": "nominal"}, "x": {"type": "temporal", "field": "time"}}}], "resolve": {"scale": {"y": "independent"}}}, "marks": ["area", "point"], "channels": ["y", "x"], "dataTypes": ["quantitative", "temporal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3199_00", "figFile": "vis-3199_00.png", "figCaption": "", "figBox": {"x": 0.018366499925247998, "y": 0.7193800891190609, "width": 0.9661289565151312, "height": 0.26134750889708974}, "figVis": ["area_chart", "line_chart"], "relationText": "The individual portfolio view displays the management details of a portfolio, at the stock holding level, which helps the users further examine and confirm the portfolio\u2019s strategy (T4) and the style in which the portfolio is managed (T5).", "note": "In the individual portfolio view ( Fig.1D), there is one horizontal axis that encodes the timeline and two vertical axes, repre- senting the stock percentages and the total percentage of investment, respectively. Note that there are two sets of information in the graph: the background and the foreground. In the background, the height of the theme river represents the portion of the total investment. It also corresponds to the vertical axis on the right-hand side.\nIn the foreground, there are multiple horizontal sticks stacked from bottom up, at each timestamp, each of them represents a particular stock.\n\n[(T, Q, N), (T, Q)] for front/back."}, {"viewId": "vis-3202_00_0", "viewFile": "vis-3202_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "x", "type": "quantitative"}, "y": {"field": "y", "type": "quantitative"}, "color": {"field": "performance", "type": "quantitative", "remark": "Darkness of circles encodes performance of the models"}, "size": {"field": "number of parameters", "type": "quantitative", "remark": "radius encodes the number of parameters"}}}, "marks": ["point"], "channels": ["x", "y", "color", "size"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["search-lookup:Attributes-extremes"], "figId": "vis-3202_00", "figFile": "vis-3202_00.png", "figCaption": "", "figBox": {"x": 0.0003935917489274725, "y": 0.0030942024175464587, "width": 0.2500858514148707, "height": 0.3663987229151842}, "figVis": ["scatterplot"], "relationText": "First, they find a baseline model by visually exploring a set of pre-trained models in the Model Overview [T1], seen in Figure 1A. ", "note": "The darkness of the circle encodes the accuracy of the architecture on a held out dataset, with darker circles corresponding to better accuracy. The radius of the circle encodes the log of the number of parameters: filter"}, {"viewId": "vis-3202_00_1", "viewFile": "vis-3202_00_1.png", "specification": {"facet": {"row": {"field": "model", "type": "nominal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "others", "encoding": {"shape": {"field": "model structure", "type": "nominal"}}}, {"mark": "text", "encoding": {"text": {"field": "val acc", "type": "quantitative"}}}, {"mark": "text", "encoding": {"text": {"field": "num of parameters", "type": "quantitative"}}}]}}, "marks": ["others", "text"], "channels": ["shape", "text"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3202_00", "figFile": "vis-3202_00.png", "figCaption": "", "figBox": {"x": 0.0003469369182007185, "y": 0.38366203127662213, "width": 0.2515085789380592, "height": 0.6132577766214908}, "figVis": ["bar_chart"], "relationText": "They select models of interest by clicking on their respec- tive circles, placing them into the Model Drawer, seen in Figure 1B. By mousing over models in the overview and scanning the Model Drawer, users can visually compare models of interest [T2]: compare", "note": ""}, {"viewId": "vis-3203_00_0", "viewFile": "vis-3203_00_0.png", "specification": {"facet": {"column": {"field": "year", "type": "temporal"}}, "spec": {"mark": "boxplot", "encoding": {"x": {"field": "type", "type": "nominal", "remark": "Blue shows unlabeled accounts, green for genuine accounts, and purple indicates spambots"}, "color": {"field": "type", "type": "nominal"}}}}, "marks": ["boxplot"], "channels": ["x", "color"], "dataTypes": ["nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3203_00", "figFile": "vis-3203_00.png", "figCaption": "", "figBox": {"x": -0.00260803382200541, "y": 0.0017719543329150751, "width": 0.7817436275398273, "height": 0.34350897428358523}, "figVis": ["box_plot"], "relationText": "The timeline view visualizes the distribution of time series features that represent Twitter accounts at three different aggregation levels.", "note": "Q# => box-plot"}, {"viewId": "vis-3203_00_1", "viewFile": "vis-3203_00_1.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "performance", "type": "quantitative", "remark": "Darkness of circles encodes performance of the models"}, "size": {"field": "tweet count feature", "type": "quantitative", "remark": "The bubble size represents the tweet count feature of each account."}}}, "marks": ["point"], "channels": ["x", "y", "color", "size"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-3203_00", "figFile": "vis-3203_00.png", "figCaption": "", "figBox": {"x": -0.001304996722689519, "y": 0.3496621680980622, "width": 0.25770185976477183, "height": 0.3420168220528869}, "figVis": ["scatterplot"], "relationText": "VASSL visualizes the results of the dimensionality reduction (DR) techniques, explained in Section 4, in a 2D scatterplot (Fig. 1 (B)). The effectiveness of 2D scatterplots in visualizing DR results, while maintaining cluster separability has been shown in [32]. Our scatterplot allows exploring similarities among accounts (R1), which are color- coded according to their class.\n\nSimilar to the timeline view, users can select accounts by clicking or brushing. Moreover, the view can be panned and zoomed as needed.", "note": ""}, {"viewId": "vis-3203_00_2", "viewFile": "vis-3203_00_2.png", "specification": {"mark": "point", "encoding": {"x": {"field": "polarity", "type": "quantitative"}, "y": {"field": "subjectivity", "type": "quantitative"}, "color": {"field": "performance", "type": "quantitative", "remark": "Darkness of circles encodes performance of the models"}, "size": {"field": "scores", "type": "quantitative", "remark": "The topics clustering view with one topic selected. The bubble chart in the bottom shows the topics with bubble size communicating topics scores."}}}, "marks": ["point"], "channels": ["x", "y", "color", "size"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-3203_00", "figFile": "vis-3203_00.png", "figCaption": "", "figBox": {"x": 0.5227939817159952, "y": 0.47585416407339093, "width": 0.25974595884055796, "height": 0.2177116050722937}, "figVis": ["scatterplot", "word_cloud"], "relationText": "The first visualization is a bubble chart that represents the generated latent topics in a two-dimensional space (Fig. 1 (D)).\n\nThe second visualization in the topic clustering view is a word cloud visualization of the most frequent words in generated topics.  LDA computes probabilities that show the distribution of these words in each topic.: distribution\n\nUsers can interact with the topics bubble chart in multiple ways. Beside zooming and panning, the visualization supports selection and brushing of topics, which allows for exploration of each topic\u2019s words. When selecting multiple topics, VASSL aggregates words\u2019 probabilities to show their relevance to all selected topics (Fig.4).: filter\n\nIn other words, we can consider the topics as clusters where a single user can belong to more than one cluster (fuzzy clustering). Changing the threshold controls the sensitivity of cluster membership", "note": ""}, {"viewId": "vis-3203_00_3", "viewFile": "vis-3203_00_3.png", "specification": {"facet": {"column": {"field": "feature", "type": "nominal", "remark": "tweet_count OR retweet_count OR reply_count"}}, "spec": {"mark": "line", "remark": "The Feature explorer view using a modified violin plot. The lines represent a kernel density estimation of classes PDFs.", "encoding": {"x": {"field": "PDF", "type": "quantitative"}, "y": {"field": "count", "type": "quantitative"}}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3203_00", "figFile": "vis-3203_00.png", "figCaption": "", "figBox": {"x": 0.0054365072696661585, "y": 0.690808322150223, "width": 0.771023252626255, "height": 0.29052496519572996}, "figVis": ["line_chart"], "relationText": "The Feature Explorer view visualizes the distribution of accounts in selected features using a new design based on a violin plot (see Fig. 5). We used a violin plot instead of a box plot to enable the user to examine multi-modality in any feature [18], which could indicate a potential cluster (R1, R4)", "note": "q# => violin plot\n"}, {"viewId": "vis-3205_00_0", "viewFile": "vis-3205_00_0.png", "specification": {"facet": {"row": {"field": "video", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "coherence score", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "modal", "type": "nominal"}, "color": {"field": "emotion type", "type": "nominal"}}}]}}, "marks": ["line", "rect"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-3205_00", "figFile": "vis-3205_00.png", "figCaption": "", "figBox": {"x": -4.048681437135365e-05, "y": 0.05386227799092779, "width": 0.24907248572230548, "height": 0.6623663718811559}, "figVis": ["line_chart", "matrix"], "relationText": "T1 To summarize emotion information in a video.\nT2 To provide video context for the analysis.\n\nThe video view (Fig. 1a) presents a list of videos that provides a quick overview of the emotion status of the three channels of each video (T1). {emotion status} derive value\n\nThe video view presents the selected video at the bottom to help users directly observe the original information about the video (T2). {raw data} retrieve value", "note": "([(line chart), (bar codeo chart)], items)"}, {"viewId": "vis-3205_00_1", "viewFile": "vis-3205_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"facet": {"field": "video segment node", "type": "nominal"}, "spec": {"mark": "treemap", "encoding": {"node": {"field": "face type", "type": "node", "encoding": {"size": {"aggregate": "count", "type": "quantitative"}}}, "link": {"field": "emotion hierarchy", "type": "relation"}}}}, {"nested": {"parent": {"mark": "sankey", "encoding": {"node": {"field": "text emotion node", "type": "node", "encoding": {"color": {"field": "node_type", "type": "nominal"}}}, "link": {"field": "flow", "type": "relation", "encoding": {"width": {"field": "link_strength", "type": "quantitative"}}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "word_cloud", "encoding": {"word": {"field": "word", "type": "nominal"}, "size": {"field": "frequency", "type": "quantitative"}}}}}}, {"facet": {"field": "node_type", "type": "nominal"}, "spec": {"mark": "bar", "encoding": {"x": {"field": "frequency", "type": "quantitative", "bin": true}, "y": {"field": "proportion", "type": "quantitative"}}}}]}, "marks": ["treemap", "sankey", "word_cloud", "bar"], "channels": ["node", "link", "size", "color", "width", "word", "x", "y"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["concat", "facet", "nested"], "aggregates": ["count", "bin"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3205_00", "figFile": "vis-3205_00.png", "figCaption": "", "figBox": {"x": 0.2499670153784047, "y": 0.05398654038068625, "width": 0.4909517885647151, "height": 0.45469987984761595}, "figVis": ["sankey_diagram", "treemap", "bar_chart", "word_cloud"], "relationText": "The channel coherence view (Fig. 1b) presents the emotion coherence information\nof the three channels by using an augmented Sankey diagram design (T3-4). Some corresponding features extracted from different channels are embedded into this view to give some hints on different channels for explanation (T5).", "note": "[treemap, (sankey relation, (word cloud)), histograms]"}, {"viewId": "vis-3205_00_2", "viewFile": "vis-3205_00_2.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "coherence score", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "modal", "type": "nominal"}, "color": {"field": "emotion type", "type": "nominal"}}}, {"layer": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "quantitative"}, "y": {"field": "pitch", "type": "quantitative"}}}, {"facet": {"layout": "mirrored", "row": {"field": "intensity or amplitude", "type": "nominal"}, "texture": {"field": "intensity or amplitude", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "time", "type": "quantitative"}, "y": {"field": "intensity or amplitude value", "type": "quantitative"}}}}]}]}, "marks": ["line", "rect", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["concat", "layer", "facet"], "aggregates": [], "actionTargets": ["produce:Attributes-values", "consume-present:Attributes-distribution"], "figId": "vis-3205_00", "figFile": "vis-3205_00.png", "figCaption": "", "figBox": {"x": 0.24874968689991053, "y": 0.5154031761763557, "width": 0.4903483852955438, "height": 0.4777425191676938}, "figVis": ["line_chart", "bar_chart", "scatterplot"], "relationText": "T6 To show the temporal distribution of emotion states and their\ncoherence.\nT7 To enable the inspection of details of emotion expressions at\nthe word level.\nT8 To reveal transition points of emotion behavior\n\nThe detail view (Fig. 1c) presents detailed information of a selected sentence and its contexts to help users analyze a\nspecific sentence (T6-8)", "note": "(shared time axis, [(top line chart value), (matrix rows, matrix cell value), (bottom line chart value), (bottom scatter value), (bottom Bar value, bottom bar category)])"}, {"viewId": "vis-3205_00_3", "viewFile": "vis-3205_00_3.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "text", "type": "node", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}}}, "link": {"field": "time-curve", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "arc", "encoding": {"theta": {"field": "channel type", "type": "nominal"}, "color": {"field": "emotion type", "type": "nominal"}}}}}}, "marks": ["graph", "arc"], "channels": ["node", "link", "x", "y", "theta", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-3205_00", "figFile": "vis-3205_00.png", "figCaption": "", "figBox": {"x": 0.7430894471679667, "y": 0.05398654038068628, "width": 0.25334992018798047, "height": 0.45469987984761556}, "figVis": ["glyph_based", "scatterplot"], "relationText": "T6 To show the temporal distribution of emotion states and their\ncoherence.\n\nThe sentence clustering view (Fig. 1d) reveals\nthe temporal distribution of emotion similarity across three channels at\nthe sentence level (T6).", "note": "(relation, (x pos, y pos, (glyph)))"}, {"viewId": "vis-3205_00_4", "viewFile": "vis-3205_00_4.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "frequency", "type": "quantitative"}, "y": {"field": "word_type", "type": "nominal"}, "color": {"field": "emotion", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-values", "query-compare:Attributes-values"], "figId": "vis-3205_00", "figFile": "vis-3205_00.png", "figCaption": "", "figBox": {"x": 0.7394760476067735, "y": 0.5078909585098934, "width": 0.2587538831746737, "height": 0.48776893119329284}, "figVis": ["bar_chart"], "relationText": "T7 To enable the inspection of details of emotion expressions at the word level.\n\nThe word view (Fig. 1e) provides the frequency of each word in the video transcript and allows users to compare different words with the face information and locate specific words in the sentences of a selected video (T7): compare", "note": ""}, {"viewId": "vis-3206_00_0", "viewFile": "vis-3206_00_0.png", "specification": {"facet": {"column": {"field": "affected/unaffected", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "motion outcome", "type": "quantitative"}}}, {"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "muscle activity signal", "type": "quantitative"}, "color": {"field": "muscle", "type": "nominal"}}}, {"facet": {"row": {"field": "muscle", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "muscle activity signal", "type": "quantitative"}, "color": {"field": "muscle", "type": "nominal"}}}}]}}, "marks": ["line", "area", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3206_00", "figFile": "vis-3206_00.png", "figCaption": "", "figBox": {"x": 0.006089624182403351, "y": 0.09083736055578241, "width": 0.5497327789335551, "height": 0.45162928188214235}, "figVis": ["line_chart", "area_chart"], "relationText": "The sliding mechanism engages users to opt for a clear comparison with a few amounts of interactions needed so that they can obtain minimal operations to analyze each patient sequentially (R3).: compare", "note": "left top (T, Q, N)\nleft bottom ((T, Q),N)"}, {"viewId": "vis-3206_00_1", "viewFile": "vis-3206_00_1.png", "specification": {"facet": {"column": {"field": "series", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"facet": {"column": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "value", "type": "quantitative"}, "x": {"field": "frequency", "type": "quantitative", "bin": true}, "color": {"field": "feature", "type": "nominal"}}}}, {"facet": {"row": {"field": "motion", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "frequency", "type": "quantitative", "bin": true}, "y": {"field": "value", "type": "quantitative"}, "color": {"field": "motion type", "type": "nominal"}}}}]}}, "marks": ["bar"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": ["bin"], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-distribution"], "figId": "vis-3206_00", "figFile": "vis-3206_00.png", "figCaption": "", "figBox": {"x": 0.5694061058240089, "y": 0.09728341032495089, "width": 0.4277167673132126, "height": 0.40684082059086163}, "figVis": ["area_chart", "line_chart"], "relationText": "R1 Align heterogeneous data sources. \n\nUsers can visually refine the timeline and muscle selection (R1) and import the refined results to the bundle comparison view.: {timeline} correlate, compare", "note": "([line, line, multi-series line], left and right)"}, {"viewId": "vis-3206_00_2", "viewFile": "vis-3206_00_2.png", "specification": {"facet": {"column": {"field": "display", "type": "nominal"}, "row": {"field": "muscle", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "muscle activity", "type": "quantitative"}, "y": {"field": "frequency", "type": "quantitative", "bin": true}, "color": {"field": "muscle", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["bin"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3206_00", "figFile": "vis-3206_00.png", "figCaption": "", "figBox": {"x": 0.5600365252839231, "y": 0.5027170087844587, "width": 0.41590779717488474, "height": 0.4831227607221826}, "figVis": ["area_chart"], "relationText": "Users thus can verify their findings and derive reasons between muscle coordination\nand physical outcome.: correlate", "note": ""}, {"viewId": "vis-3210_00_0", "viewFile": "vis-3210_00_0.png", "specification": {"facet": {"column": {"field": "metric", "type": "nominal"}, "row": {"field": "id", "type": "ordinal"}}, "spec": {"condition_1": {"test": "not acc or recall", "value": {"mark": "bar", "encoding": {"x": {"field": "metric value", "type": "quantitative"}}}}, "condition_2": {"test": "acc or recall", "value": {"mark": "text", "encoding": {"text": {"field": "metric value", "type": "quantitative"}}}}}}, "marks": ["bar", "text"], "channels": ["x", "text"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["search-locate:Attributes-outliers"], "figId": "vis-3210_00", "figFile": "vis-3210_00.png", "figCaption": "", "figBox": {"x": 0.34764745187003016, "y": 0.01229006442340821, "width": 0.6418351751269338, "height": 0.2375564269791555}, "figVis": ["bar_chart", "table"], "relationText": "Poisoning rates of lower than 5% are considered to be high risk, since only a small amount of poisoned instances can cause label flipping in these data instances, and poisoning rates of 20% are likely infeasible (high risk of being caught).: {high risk} anomalies", "note": ""}, {"viewId": "vis-3210_00_1", "viewFile": "vis-3210_00_1.png", "specification": {"mark": "radar", "encoding": {"theta": {"field": "metric_type", "type": "nominal"}, "radius": {"field": "metric_value", "type": "quantitative"}, "color": {"field": "method", "type": "nominal"}}}, "marks": ["radar"], "channels": ["theta", "radius", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-values", "query-compare:Attributes-distribution"], "figId": "vis-3210_00", "figFile": "vis-3210_00.png", "figCaption": "", "figBox": {"x": 0.015538637457118792, "y": 0.3110886530535242, "width": 0.2536174255823603, "height": 0.2939745752368117}, "figVis": ["polar_plot"], "relationText": "The model overview provides a summary of the poisoned model as well as a comparison between the original (victim) and poisoned model (T2, D2.1).: compare\n\nThe four elements commonly used in confusion matrices (true negative (TN), false negative (FN), true positive (TP), and false positive (FP)) are mapped to the four axes on the left side of the radar chart, and accuracy, recall, F1 and ROC-AUC scores are mapped to the right side.: derive value", "note": ""}, {"viewId": "vis-3210_00_2", "viewFile": "vis-3210_00_2.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}, "color": {"field": "label", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation", "consume-present:Attributes-clusters"], "figId": "vis-3210_00", "figFile": "vis-3210_00.png", "figCaption": "", "figBox": {"x": 0.37124762064780104, "y": 0.6136788895513329, "width": 0.25443523996662376, "height": 0.38778167341249553}, "figVis": ["scatterplot"], "relationText": "The projection view (Figure 1 (D)) provides a global picture of the data distribution, clusters, and relationships between the original and poisoned instances. ", "note": ""}, {"viewId": "vis-3210_00_3", "viewFile": "vis-3210_00_3.png", "specification": {"facet": {"column": {"field": "indicator", "type": "nominal"}, "row": {"field": "id", "type": "ordinal"}}, "spec": {"condition_1": {"test": "distribution", "value": {"mark": "bar", "encoding": {"x": {"field": "value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}, "xoffset": {"field": "KNN label", "type": "nominal"}, "color": {"field": "KNN label", "type": "nominal"}}}}, "condition_2": {"test": "not distribution", "value": {"mark": "text", "encoding": {"text": {"field": "indicator value", "type": "quantitative"}}}}}}, "marks": ["bar", "text"], "channels": ["x", "y", "xoffset", "color", "text"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-3210_00", "figFile": "vis-3210_00.png", "figCaption": "", "figBox": {"x": 0.27412514016198236, "y": 0.2988770028816056, "width": 0.3492102725969641, "height": 0.30274622676483604}, "figVis": ["bar_chart", "table"], "relationText": "T3.2 At the feature-level, what is the impact of data poisoning on the feature distributions?: distribution\n\nThe feature view is designed to reflect the relationship between class features and prediction outputs to help users understand the effects of data poisoning (T3.2, D2.3).", "note": "[((bar chart), N rows), (table)]"}, {"viewId": "vis-3210_00_4", "viewFile": "vis-3210_00_4.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "KNN instances", "type": "node"}, "link": {"field": "impact relation", "type": "relation", "encoding": {"color": {"field": "The source node of the impact"}, "gradient": {"field": "direction of the impact"}, "thickness": {"field": "impact value"}}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "others", "encoding": {"inner_ring": {"field": "class distribution of kNNs in the victim model"}, "outer_ring": {"field": "class distribution of kNNs in the poisoned model"}, "color": {"field": "Classification Probability"}, "texture": {"field": "Whether the predicted label is flipped from the victim mode"}, "size": {"field": "classification probability"}, "lightness": {"field": "total exported impact value"}}}}}}, "marks": ["graph", "others"], "channels": ["node", "link", "color", "gradient", "thickness", "inner_ring", "outer_ring", "texture", "size", "lightness"], "dataTypes": ["node", "relation"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-discover:Graphs-links/paths", "search-lookup:Attributes-outliers"], "figId": "vis-3210_00", "figFile": "vis-3210_00.png", "figCaption": "", "figBox": {"x": 0.63070953334179, "y": 0.3129054338617627, "width": 0.3550530308158966, "height": 0.6782783092694079}, "figVis": ["glyph_based", "graph"], "relationText": "T3.1 At the instance-level, is the original prediction different from the victim model prediction?  How close is the data instance to the decision boundary? How do the neighboring instances affect the class label? Is there any poisoned data in the data-instance\u2019s top-k nearest neighbors?\n\nIn order to understand model vulnerabilities, users need to audit the relationship between poisoned instances and targets to gain insights into the impact of an attack (T3.1, D2.4)", "note": ""}, {"viewId": "vis-3211_02_0", "viewFile": "vis-3211_02_0.png", "specification": {"facet": {"row": {"field": "feature", "type": "nominal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "text", "encoding": {"text": {"field": "feature value", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "value", "type": "quantitative"}, "y": {"field": "value_type", "type": "nominal"}, "color": {"field": "type2", "type": "nominal"}}}]}}, "marks": ["text", "bar"], "channels": ["text", "x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "consume-present:Attributes-distribution"], "figId": "vis-3211_02", "figFile": "vis-3211_02.png", "figCaption": "", "figBox": {"x": 0.3991603029424703, "y": 0.27632834015056584, "width": 0.13108408792804152, "height": 0.19135783603054224}, "figVis": ["line_chart"], "relationText": "Each feature has two bar charts which indicate the by-group feature value distribution (e.g., orange bar chart for Male, and green bar chart for Female), and the correlation measure (i.e., how the two distributions are dissimilar to each other).", "note": "[Q,Q]: two indicators"}, {"viewId": "vis-3211_02_1", "viewFile": "vis-3211_02_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"layer": [{"mark": "rect", "encoding": {"x": {"field": "individual", "type": "ordinal"}, "texture": {"field": "negative target label", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "individual", "type": "ordinal"}, "y": {"field": "trend", "type": "quantitative"}, "color": {"field": "within-ranking fairness/utility", "type": "nominal"}, "shape": {"field": "within-ranking fairness/utility", "type": "nominal"}}}]}, {"mark": "rect", "encoding": {"x": {"field": "individual", "type": "ordinal"}, "color": {"field": "protected/non-protected group", "type": "nominal"}}}]}, "marks": ["rect", "line"], "channels": ["x", "texture", "y", "color", "shape"], "dataTypes": ["ordinal", "nominal", "quantitative"], "compositions": ["concat", "layer"], "aggregates": [], "actionTargets": ["produce:Attributes-order", "produce:Attributes-values"], "figId": "vis-3211_02", "figFile": "vis-3211_02.png", "figCaption": "", "figBox": {"x": 0.5274630359883536, "y": 0.022279906393420965, "width": 0.3043342705281713, "height": 0.2698438052755537}, "figVis": ["line_chart"], "relationText": "Ranking View (Fig. 2b) provides an overview of the current ranking outcome.: {measures} derive value, {ranking} sort", "note": "[Q,Q,N]: two indicators with one group"}, {"viewId": "vis-3211_02_2", "viewFile": "vis-3211_02_2.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "point", "encoding": {"x": {"field": "dimensionality reduction x", "type": "quantitative"}, "y": {"field": "dimensionality reduction y", "type": "quantitative"}, "color": {"field": "gender", "type": "nominal"}}}, {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "individual", "type": "nominal"}, "y": {"aggregate": "count", "field": "distortion", "type": "quantitative"}, "color": {"field": "gender", "type": "nominal"}}}, {"mark": "rect", "encoding": {"x": {"field": "individual", "type": "nominal"}, "y": {"field": "individual", "type": "nominal"}, "color": {"aggregate": "count", "field": "pairwise distortion", "type": "quantitative"}}}]}, {"mark": "tick", "encoding": {"y": {"field": "ranking", "type": "ordinal"}, "color": {"field": "gender", "type": "nominal"}}}]}, "marks": ["point", "bar", "rect", "tick"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-3211_02", "figFile": "vis-3211_02.png", "figCaption": "", "figBox": {"x": 0.5301726819739894, "y": 0.2891688896753636, "width": 0.3217556524830847, "height": 0.3966721041126423}, "figVis": ["matrix", "heatmap"], "relationText": "This view consists of the visual components of three spaces. Each space visualizes the distribution of individuals in each phase (T2): distribution\n\nFor Mapping space, Matrix View represents all pairs of individuals in the mapping process with the amount of pairwise distortion between two spaces.: correlate\n", "note": "[scatter plot,[bar chart, matrix]]"}, {"viewId": "vis-3211_02_3", "viewFile": "vis-3211_02_3.png", "specification": {"facet": {"column": {"field": "headers", "type": "nominal"}, "row": {"field": "status", "type": "nominal"}}, "spec": {"condition_1": {"test": "first row and outlier", "value": {"mark": "bar", "encoding": {"x": {"field": "outlier value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "condition_2": {"test": "not first row and outlier", "value": {"mark": "unit", "encoding": {"unit": {"field": "instance", "type": "node"}, "x": {"field": "feature", "type": "nominal"}, "color": {"field": "outlier or not", "type": "nominal"}}}}, "condition_3": {"test": "first row and perturbation", "value": {"mark": "bar", "encoding": {"y": {"aggregate": "count", "type": "quantitative"}, "x": {"field": "perturbation value", "type": "quantitative", "bin": true}}}}, "condition_4": {"test": "not first row and perturbation", "value": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"y": {"aggregate": "count", "type": "quantitative"}, "x": {"field": "perturbation value", "type": "quantitative", "bin": true}, "color": {"field": "outlier or not", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "feature", "type": "nominal"}, "color": {"field": "gender", "type": "nominal"}}}]}}}}, "marks": ["bar", "unit"], "channels": ["x", "y", "unit", "color"], "dataTypes": ["quantitative", "node", "nominal"], "compositions": ["facet", "concat"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution", "search-locate:Attributes-outliers"], "figId": "vis-3211_02", "figFile": "vis-3211_02.png", "figCaption": "", "figBox": {"x": 0.5075905302620363, "y": 0.7088147225774964, "width": 0.4859001456575742, "height": 0.2881468950978745}, "figVis": ["others"], "relationText": "For the feature distortion, we plot the overall distribution of instances with respect to their distortions.: distribution\n\nWe then identify outliers that have greater distortion within 5% of the right tail. For each feature, we represent the whole individuals (gray circle) with outliers (red circle) in a histogram along with feature correlation score.: anomaly", "note": "statistical distribution of multiple features"}, {"viewId": "vis-3212_00_0", "viewFile": "vis-3212_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}}}, "marks": ["point"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-3212_00", "figFile": "vis-3212_00.png", "figCaption": "", "figBox": {"x": 0.007146006098130058, "y": 0.170685979772442, "width": 0.22916829030302052, "height": 0.3962318168205074}, "figVis": ["scatterplot"], "relationText": "Each dot corresponds to one class of the model, with spatial position encoding their similarity.: cluster\n\nClicking on a point in the Embedding View will update the selection for the remaining views of SUMMIT, as described below.: filter", "note": ""}, {"viewId": "vis-3212_00_1", "viewFile": "vis-3212_00_1.png", "specification": {"facet": {"row": {"field": "class", "type": "nominal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "class value", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "probability value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}]}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet", "concat"], "aggregates": ["bin", "count"], "actionTargets": ["produce:Attributes-order", "query-compare:Attributes-distribution", "consume-present:Attributes-distribution"], "figId": "vis-3212_00", "figFile": "vis-3212_00.png", "figCaption": "", "figBox": {"x": 0.005923306834089878, "y": 0.5735536074490669, "width": 0.23471426136184267, "height": 0.41891892465651753}, "figVis": ["bar_chart"], "relationText": "(B) Class Sidebar enables users to search, sort, and compare all classes within a model. : sort, compare\n\nFrom this small histogram, users can quickly see how well a class performs. For example, classes with power law histograms indicate high accuracy, whereas classes with normal distribution histograms indicate underperformance.: distribution", "note": "many bar charts"}, {"viewId": "vis-3212_00_2", "viewFile": "vis-3212_00_2.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "filter", "type": "node"}, "link": {"field": "network connection", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "image", "encoding": {"image": {"field": "visual feature map"}}}}}}, "marks": ["graph", "image"], "channels": ["node", "link", "image"], "dataTypes": ["node", "relation"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3212_00", "figFile": "vis-3212_00.png", "figCaption": "", "figBox": {"x": 0.2412298656671789, "y": 0.15979132844014327, "width": 0.3650548479572108, "height": 0.8391045831273086}, "figVis": ["graph"], "relationText": "(C) Attribution Graph View visualizes highly activated neurons as vertices (\u201cscales,\u201d \u201cfish\u201d) and their most influential connections as edges (dashed purple edges).: {influential connections} correlate", "note": ""}, {"viewId": "vis-3213_03_0", "viewFile": "vis-3213_03_0.png", "specification": {"facet": {"field": "data center id", "type": "ordinal"}, "spec": {"mark": "unit", "encoding": {"size": {"field": "anomaly score", "type": "quantitative"}, "unit": {"field": "data cluster", "type": "node"}}}}, "marks": ["unit"], "channels": ["size", "unit"], "dataTypes": ["quantitative", "node"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-outliers", "produce:Attributes-order", "consume-present:Attributes-clusters"], "figId": "vis-3213_03", "figFile": "vis-3213_03.png", "figCaption": "", "figBox": {"x": 0.005248676216767479, "y": -0.0008078853948316367, "width": 0.5523075562741929, "height": 0.19818352413703347}, "figVis": ["glyph_based"], "relationText": "The spatial overview assists users to observe the general anomaly degree and query the data of a cloud computing system hierarchically (from data center to sub-level data cluster) through a bubble chart. : anomaly\n\nThus, the spatial overview arranges data centers according to their abnormal scores in descending order, from left to right and top to bottom. : sort\n\nIn addition, the inner bubbles will only appear when their represented data clusters\u2019 sum of anomaly scores is larger than the human-set threshold.: cluster", "note": "(node number, node)"}, {"viewId": "vis-3213_03_1", "viewFile": "vis-3213_03_1.png", "specification": {"condition_1": {"test": "bar mode", "value": {"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "anomaly score", "type": "quantitative"}, "color": {"field": "metric", "type": "nominal"}}}}, "condition_2": {"test": "area mode", "value": {"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "metric value", "type": "quantitative"}, "color": {"field": "metric", "type": "nominal"}}}}}, "marks": ["bar", "area"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": [], "figId": "vis-3213_03", "figFile": "vis-3213_03.png", "figCaption": "", "figBox": {"x": 0.0022479235870591077, "y": 0.20031843730836943, "width": 0.5577052009102773, "height": 0.1745311442605635}, "figVis": ["area_chart", "bar_chart"], "relationText": "The temporal overview (Fig. 4(2)) aims at revealing an anomaly overview of the variation of all the important tracking metrics (e.g., CPU frequency and memory usage) over time, \ninter-pattern comparison and correlation discovery of multiple metrics can be fulfilled (T5)", "note": ""}, {"viewId": "vis-3213_03_2", "viewFile": "vis-3213_03_2.png", "specification": {"facet": {"row": {"field": "data center", "type": "nominal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"aggregate": "average", "field": "anomaly degree", "type": "quantitative"}, "y": {"field": "performance metric", "type": "nominal"}, "color": {"field": "performance metric", "type": "nominal"}}}, {"mark": "unit", "layout": "calendar", "encoding": {"unit": {"field": "time unit", "type": "node"}, "color": {"field": "anomaly score", "type": "quantitative"}}}]}}, "marks": ["bar", "unit"], "channels": ["x", "y", "color", "unit"], "dataTypes": ["quantitative", "nominal", "node"], "compositions": ["facet", "concat"], "aggregates": ["average"], "actionTargets": [], "figId": "vis-3213_03", "figFile": "vis-3213_03.png", "figCaption": "", "figBox": {"x": 4.7807914603102575e-05, "y": 0.39893808557712185, "width": 0.12551420158624912, "height": 0.5994666817781612}, "figVis": ["bar_chart", "heatmap"], "relationText": "The rank view in Fig. 4(3) shows a list of compute nodes with high anomaly scores within the user-specified time period in the temporal view, which reduces users efforts in searching for suspicious nodes.", "note": ""}, {"viewId": "vis-3213_03_3", "viewFile": "vis-3213_03_3.png", "specification": {"facet": {"row": {"field": "anomaly id", "type": "ordinal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "area", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"type": "quantitative"}, "color": {"field": "metric type", "type": "nominal"}}}, {"facet": {"row": {"field": "metric type", "type": "nominal"}}, "spec": {"mark": "area", "layout": "horizon", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "anomaly score", "type": "quantitative"}, "color": {"field": "density", "type": "quantitative"}}}}]}}, "marks": ["area"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "search-locate:Attributes-outliers"], "figId": "vis-3213_03", "figFile": "vis-3213_03.png", "figCaption": "", "figBox": {"x": 0.12381092089105523, "y": 0.3926934908987803, "width": 0.3043135757056446, "height": 0.6057083420006832}, "figVis": ["stripe_graph"], "relationText": "The performance view (in Fig. 4(4)) displays the detailed performance metrics data, associated with anomaly detection results, to facilitate the anomaly inspection and correlation analysis among different metrics in time scale.  ", "note": "(((Streamgraph), different feature), different chart)"}, {"viewId": "vis-3213_03_4", "viewFile": "vis-3213_03_4.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"layer": [{"mark": "surface", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "surface": {"field": "point_density", "type": "quantitative"}}}, {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}}}, "child": {"child_type": "configured", "configuration": {"mark": "arc", "encoding": {"theta": {"field": "metric", "type": "nominal"}, "radius": {"field": "anomaly degree", "type": "quantitative"}, "color": {"field": "type", "type": "nominal"}}}}}}]}, {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "anomaly score", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}]}, "marks": ["surface", "point", "arc", "line"], "channels": ["x", "y", "surface", "theta", "radius", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "layer", "nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-3213_03", "figFile": "vis-3213_03.png", "figCaption": "", "figBox": {"x": 0.4264373592931777, "y": 0.39389128769122156, "width": 0.1338403477003439, "height": 0.59956423093531}, "figVis": ["scatterplot", "glyph_based", "line_chart"], "relationText": "The cluster view (Fig. 4(5)) shows the spatial distribution of all the selected compute nodes using t-Distributed Stochastic Neighbor Embedding (t-SNE) based on their performance data", "note": "((glyph), x, y) "}, {"viewId": "vis-3214_00_0", "viewFile": "vis-3214_00_0.png", "specification": {"facet": {"row": {"field": "paragraph", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "metric", "type": "nominal"}, "y": {"field": "metric value", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["produce:Attributes-values", "consume-present:Attributes-correlation"], "figId": "vis-3214_00", "figFile": "vis-3214_00.png", "figCaption": "", "figBox": {"x": 0.009573701858218465, "y": 0.08814037449710374, "width": 0.682967095940859, "height": 0.5413409025228315}, "figVis": ["bar_chart"], "relationText": "While the bar charts show a subset of related metrics per class (grouped by packages) in stacked bars.: derive value\n\nThese visualizations are useful in discerning important patterns and relationships between metrics [45]. : correlate", "note": ""}, {"viewId": "vis-3214_00_1", "viewFile": "vis-3214_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "metric types", "type": "nominal"}, "y": {"field": "metric value", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "selected metric x", "type": "quantitative"}, "y": {"field": "selected metric y", "type": "quantitative"}}}]}, "marks": ["line", "point"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["produce:Attributes-values", "consume-present:Attributes-distribution"], "figId": "vis-3214_00", "figFile": "vis-3214_00.png", "figCaption": "", "figBox": {"x": 0.018012615857678608, "y": 0.6258619823693381, "width": 0.6696271004875768, "height": 0.3555358671014141}, "figVis": ["parallel_coordinate"], "relationText": "the parallel coordinates plot displays all metrics for all classes (i.e., each line represents a class); the scatterplot adds a different perspective for a user-selected pair of metrics.\n\nTo obtain an overview of all the metrics, the parallel coordinates plot is helpful, whereas the scatterplot supports the identification of relationships between two metrics.: correlate", "note": "(parallel coordinates, scatterplot)"}, {"viewId": "vis-3217_00_0", "viewFile": "vis-3217_00_0.png", "specification": {"facet": {"row": {"field": "index", "type": "ordinal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "text", "encoding": {"text": {"field": "offense category", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "weight", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "rating", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}, "remark": "In a histogram,the x-axis shows the rating scale from zero to one hundimensionality reductioned, and the y-axis shows the count of each score."}, {"mark": "rule", "encoding": {"x": {"field": "rating", "aggregate": "average", "type": "quantitative"}}, "remark": "The black lines denote the averages."}]}}, "marks": ["text", "bar", "rule"], "channels": ["text", "x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": ["bin", "count", "average"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3217_00", "figFile": "vis-3217_00.png", "figCaption": "", "figBox": {"x": 0.0059572785100241625, "y": 0.12873167051944281, "width": 0.17524791934158268, "height": 0.8545472174768987}, "figVis": ["bar_chart"], "relationText": "The rating distribution indicates the variation of opinions among survey participant", "note": ""}, {"viewId": "vis-3217_00_1", "viewFile": "vis-3217_00_1.png", "specification": {"facet": {"column": {"field": "group", "type": "nominal"}, "color": {"field": "group", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "dandelion", "encoding": {"theta": {"field": "attribute", "type": "nominal"}, "radius": {"field": "group", "type": "nominal"}, "color": {"field": "group", "type": "nominal"}}}, {"mark": "radar", "encoding": {"theta": {"field": "attribute", "type": "nominal"}, "radius": {"field": "proportional ratio", "type": "nominal"}, "color": {"field": "group", "type": "nominal"}, "remark": "The length of a ribbon on one axis encodes the proportional ratio of one data item to the total of an attribute"}}]}}, "marks": ["dandelion", "radar"], "channels": ["theta", "radius", "color", "remark"], "dataTypes": ["nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values", "query-identify:Attributes-outliers", "query-identify:Attributes-correlation"], "figId": "vis-3217_00", "figFile": "vis-3217_00.png", "figCaption": "", "figBox": {"x": 0.1910719310476531, "y": 0.05253251001263988, "width": 0.5454571387563649, "height": 0.5827569631157186}, "figVis": ["polar_plot"], "relationText": "For high-level comparison tasks (Fig. 8), the group performance view demonstrates(1) performance evaluation and comparison at the group level (withinthe same level), and (2) each individual data item\u2019s performance con-tribution to its group and performance contribution of a group to the entire organization (across two levels): compare\n\nFor low-level comparison tasks, the customized dandelion glyphs provide an efficient simultaneous comparison for a set of data attributes, and identification of outliers and correlation among attributes: outlier, correlation", "note": "(x, [Dandelion Glyph, stacked radar chart])"}, {"viewId": "vis-3217_00_2", "viewFile": "vis-3217_00_2.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-3217_00", "figFile": "vis-3217_00.png", "figCaption": "", "figBox": {"x": 0.7437677879858158, "y": 0.02228558042200721, "width": 0.2498888161839439, "height": 0.5260959100470549}, "figVis": ["scatterplot"], "relationText": "During shift planning, team commanderscan build a new team of employees with similar experiences addimensionality reductionessing specific types of crime: cluster", "note": ""}, {"viewId": "vis-3217_00_3", "viewFile": "vis-3217_00_3.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"mark": "rect", "position": 1, "encoding": {"x": {"field": "emplyee ids", "type": "nominal"}, "y": {"field": "job types", "type": "nominal"}, "color": {"field": "performance score", "type": "quantitative"}}}, {"mark": "bar", "position": 2, "encoding": {"x": {"field": "emplyee ids", "type": "nominal"}, "y": {"field": "score", "type": "quantitative", "aggregate": "sum"}}}, {"mark": "bar", "position": 5, "encoding": {"x": {"field": "performance score", "type": "quantitative", "aggregate": "sum"}, "y": {"field": "job types", "type": "nominal"}}}]}, "marks": ["rect", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": ["sum"], "actionTargets": ["query-compare:Attributes-values", "consume-present:Attributes-order"], "figId": "vis-3217_00", "figFile": "vis-3217_00.png", "figCaption": "", "figBox": {"x": 0.19132493695770592, "y": 0.6735316034800924, "width": 0.8020007844628888, "height": 0.3143887447970668}, "figVis": ["bar_chart", "heatmap"], "relationText": "To efficiently evaluate and compare the performance of employees for the entire organization (T1, T3), our performance matrix (Fig. 5) isdesigned to show the detailed job completion status of all employees in a holistic view: compare\n\nWe adopted a color-coded reorderable matrix: sort\n\nSelection interactions are supported to simplify officer comparison; for instance, users can select any officers that they are interested in and then those officers will be aligned on the left side of the matrix. : filter", "note": "(x, [(y, color), height of bar])"}, {"viewId": "vis-3218_04_0", "viewFile": "vis-3218_04_0.png", "specification": {"mark": "word_cloud", "encoding": {"size": {"field": "frequency", "type": "quantitative"}, "word": {"field": "word", "type": "nominal"}, "color": {"field": "sentiment", "type": "nominal"}, "remark": "The sentiment of each word is averaged by the sentiment of weibos containing the word. The size of each word denotes the frequency it appears in the selected weibos."}}, "marks": ["word_cloud"], "channels": ["size", "word", "color", "remark"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3218_04", "figFile": "vis-3218_04.png", "figCaption": "", "figBox": {"x": 0.00432454503580413, "y": 0.6900648238525073, "width": 0.23874513474941933, "height": 0.29505596566612197}, "figVis": ["word_cloud"], "relationText": "The Word Cloud View shows the keyword distribution of the selected weibos: distribution\n\nUsers can select weibos that contain a specific word by clicking the word in this view: select", "note": "raw data => (word count, sentiment)"}, {"viewId": "vis-3218_04_1", "viewFile": "vis-3218_04_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "tree", "encoding": {"node": {"field": "player", "type": "node"}, "link": {"field": "reposting relation", "type": "relation"}}}, {"mark": "tick", "encoding": {"y": {"field": "delay time of reposting", "type": "temporal"}, "x": {"field": "player", "type": "nominal"}, "color": {"field": "post type", "type": "nominal"}}}]}, "marks": ["tree", "tick"], "channels": ["node", "link", "y", "x", "color"], "dataTypes": ["node", "relation", "temporal", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-correlation", "query-identify:Graphs-links/paths", "query-identify:Attributes-order"], "figId": "vis-3218_04", "figFile": "vis-3218_04.png", "figCaption": "", "figBox": {"x": 0.8520956378789727, "y": 0.058326769226791496, "width": 0.14265820688759118, "height": 0.9267712624063845}, "figVis": ["scatterplot"], "relationText": "The Timeline View (Figure 5c) provides a temporal overview of the diffusion process (R3): correlate\n\nAbove the timeline, a node-link diagram is provided to indicate the reposting relations of the key players, which are sorted according to the reposting time: graph, sort\n\nA brush function is also provided for exploring repostings of interest: filter", "note": "(node-link, (user, time, delay time))"}, {"viewId": "vis-3218_04_2", "viewFile": "vis-3218_04_2.png", "specification": {"mark": "others", "encoding": {"lake": {"field": "key player in the diffusion process"}, "county": {"field": "a nonkeyplayer weibo node in the reposting tree"}, "region": {"field": "counties discussing similar topics"}, "country": {"field": "a subtree rooted by a key player"}, "continent and island": {"field": "large connected subtrees"}, "river": {"field": "parent-child relations of key players"}, "route": {"field": "a key player follow his/her parent or not"}, "bridge": {"field": "the topics of the territories belonging to the key player are different from his/her parent or not"}}}, "marks": ["others"], "channels": ["lake", "county", "region", "country", "continent and island", "river", "route", "bridge"], "dataTypes": [], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Graphs-topology/structures"], "figId": "vis-3218_04", "figFile": "vis-3218_04.png", "figCaption": "", "figBox": {"x": 0.254261590591868, "y": 0.04999458602561931, "width": 0.5898767567354758, "height": 0.9378324286977662}, "figVis": ["others"], "relationText": "The Map View (Figure 5b) provides an overview of the reposting structure and the different topics discussed in the reposting process(R1): graph, correlate", "note": "(text, repost level, sentiment, user role, repost)"}, {"viewId": "vis-3219_00_0", "viewFile": "vis-3219_00_0.png", "specification": {"mark": "sankey", "encoding": {"node": {"condition": {"test": "keyword/related top K POIs", "value": {"x": {"field": "POIs including the corresponding keyword", "type": "quantitative", "aggregate": "count"}}}, "value": {"x": {"field": "POIs including the corresponding keyword", "type": "quantitative", "aggregate": "count"}}}, "link": {"field": "relavance", "type": "relation"}}}, "marks": ["sankey"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": ["count"], "actionTargets": ["search-explore:Graphs-links/paths"], "figId": "vis-3219_00", "figFile": "vis-3219_00.png", "figCaption": "", "figBox": {"x": 0.03045079127210975, "y": 0.13619272033933033, "width": 0.2417256422776573, "height": 0.2649113733530917}, "figVis": ["bar_chart", "tree"], "relationText": "Its node-link based tree display can facilitate the rapid exploration of keywords and  related  POIs  by  depicting  their  relationship  to  visual  cues  of font and curve attributes: graph", "note": "((left/right, histogram), tree)"}, {"viewId": "vis-3219_00_1", "viewFile": "vis-3219_00_1.png", "specification": {"layer": [{"mark": "graph", "encoding": {"node": {"x": {"field": "trajectory node x", "type": "quantitative"}, "y": {"field": "trajectory node y", "type": "quantitative"}}, "link": {"field": "trajectory", "type": "relation"}}}, {"mark": "radar", "encoding": {"theta": {"field": "POI type", "type": "nominal"}}}]}, "marks": ["graph", "radar"], "channels": ["node", "link", "theta"], "dataTypes": ["node", "relation", "nominal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["query-identify:Graphs-links/paths", "query-summarize:Graphs-links/paths"], "figId": "vis-3219_00", "figFile": "vis-3219_00.png", "figCaption": "", "figBox": {"x": 0.007902363380598727, "y": 0.41218182298948824, "width": 0.19231922657778108, "height": 0.3101131566841536}, "figVis": ["polar_plot"], "relationText": "This  semantic  view  abstracts  and  visualizes individual trajectories in a \u2018region functional topic space\u2019 which is intuitive and provides easy interaction. It helps users immediately identify their main mobility patterns among city regions: abstract each trajectory only using the region", "note": "(time, region type, different trajectory)"}, {"viewId": "vis-3219_00_2", "viewFile": "vis-3219_00_2.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "graph", "encoding": {"node": {"longitude": {"field": "longitude", "type": "quantitative"}, "latitude": {"field": "latitude", "type": "quantitative"}}, "link": {"field": "trajectory", "type": "relation"}}}, {"mark": "rect", "encoding": {"longitude": {"field": "longitude", "type": "quantitative"}, "latitude": {"field": "latitude", "type": "quantitative"}, "color": {"field": "link density", "type": "quantitative"}}}]}, "marks": ["geoshape", "graph", "rect"], "channels": ["node", "link", "longitude", "latitude", "color"], "dataTypes": ["node", "relation", "quantitative"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Graphs-links/paths"], "figId": "vis-3219_00", "figFile": "vis-3219_00.png", "figCaption": "", "figBox": {"x": 0.2021596344353377, "y": 0.40962870374807253, "width": 0.6129295163041173, "height": 0.43288659749722375}, "figVis": ["map"], "relationText": "The  Map  View visualizes  the  result  trajectories  as  polylines  in  ageographical map (Figure 1 (e)): raw trajectory", "note": ""}, {"viewId": "vis-3219_00_3", "viewFile": "vis-3219_00_3.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "trajectory event start", "type": "temporal"}, "x2": {"field": "trajectory event end", "type": "temporal"}, "y": {"field": "trajectory id", "type": "nominal"}, "color": {"field": "function type", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "x2", "y", "color"], "dataTypes": ["temporal", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-correlation"], "figId": "vis-3219_00", "figFile": "vis-3219_00.png", "figCaption": "", "figBox": {"x": 0.09437466065793021, "y": 0.83979258182215, "width": 0.7203025386715831, "height": 0.15664790676867046}, "figVis": ["bar_chart"], "relationText": "We adopt this design because such visualization has proven to be useful in analyzing chronological sequence data: correlate ", "note": ""}, {"viewId": "vis-3219_00_4", "viewFile": "vis-3219_00_4.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "trajectory id", "type": "nominal"}, "y": {"field": "relavance score", "type": "quantitative"}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-order", "search-locate:Attributes-values"], "figId": "vis-3219_00", "figFile": "vis-3219_00.png", "figCaption": "", "figBox": {"x": 0.8115737883027264, "y": 0.4067780292740337, "width": 0.18071630250403686, "height": 0.5800242030987626}, "figVis": ["bar_chart"], "relationText": "The trajectories are sorted by their relevance scores shown in blue bars: sort\nUsers can check to select them further exploration on the other views: select", "note": ""}, {"viewId": "vis-3225_00_0", "viewFile": "vis-3225_00_0.png", "specification": {"facet": {"row": {"field": "first-level variable", "type": "nominal"}}, "spec": {"nested": {"parent": {"mark": "others", "encoding": {"x": {"field": "second-level variable", "type": "nominal"}, "y1": {"field": "numerical target variable", "aggregate": "min", "type": "quantitative"}, "y2": {"field": "10th percentile numerical target variable", "type": "quantitative"}, "y3": {"field": "numerical target variable", "aggregate": "q1", "type": "quantitative"}, "y4": {"field": "numerical target variable", "aggregate": "median", "type": "quantitative"}, "y5": {"field": "numerical target variable", "aggregate": "q3", "type": "quantitative"}, "y6": {"field": "90th percentile numerical target variable", "aggregate": "min", "type": "quantitative"}, "y7": {"field": "numerical target variable", "aggregate": "max", "type": "quantitative"}, "point": {"field": "numerical target variable", "aggregate": "average", "type": "quantitative"}, "color": {"field": "range of percentiles", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "bar", "configuration": {"mark": "area", "encoding": {"x": {"field": "variable value", "type": "quantitative"}, "y": {"field": "variable range", "type": "quantitative"}}}}, "remark": "a variation of boxplot"}}}, "marks": ["others", "area"], "channels": ["x", "y1", "y2", "y3", "y4", "y5", "y6", "y7", "point", "color", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "nested"], "aggregates": ["min", "q1", "median", "q3", "max", "average"], "actionTargets": ["consume-present:Attributes-distribution", "query-compare:Attributes-values", "query-identify:Attributes-correlation"], "figId": "vis-3225_00", "figFile": "vis-3225_00.png", "figCaption": "", "figBox": {"x": 0.013308937831447857, "y": 0.03822008747760315, "width": 0.5502827206255385, "height": 0.7302910050605734}, "figVis": ["bar_chart", "line_chart"], "relationText": "R1: visualizing a complete distribution curve is important to prevent any incorrect statistical information.: distribution\nR2: Comparative visualization.: compare\nR3: Filtering.: filter", "note": "(group, variable, stat of Q)"}, {"viewId": "vis-3225_00_1", "viewFile": "vis-3225_00_1.png", "specification": {"mark": "others", "encoding": {"x": {"field": "aggregate variable", "type": "nominal"}, "y1": {"field": "numerical target variable", "aggregate": "min", "type": "quantitative"}, "y2": {"field": "10th percentile numerical target variable", "type": "quantitative"}, "y3": {"field": "numerical target variable", "aggregate": "q1", "type": "quantitative"}, "y4": {"field": "numerical target variable", "aggregate": "median", "type": "quantitative"}, "y5": {"field": "numerical target variable", "aggregate": "q3", "type": "quantitative"}, "y6": {"field": "90th percentile numerical target variable", "aggregate": "min", "type": "quantitative"}, "y7": {"field": "numerical target variable", "aggregate": "max", "type": "quantitative"}, "point": {"field": "numerical target variable", "aggregate": "average", "type": "quantitative"}, "color": {"field": "range of percentiles", "type": "nominal"}}}, "marks": ["others"], "channels": ["x", "y1", "y2", "y3", "y4", "y5", "y6", "y7", "point", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": ["min", "q1", "median", "q3", "max", "average"], "actionTargets": ["query-summarize:Attributes-distribution"], "figId": "vis-3225_00", "figFile": "vis-3225_00.png", "figCaption": "", "figBox": {"x": 0.6105494115697826, "y": 0.03375986034448015, "width": 0.04591399940747702, "height": 0.7201764401278442}, "figVis": ["bar_chart", "line_chart"], "relationText": "R6: summarization", "note": ""}, {"viewId": "vis-3225_00_2", "viewFile": "vis-3225_00_2.png", "specification": {"mark": "line", "encoding": {"x": {"field": "variable", "type": "nominal"}, "y": {"field": "aggregate throughput", "type": "quantitative"}, "color": {"field": "maximum/minimum", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3225_00", "figFile": "vis-3225_00.png", "figCaption": "", "figBox": {"x": 0.15656461229082452, "y": 0.7784238790766534, "width": 0.3501157977284231, "height": 0.19207824267017617}, "figVis": ["line_chart"], "relationText": "The Provenance Terminal (see Figure 6) is used to keep track of the progress of the iterative filtering activities. In this process, the analyst might want to toggle between multiple parameter configurations to compare the resulting dependent variable distributions.: compare", "note": "(two line, time, value)"}, {"viewId": "vis-3229_00_0", "viewFile": "vis-3229_00_0.png", "specification": {"facet": {"column": {"field": "feature name", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature value", "bin": true, "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "selected or not", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3229_00", "figFile": "vis-3229_00.png", "figCaption": "", "figBox": {"x": 0.0071146305529034845, "y": 0.13545042935490847, "width": 0.18959241319171521, "height": 0.8512409910138068}, "figVis": ["bar_chart"], "relationText": "A large part of understanding model per-formance is understanding how the data used to train a model is distributed: distribution\n\nOur interface allows users to generate both specific subgroups and all subgroups of multiple features by selecting a combination of features and values: filter", "note": "(feature, color, (distribution of N or Q))"}, {"viewId": "vis-3229_00_1", "viewFile": "vis-3229_00_1.png", "specification": {"facet": {"column": {"field": "metric", "type": "nominal"}}, "spec": {"layer": [{"mark": "tick", "encoding": {"x": {"field": "metric value", "bin": true, "type": "quantitative"}, "color": {"field": "hovered or pinned or not", "type": "nominal"}}}, {"mark": "rule", "encoding": {"x": {"field": "metric value", "aggregate": "average", "type": "quantitative"}}}]}}, "marks": ["tick", "rule"], "channels": ["x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "layer"], "aggregates": ["bin", "average"], "actionTargets": ["query-identify:Attributes-correlation", "produce:Attributes-values", "search-explore:Attributes-clusters"], "figId": "vis-3229_00", "figFile": "vis-3229_00.png", "figCaption": "", "figBox": {"x": 0.1940395511610836, "y": 0.12386142588556934, "width": 0.5414081138881871, "height": 0.45341943081999564}, "figVis": ["stripe_graph"], "relationText": "To measure the severity of bias against a certain subgroup, it is important to know how the subgroup is performing in relation to the overall model: compare\n\nWhen a user clicks the \u201cGenerate Subgroups\u201d button (Fig. 3),FAIRVIS splits the data into the specified subgroups and calculates various performance metrics for them: derived value\n\nTo further investigate a subgroup,the user can click on a bar to pin the group and use the Detailed Comparison View to further investigate the group: filter", "note": "(metric, value, color)"}, {"viewId": "vis-3229_00_2", "viewFile": "vis-3229_00_2.png", "specification": {"facet": {"column": {"field": "group id", "type": "ordinal"}, "row": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "feature value", "type": "quantitative"}, "color": {"field": "dominant or not", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-outliers", "consume-present:Attributes-similarity", "consume-present:Attributes-distribution", "search-locate:Attributes-values", "consume-discover:Attributes-clusters"], "figId": "vis-3229_00", "figFile": "vis-3229_00.png", "figCaption": "", "figBox": {"x": 0.21449238168938403, "y": 0.5876662774576076, "width": 0.5210401568479891, "height": 0.37820391298120554}, "figVis": ["bar_chart"], "relationText": "To help the user find potentially biased subgroups, we generate subgroups algorithmically and present them to the user for investiga-tion. The Suggested and Similar Subgroup View at the bottom of the interface displays these subgroups and allows the user to sort them by any fairness metric to discover underperforming subgroups: sort, anomaly\n\nSince the generated subgroups are not strictly defined by a few features,it is important to show the feature distributions for each featurein a group: distribution\n\nTo explore the groups, users can filter and sort the groups to refinetheir search space (C3): sort, filter\n\nSimilar subgroups can be infor-mative in two primary manners: finding features which are important for performance and discovering more general subgroups: compare", "note": "(group, selected feature, (features, value))"}, {"viewId": "vis-3229_00_3", "viewFile": "vis-3229_00_3.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "metric value", "type": "quantitative"}, "y": {"field": "metric", "type": "nominal"}, "xoffset": {"field": "hovered/pinned", "type": "nominal"}, "color": {"field": "hovered/pinned", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "xoffset", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-clusters"], "figId": "vis-3229_00", "figFile": "vis-3229_00.png", "figCaption": "", "figBox": {"x": 0.7438330917523955, "y": 0.1431060370709607, "width": 0.23799935840804273, "height": 0.34866175806724736}, "figVis": ["bar_chart"], "relationText": "The grouped bar chart also enables direct comparison between the pinnedand hovered subgroups without the distraction of other groups: compare", "note": ""}, {"viewId": "vis-3294_02_0", "viewFile": "vis-3294_02_0.png", "specification": {"mark": "rect", "encoding": {"y": {"field": "PCA dimension", "type": "nominal"}, "x": {"field": "feature", "type": "nominal"}, "color": {"field": "feature contribution", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-3294_02", "figFile": "vis-3294_02.png", "figCaption": "", "figBox": {"x": 0.003914175766089159, "y": 0.006837689593031829, "width": 0.24906764624802166, "height": 0.6837952722937425}, "figVis": ["scatterplot"], "relationText": "The left part of the feature contribution view lists all the network features generated\nby DeepGL. They usually consist of a few relational feature operators (RFOs), which are represented with mathematical notations (Fig. 6-a)", "note": "(Q, Q, Q, N) - x/y/color/border_type"}, {"viewId": "vis-3294_02_1", "viewFile": "vis-3294_02_1.png", "specification": {"mark": "point", "encoding": {"x": {"field": "pca_x", "type": "quantitative"}, "y": {"field": "pca_x", "type": "quantitative"}, "color": {"field": "scale feature value", "type": "quantitative"}, "stroke": {"field": "target or background", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color", "stroke"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Graphs-graphs"], "figId": "vis-3294_02", "figFile": "vis-3294_02.png", "figCaption": "", "figBox": {"x": 0.25117572438667085, "y": 0.008000874452567424, "width": 0.49466129650731255, "height": 0.9839982510948638}, "figVis": ["scatterplot"], "relationText": "ContraNA\u2019s contrastive representation view (Fig. 2-a) visualizes the results to reveal whether or not there is uniqueness in the target network compared to the background network, serving as the following step (Fig. 3-B, DC1-Discovery)", "note": "(Q, Q, Q, N) - x/y/color/border_type"}, {"viewId": "vis-3294_02_2", "viewFile": "vis-3294_02_2.png", "specification": {"mark": "line", "encoding": {"y": {"field": "probability", "type": "quantitative"}, "x": {"field": "scale feature value", "type": "quantitative"}, "color": {"field": "target or background", "type": "nominal"}}}, "marks": ["line"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3294_02", "figFile": "vis-3294_02.png", "figCaption": "", "figBox": {"x": 0.002349203183772388, "y": 0.6934252315148465, "width": 0.2520726194594891, "height": 0.2980836094562961}, "figVis": ["line_chart"], "relationText": "The probability distribution view (Fig. 2-c) shows the distributions of the selected feature values in the feature contribution view : distribution", "note": "(Q, Q, N): x, y, color"}, {"viewId": "vis-3294_02_3", "viewFile": "vis-3294_02_3.png", "specification": {"facet": {"row": {"field": "target/backgound network", "type": "nominal"}}, "spec": {"mark": "graph", "encoding": {"node": {"field": "network", "type": "node", "encoding": {"color": {"field": "scaled feature value", "type": "quantitative"}}}, "link": {"field": "network link", "type": "relation"}}}}, "marks": ["graph"], "channels": ["node", "link", "color"], "dataTypes": ["node", "relation", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3294_02", "figFile": "vis-3294_02.png", "figCaption": "", "figBox": {"x": 0.7438084658619616, "y": 0.011742016421440432, "width": 0.25740439528064907, "height": 0.9786599652077916}, "figVis": ["graph"], "relationText": "The network layout view in Fig. 2-d, e visualizes laid-out target and background networks. Laid-out networks are helpful for viewing the topological differences (e.g., whether multiple com- munities exist).: compare", "note": ""}, {"viewId": "vis-3295_00_0", "viewFile": "vis-3295_00_0.png", "specification": {"facet": {"column": {"field": "size or IOU or cont or robustness", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"bin": true, "field": "IMDB Rating"}, "y": {"aggregate": "count"}, "color": {"field": "size or IOU or cont or robustness", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-3295_00", "figFile": "vis-3295_00.png", "figCaption": "", "figBox": {"x": 0.004289156158649817, "y": 0.10531415682113793, "width": 0.992153981636659, "height": 0.13971606930330205}, "figVis": ["bar_chart"], "relationText": "This view offers a summary and navigation for key performance statis- tics ( Fig. 1- a ).", "note": ""}, {"viewId": "vis-3295_00_1", "viewFile": "vis-3295_00_1.png", "specification": {"nested": {"parent": {"mark": "rect", "encoding": {"x": {"field": "cell_column", "type": "nominal"}, "y": {"field": "cell_row", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "image", "remark": "each tile shows a detected image patch"}}}}, "marks": ["rect", "image"], "channels": ["x", "y"], "dataTypes": ["nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-3295_00", "figFile": "vis-3295_00.png", "figCaption": "", "figBox": {"x": 0.024910647222750243, "y": 0.2622177900219951, "width": 0.5770921412667447, "height": 0.3113011051765277}, "figVis": ["matrix", "contour_graph"], "relationText": "We design a view of performance landscape, TileScape, to summarize visual characteristics and corresponding performance over tens of thou- sands of objects (design requirement RP2 ),", "note": "[((feature map of each image),columns,rows), right bars, bottom bars]"}, {"viewId": "vis-3295_00_2", "viewFile": "vis-3295_00_2.png", "specification": {"parent": {"mark": "rect", "encoding": {"color": {"field": "score", "type": "quantitative"}, "x": {"field": "cell_column", "type": "nominal"}, "y": {"field": "cell_row", "type": "nominal"}}}}, "marks": ["rect"], "channels": ["color", "x", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3295_00", "figFile": "vis-3295_00.png", "figCaption": "", "figBox": {"x": 0.0025009366727074818, "y": 0.6038364345334153, "width": 0.633244913398489, "height": 0.37599735064173784}, "figVis": ["heatmap"], "relationText": "(a) Detection confidence summary over the first two PCA components of latent dimensions, and one low confidence area (\u2018S1\u2019);: confidence", "note": ""}, {"viewId": "vis-3295_00_3", "viewFile": "vis-3295_00_3.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "tree", "encoding": {"node": {"field": "dimension", "type": "node"}, "link": {"field": "agglomerative hierarchy", "type": "relation"}}}, {"nested": {"parent": {"mark": "line", "encoding": {"x": {"field": "dimension_2", "type": "nominal"}, "y": {"field": "dimension_1", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "axis", "configuration": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "dimension_2", "type": "temporal"}, "y": {"field": "score_1", "type": "quantitative"}, "color": {"field": "score_2", "type": "quantitative"}}}, {"mark": "image", "encoding": {"x": {"field": "image_x", "type": "nominal"}, "y": {"field": "image_y", "type": "nominal"}, "color": {"field": "pixel value", "type": "quantitative"}}}]}}}}]}, "marks": ["tree", "line", "bar", "image"], "channels": ["node", "link", "x", "y", "color"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["concat", "nested"], "aggregates": [], "actionTargets": ["query-identify:Attributes-values"], "figId": "vis-3295_00", "figFile": "vis-3295_00.png", "figCaption": "", "figBox": {"x": 0.6125140572694533, "y": 0.6593087247178919, "width": 0.38716963097140805, "height": 0.34247576651044087}, "figVis": ["bar_chart", "graph"], "relationText": "To efficiently explore the semantic representation space, a hierarchical parallel coordinates plot, (hPCP), is designed as shown in Fig. 1- d . Latent dimensions are hierarchically clustered with an agglomerative method to efficiently organize and navigate these dimensions", "note": "(((ordered images, [(image feature map),(bar)]), each row), G)"}, {"viewId": "vis-3296_00_0", "viewFile": "vis-3296_00_0.png", "specification": {"facet": {"field": "network index", "type": "ordinal"}, "spec": {"layer": [{"mark": "graph", "encoding": {"node": {"field": "network nodes", "type": "node"}, "link": {"field": "link", "type": "relation"}}}, {"mark": "arc", "encoding": {"theta": {"field": "value", "type": "quantitative"}, "color": {"field": "risk level", "type": "ordinal"}}}]}}, "marks": ["graph", "arc"], "channels": ["node", "link", "theta", "color"], "dataTypes": ["node", "relation", "quantitative", "ordinal"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values"], "figId": "vis-3296_00", "figFile": "vis-3296_00.png", "figCaption": "", "figBox": {"x": 0.004556970749566995, "y": 0.008004664576474125, "width": 0.3498799978684089, "height": 0.9817031510686903}, "figVis": ["graph", "pie_chart"], "relationText": "The Guarantee Network Explorer (GNE) view facilities an overview of and zooming in on a level of detail of a guarantee network, using a network tessellation layout. It provides intuitive and metaphorical symbols of contagion risk (through the Contagious Effect Badge (CEB) described in Section 5.2) to support selection by financial interest.", "note": "each icon is a graph plus its summary [G,(N,Q)]"}, {"viewId": "vis-3296_00_1", "viewFile": "vis-3296_00_1.png", "specification": {"nested": {"parent": {"mark": "matrix", "encoding": {"color": {"field": "risk level", "type": "ordinal"}, "column": {"field": "range of influence", "type": "quantitative"}, "row": {"field": "converible", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "graph", "encoding": {"node": {"field": "node", "type": "node"}, "link": {"field": "link", "type": "relation"}}}}}}, "marks": ["matrix", "graph"], "channels": ["color", "column", "row", "node", "link"], "dataTypes": ["ordinal", "quantitative", "node", "relation"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation"], "figId": "vis-3296_00", "figFile": "vis-3296_00.png", "figCaption": "", "figBox": {"x": 0.35692198134673697, "y": 0.015449810842704078, "width": 0.3446851244933344, "height": 0.6191098522254139}, "figVis": ["matrix"], "relationText": "Based on this core metric, we designed a Contagion Effect Matrix (CEM) view to encode the risks of each network in a matrix manner. It also works as a filter for chain-level analysis.: {contagion} correlate, filter", "note": ""}, {"viewId": "vis-3296_00_2", "viewFile": "vis-3296_00_2.png", "specification": {"mark": "point", "encoding": {"x": {"type": "quantitative", "field": "guarantee amount"}, "y": {"type": "quantitative", "field": "exposure"}, "shape": {"field": "coincide_level", "type": "ordinal"}}}, "marks": ["point"], "channels": ["x", "y", "shape"], "dataTypes": ["quantitative", "ordinal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3296_00", "figFile": "vis-3296_00.png", "figCaption": "", "figBox": {"x": 0.7034327600985587, "y": 0.010866751392567013, "width": 0.29942298383601107, "height": 0.6145508524555232}, "figVis": ["scatterplot", "glyph_based"], "relationText": "The Chain Instance Explorer (CIE) is a tailored financial coordinate system for middle-level (contagion chain) risk analysis.: {risk} retrieve value\n\nEach petal is clickable for the user to select the chain instances in other views.: filter", "note": ""}, {"viewId": "vis-3296_00_3", "viewFile": "vis-3296_00_3.png", "specification": {"mark": "point", "encoding": {"x": {"type": "quantitative", "field": "tsne_x"}, "y": {"type": "quantitative", "field": "tsne_y"}}}, "marks": ["point"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-values"], "figId": "vis-3296_00", "figFile": "vis-3296_00.png", "figCaption": "", "figBox": {"x": 0.35762690098282546, "y": 0.6722456953194447, "width": 0.640422958631111, "height": 0.31985500384185733}, "figVis": ["scatterplot"], "relationText": "In order to facilitate low-level (i.e., node-level) detail on demand for the finest grain analysis of guaranteed loans, we provide the node instance explorer.: {raw data of node instance} retrieve value", "note": ""}, {"viewId": "vis-3299_00_0", "viewFile": "vis-3299_00_0.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "entity", "type": "node"}, "link": {"field": "causal relation", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "arc", "encoding": {"theta": {"field": "value", "type": "quantitative"}, "color": {"field": "category", "type": "nominal"}}}}}}, "marks": ["graph", "arc"], "channels": ["node", "link", "theta", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-discover:Graphs-links/paths"], "figId": "vis-3299_00", "figFile": "vis-3299_00.png", "figCaption": "", "figBox": {"x": 0.3220121901133709, "y": 0.0660000059213182, "width": 0.6719735569669518, "height": 0.917181663392117}, "figVis": ["graph", "pie_chart"], "relationText": "a graph view for exploring the causal relations ", "note": ""}, {"viewId": "vis-3299_00_1", "viewFile": "vis-3299_00_1.png", "specification": {"facet": {"column": {"field": "dimension", "type": "nominal"}}, "spec": {"mark": "bar", "remark": "Histograms of all dimensions for comparative analyses of the distribution", "encoding": {"x": {"bin": true, "field": "dimension values"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3299_00", "figFile": "vis-3299_00.png", "figCaption": "", "figBox": {"x": 0.006308125760684208, "y": 0.061634191177176285, "width": 0.30439729786225916, "height": 0.5015783739945026}, "figVis": ["bar_chart"], "relationText": "Histograms of all dimensions for comparative analyses of the distributions.", "note": "Q#: distribution"}, {"viewId": "vis-3299_00_2", "viewFile": "vis-3299_00_2.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "percentage", "type": "quantitative"}, "y": {"field": "value", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3299_00", "figFile": "vis-3299_00.png", "figCaption": "", "figBox": {"x": 0.006308125760684202, "y": 0.5660269453936497, "width": 0.30439729786225933, "height": 0.4266509727503838}, "figVis": ["bar_chart"], "relationText": "Users can click on a histogram and the detail of the dimension will be shown in the Table view (Fig. 1(c)). Each row shows the name and the proportion of a dimension value. When hovering on a row, a control panel is provided to help users establish the intervention and attribution (Fig. 6(a)).", "note": "Q#: distribution"}, {"viewId": "vis-3300_00_0", "viewFile": "vis-3300_00_0.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"concat": {"type": "vertical"}, "spec": [{"mark": "point", "encoding": {"shape": {"field": "primitive", "type": "nominal"}, "x": {"field": "primitive", "type": "nominal"}}}, {"mark": "bar", "encoding": {"y": {"field": "correlations", "type": "quantitative", "remark": "showing correlations between primitive usage and pipeline scores"}, "x": {"field": "primitive", "type": "nominal"}}}, {"mark": "rect", "encoding": {"y": {"field": "system pipeline", "type": "nominal"}, "x": {"field": "primitive", "type": "nominal"}, "shape": {"field": "primitive", "type": "nominal"}, "color": {"field": "where it appears", "type": "nominal", "remark": "each primitive (node) is color-coded to indicate the pipeline where it appears"}}}]}, {"concat": {"type": "horizontal"}, "spec": [{"mark": "rect", "encoding": {"y": {"field": "system pipeline", "type": "nominal"}, "x": {"field": "parameters", "type": "nominal"}, "color": {"field": "where it appears", "type": "nominal", "remark": "each primitive (node) is color-coded to indicate the pipeline where it appears"}}}, {"mark": "bar", "encoding": {"y": {"field": "system pipeline", "type": "nominal"}, "x": {"field": "f1 score", "type": "quantitative"}}}]}]}, "marks": ["point", "bar", "rect"], "channels": ["shape", "x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["query-summarize:Attributes-values", "consume-present:Attributes-correlation"], "figId": "vis-3300_00", "figFile": "vis-3300_00.png", "figCaption": "", "figBox": {"x": 0.034559676362008934, "y": 0.1283775172248262, "width": 0.9323475000086683, "height": 0.6082812986270695}, "figVis": ["matrix", "bar_chart"], "relationText": "The Pipeline Matrix provides a summary for a collection of machine learning pipelines [R1] selected by the user. : derive value\n\nTo convey information about the relationships between primitive usage and pipeline scores [R5], we designed the Primitive Contribution view.: correlate\n", "note": "([(N, N), Q], N): left matrix, and left bar on the top. The matrix and bars on the right are with similar configuration\n"}, {"viewId": "vis-3305_00_0", "viewFile": "vis-3305_00_0.png", "specification": {"facet": {"row": {"field": "sample", "type": "nominal"}}, "spec": {"concat": {"type": "vertical"}, "spec": [{"mark": "area", "encoding": {"y": {"field": "pdf", "type": "quantitative"}, "x": {"field": "value", "type": "quantitative"}, "color": {"field": "cohort", "type": "nominal"}}}, {"mark": "tick", "encoding": {"x": {"field": "value", "type": "quantitative"}, "color": {"field": "cohort", "type": "nominal"}}}]}}, "marks": ["area", "tick"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values", "consume-discover:Attributes-outliers"], "figId": "vis-3305_00", "figFile": "vis-3305_00.png", "figCaption": "", "figBox": {"x": 0.0040823178989309135, "y": 0.19353062394020867, "width": 0.20982791389975716, "height": 0.7959403343884337}, "figVis": ["area_chart"], "relationText": "In the first step, we are interested to compare two cohorts according to the abundance of the different existing cell types in each of the contained samples (T1) and visually detect possible outliers in each of the cohorts (T3)", "note": "(Q, [Q,Q,N]): (x-axis, [blue/red line_and_color_at_the_bottom])"}, {"viewId": "vis-3305_00_1", "viewFile": "vis-3305_00_1.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"mark": "rect", "position": 1, "encoding": {"x": {"field": "center cell type", "type": "nominal"}, "y": {"field": "microenvironment", "type": "nominal"}, "color": {"field": "abundance of pairwise combina- tions of cell types", "type": "quantitative"}}}, {"mark": "rect", "position": 2, "encoding": {"x": {"field": "center cell type", "type": "nominal"}, "color": {"field": "center cell type", "type": "nominal"}}}, {"mark": "rect", "position": 5, "encoding": {"color": {"field": "microenvironment", "type": "nominal"}, "y": {"field": "microenvironment", "type": "nominal"}}}]}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3305_00", "figFile": "vis-3305_00.png", "figCaption": "", "figBox": {"x": 0.5791880185117547, "y": 0.014836204156578978, "width": 0.208324545494362, "height": 0.9760463911327375}, "figVis": ["heatmap"], "relationText": "The exploration of the differences between the two cohorts, with re- gard to the contained microenvironments (T2) starts with the overview provided by the difference heatmap (Fig. 8a).", "note": ""}, {"viewId": "vis-3306_00_0", "viewFile": "vis-3306_00_0.png", "specification": {"layer": [{"mark": "geoshape"}, {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"field": "transportation zone", "type": "node", "encoding": {"x": {"field": "zone pos x", "type": "quantitative"}, "y": {"field": "zone pos y", "type": "quantitative"}}}, "link": {"remark": "the numbers of the routes between the zones are encoded with the link widths", "field": "route", "type": "relation", "encoding": {"width": {"aggregate": "count", "field": "route", "type": "quantitative"}}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"layer": [{"mark": "area", "layout": "circular", "encoding": {"x": {"field": "geographical directions", "type": "nominal"}, "y": {"aggregate": "count", "field": "passenger flow", "type": "quantitative"}, "color": {"field": "leave/enter", "type": "nominal"}}}, {"mark": "radar", "encoding": {"theta": {"field": "criteria", "type": "nominal"}, "radius": {"field": "criteria_value", "type": "quantitative"}}}]}}}}]}, "marks": ["geoshape", "graph", "area", "radar"], "channels": ["node", "link", "x", "y", "width", "color", "theta", "radius"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["layer", "nested"], "aggregates": ["count"], "actionTargets": ["query-summarize:Graphs-graphs", "consume-present:Attributes-distribution", "query-compare:Graphs-nodes"], "figId": "vis-3306_00", "figFile": "vis-3306_00.png", "figCaption": "", "figBox": {"x": 0.006692485026953173, "y": 0.04781116129325366, "width": 0.572257105124942, "height": 0.5688650328704461}, "figVis": ["map", "glyph_based", "polar_plot"], "relationText": "Therefore, we designed the aggregation layer to visualize the topology with an aggregation graph. In addition, the numbers of the routes between the zones are encoded with the link widths.\n\nA zone glyph (Fig. 1D) is placed at the centroid of each transportation zone to summarize the key statistics of this zone.\n\nThe zone glyph summarizes the statistics and passenger flows of a transportation zone.\nTwo diverging circular distributions around the glyph visualize the amount of passenger flows by the geographical directions in which the passengers in this zone leave (green) or enter (orange). Double clicks magnify the glyphs, allowing users to obtain a clearer view of the radar charts inside. The design of this glyph is kept simple yet informative, such that the users can naturally obtain and compare the performance of different zones with a number of glyphs.", "note": "(area chart (Q, Q, N), radar inside (N, Q)) => a glyph,"}, {"viewId": "vis-3306_00_1", "viewFile": "vis-3306_00_1.png", "specification": {"concat": {"layout": "crossing"}, "spec": [{"mark": "rect", "position": 1, "encoding": {"y": {"field": "bus stop", "type": "nominal"}, "x": {"field": "bus stop", "type": "nominal"}, "color": {"aggregate": "count", "field": "passengers traveling", "type": "quantitative"}}}, {"position": 2, "facet": {"row": {"field": "bus stop", "type": "nominal"}}, "spec": {"mark": "area", "layout": "horizon", "encoding": {"y": {"aggregate": "count", "field": "passengers check-out", "type": "quantitative"}, "x": {"field": "time", "type": "temporal", "bin": "true"}}}}, {"mark": "bar", "position": 3, "encoding": {"x": {"aggregate": "count", "field": "passengers check-out", "type": "quantitative"}, "y": {"field": "bus stop", "type": "nominal"}}}, {"mark": "bar", "position": 4, "encoding": {"y": {"aggregate": "count", "field": "passengers check-in", "type": "quantitative"}, "x": {"field": "bus stop", "type": "nominal"}}}, {"position": 5, "facet": {"column": {"field": "bus stop", "type": "nominal"}}, "spec": {"mark": "area", "layout": "horizon", "encoding": {"x": {"aggregate": "count", "field": "passengers check-in", "type": "quantitative"}, "y": {"field": "time", "type": "temporal", "bin": "true"}}}}]}, "marks": ["rect", "area", "bar"], "channels": ["y", "x", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": ["count", "bin"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3306_00", "figFile": "vis-3306_00.png", "figCaption": "", "figBox": {"x": 0.5857294306415453, "y": 0.06387173787417323, "width": 0.407670240423353, "height": 0.5491617736966611}, "figVis": ["matrix", "heatmap", "bar_chart"], "relationText": "A flow matrix (Fig. 4A) is designed to visualize the passenger flows and transfers. ", "note": "((matrix), N)"}, {"viewId": "vis-3306_00_2", "viewFile": "vis-3306_00_2.png", "specification": {"facet": {"column": {"field": "metric", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "area", "encoding": {"x": {"field": "metric value", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "metric value", "type": "quantitative"}, "y": {"field": "route", "type": "ordinal"}}}]}}, "marks": ["area", "bar"], "channels": ["x", "y"], "dataTypes": ["quantitative"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["produce:Attributes-order"], "figId": "vis-3306_00", "figFile": "vis-3306_00.png", "figCaption": "", "figBox": {"x": 0.00812929633227794, "y": 0.6339404745862368, "width": 0.8010588429417356, "height": 0.3635116560349902}, "figVis": ["table", "area_chart", "bar_chart"], "relationText": "Inspired by LineUp [27], a table-based ranking visualization is included in the route ranking view to facilitate the multicriteria analysis of the routes.", "note": ""}, {"viewId": "vis-3307_00_0", "viewFile": "vis-3307_00_0.png", "specification": {"facet": {"row": {"field": "attribute types", "type": "nominal"}}, "spec": {"facet": {"column": {"field": "attribute level 1", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "attribute tec level 2", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3307_00", "figFile": "vis-3307_00.png", "figCaption": "", "figBox": {"x": 0.012258620563342539, "y": 0.07779105102051616, "width": 0.19016691175093933, "height": 0.4341211040015908}, "figVis": ["bar_chart"], "relationText": "We design Attribute Editor (Fig. 1(A)) to adjust the weights of different attributes and group similar values (T1, T3). Users can expand the bottom to view detailed information of values in an attribute (Fig. 1(A1)) and group similar values (T3).: compare", "note": ""}, {"viewId": "vis-3307_00_1", "viewFile": "vis-3307_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "unit", "encoding": {"unit": {"field": "subset A event", "type": "node"}, "y": {"field": "subset A pattern", "type": "nominal"}, "icon": {"field": "subset A event type", "type": "nominal"}}}, {"layer": [{"mark": "bar", "encoding": {"x": {"field": "winning rate", "type": "nominal"}, "y": {"field": "event", "type": "quantitative"}, "color": {"field": "higher one", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "winning rate", "type": "nominal"}, "y": {"field": "event", "type": "quantitative"}, "color": {"field": "subset", "type": "nominal"}}}]}, {"mark": "unit", "encoding": {"unit": {"field": "subset B event", "type": "node"}, "y": {"field": "subset B pattern", "type": "nominal"}, "icon": {"field": "subset B event type", "type": "nominal"}}}]}, "marks": ["unit", "bar", "line"], "channels": ["unit", "y", "icon", "x", "color"], "dataTypes": ["node", "nominal"], "compositions": ["concat", "layer"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3307_00", "figFile": "vis-3307_00.png", "figCaption": "", "figBox": {"x": 0.21631520516259026, "y": 0.055463729142618566, "width": 0.581213298518323, "height": 0.930265864427235}, "figVis": ["bar_chart", "glyph_based", "line_chart"], "relationText": "We design Pattern Comparator to help experts compare patterns one-to-one, where juxtaposition is a commonly used method.", "note": "[bar chart, line chart]"}, {"viewId": "vis-3307_00_2", "viewFile": "vis-3307_00_2.png", "specification": {"nested": {"parent": {"mark": "point", "encoding": {"x": {"field": "dimension_1", "type": "quantitative"}, "y": {"field": "dimension_2", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "point", "configuration": {"mark": "arc", "encoding": {"theta": {"field": "subset", "type": "quantitative"}, "color": {"field": "subset", "type": "nominal"}, "size": {"field": "frequency", "type": "quantitative"}, "outside_arc": {"field": "winning percentage", "type": "quantitative"}}}}}}, "marks": ["point", "arc"], "channels": ["x", "y", "theta", "color", "size", "outside_arc"], "dataTypes": ["quantitative", "nominal"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-clusters"], "figId": "vis-3307_00", "figFile": "vis-3307_00.png", "figCaption": "", "figBox": {"x": 0.8011097504545741, "y": 0.059490285081111295, "width": 0.19279753722054743, "height": 0.3365656460305774}, "figVis": ["scatterplot"], "relationText": "Scatterplot help users overview the patterns of two subsets and quickly focus on interesting ones. The distance between them shows the similarity between the patterns: cluster", "note": "(glyph, Q, Q)"}, {"viewId": "vis-3307_00_3", "viewFile": "vis-3307_00_3.png", "specification": {"mark": "unit", "encoding": {"unit": {"field": "instance", "type": "node"}, "y": {"field": "instance index", "type": "ordinal"}, "icon": {"field": "win/lose", "type": "nominal"}, "color": {"field": "subset", "type": "nominal"}}}, "marks": ["unit"], "channels": ["unit", "y", "icon", "color"], "dataTypes": ["node", "ordinal", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Attributes-values"], "figId": "vis-3307_00", "figFile": "vis-3307_00.png", "figCaption": "", "figBox": {"x": 0.8011028418690233, "y": 0.40391610057685223, "width": 0.18966505692721547, "height": 0.5776059226624158}, "figVis": ["others"], "relationText": "All the sequences with a certain pattern are shown in the Instance View (Fig. 1(E)) for detailed information (T5)", "note": "N\u4e2aevent sequence"}, {"viewId": "vis-3308_00_0", "viewFile": "vis-3308_00_0.png", "specification": {"facet": {"column": {"field": "attribute", "type": "nominal"}, "row": {"field": "subgroup", "type": "nominal"}}, "spec": {"condition_1": {"remark": "", "test": "subgroup with r-counterfactuals", "value": {"facet": {"layout": "mirrored", "row": {"field": "instances/CF examples", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "attribute value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}, "texture": {"field": "true/false", "type": "nominal"}, "color": {"field": "prediction class and instances hardly be altered", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "attribute value", "type": "quantitative"}, "y": {"field": "gini impurity", "type": "quantitative"}, "color": {"field": "gini impurity", "type": "quantitative"}}}]}}}, "condition_2": {"remark": "The first column shows the predictions of the instances ina stacked bar chart, where each bar represents a prediction class.", "test": "first column", "value": {"mark": "bar", "encoding": {"x": {"field": "class", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}, "texture": {"field": "true/false", "type": "nominal"}, "color": {"field": "prediction class", "type": "nominal"}}}}}}, "marks": ["bar", "line"], "channels": ["x", "y", "texture", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution", "query-compare:Attributes-clusters", "query-summarize:Attributes-clusters"], "figId": "vis-3308_00", "figFile": "vis-3308_00.png", "figCaption": "", "figBox": {"x": 0.03294279081842311, "y": 0.02575242465913131, "width": 0.7094307972907924, "height": 0.6114483475345159}, "figVis": ["bar_chart", "table"], "relationText": "R3 Select and refine a data subgroup of interest.: filter\nR5 Compare the counterfactual examples of different sub-groups: compare\n\nThe table header (Fig.1A1) presents the overall data distribution of the features in a set of linked histograms/bar charts.\n\nThe subgroup list (Fig.1A2) allows users to create, refine, and compare different subgroups. Here, each row corresponds to a subgroup. The first column presents the predictions of the instances in the same design used in the table header. In other columns, each cell (i, j) presents a summary of the subgroup i with r-counterfactuals for the feature j (introduced in Sect. 5.2). The subgroup list is initialed with one default group, which is the whole dataset with unconstrained CF examples", "note": "((bar chart), N, N)"}, {"viewId": "vis-3308_00_1", "viewFile": "vis-3308_00_1.png", "specification": {"facet": {"column": {"field": "attribute", "type": "nominal"}, "row": {"field": "instance", "type": "nominal"}}, "spec": {"condition_1": {"remark": "For numerical features, we use a line segment to show how the change is made.", "test": "numerical features", "value": {"mark": "line", "encoding": {"x": {"field": "feature value of the original instance", "type": "quantitative"}, "x2": {"field": "feature value of the CF example", "type": "quantitative"}, "y": {"field": "pred value", "type": "quantitative"}, "color": {"field": "original instance/CF example/positive or negative", "type": "nominal"}}}}, "condition_2": {"remark": "For categorical features, we use two broad line segments to indicate the category of the original instance (in a deeper color) and the CF example (in a lighter color).", "test": "categorical features", "value": {"mark": "tick", "encoding": {"x": {"field": "category", "type": "nominal"}, "y": {"field": "pred value", "type": "quantitative"}, "color": {"field": "prediction class", "type": "nominal"}}}}}}, "marks": ["line", "tick"], "channels": ["x", "x2", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3308_00", "figFile": "vis-3308_00.png", "figCaption": "", "figBox": {"x": 0.032942790818423086, "y": 0.6347812060656737, "width": 0.7094307972907916, "height": 0.3559944506153864}, "figVis": ["bar_chart", "table"], "relationText": "When users click a cell in the subgroup list, the instance lens (Fig.1A3) presents details pertaining to each instance and CF examples.", "note": "((bar chart), N, N)"}, {"viewId": "vis-3308_00_2", "viewFile": "vis-3308_00_2.png", "specification": {"layer": [{"mark": "line", "encoding": {"x": {"field": "attribute value", "type": "quantitative", "bin": true}, "y": {"field": "attribute", "type": "nominal"}}}, {"facet": {"row": {"field": "attribute", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "attribute value", "type": "quantitative", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "hover or not", "type": "nominal"}}}}]}, "marks": ["line", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["layer", "facet"], "aggregates": ["bin", "count"], "actionTargets": ["consume-present:Attributes-distribution", "query-compare:Attributes-values"], "figId": "vis-3308_00", "figFile": "vis-3308_00.png", "figCaption": "", "figBox": {"x": 0.7712194690589029, "y": 0.026857491804376608, "width": 0.20519718075303958, "height": 0.9497934949141964}, "figVis": ["bar_chart"], "relationText": "The distribution of each feature value is presented in a histogram, which suggests the users compare the instance\u2019s feature values with the overall distribution of the whole\ndataset.", "note": "((histogram, N), relations)"}, {"viewId": "vis-3309_00_0", "viewFile": "vis-3309_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "data source", "type": "nominal"}, "color": {"field": "data source", "type": "nominal"}, "shape": {"field": "confirmed dimensionality reductionifts/highlight time segments", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color", "shape"], "dataTypes": ["ordinal", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["produce:Attributes-values"], "figId": "vis-3309_00", "figFile": "vis-3309_00.png", "figCaption": "", "figBox": {"x": 0.009048035173452814, "y": 0.8824735132921779, "width": 0.9832185449749699, "height": 0.10921090409417569}, "figVis": ["others"], "relationText": "DR1. Provide an overview of concept dimensionality reductionift occurrences over time.\n\nAs required by DR1, the timeline navigator view presents the entire timeline and the indices of concept dimensionality reductionifts from multiple data sources (see Figure 1(b)).: {raw occurrences} retrieve value", "note": ""}, {"viewId": "vis-3309_00_1", "viewFile": "vis-3309_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "ordinal"}, "y": {"field": "accuracy", "type": "quantitative"}, "color": {"field": "time segments", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "projected x", "type": "quantitative"}, "y": {"field": "projected y", "type": "quantitative"}, "color": {"field": "time segments", "type": "nominal"}}}]}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["query-identify:Attributes-range", "search-locate:Attributes-outliers"], "figId": "vis-3309_00", "figFile": "vis-3309_00.png", "figCaption": "", "figBox": {"x": 0.0064285705311567425, "y": 0.6089938024270413, "width": 0.9864855512767511, "height": 0.28372482392826726}, "figVis": ["line_chart"], "relationText": "Different data sources may issue dimensionality reductionift warnings at similar time segments.: {warning} anomaly\n\nthe start and end moments of different time segments can be clearly distinguished.", "note": ""}, {"viewId": "vis-3309_00_2", "viewFile": "vis-3309_00_2.png", "specification": {"facet": {"row": {"field": "data source", "type": "nominal"}}, "spec": {"mark": "rect", "encoding": {"x": {"field": "arriving time", "type": "ordinal"}, "color": {"field": "risk level", "type": "ordinal"}}}}, "marks": ["rect"], "channels": ["x", "color"], "dataTypes": ["ordinal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["produce:Attributes-values"], "figId": "vis-3309_00", "figFile": "vis-3309_00.png", "figCaption": "", "figBox": {"x": 0.7328055725327962, "y": 0.004233172088437155, "width": 0.2626857432526168, "height": 0.5927365970474111}, "figVis": ["heatmap"], "relationText": "DR3 Identify the context of concepts and allow adjustments.\n\nThe concept-time view displays the time segments in different data sources that are integrated for concept analysis, as shown in Figure 1(d). To display the sources of the applied data records, as mentioned in DR3, ", "note": "\uff08(x, luminance), \u591a\u4e2a\uff09"}, {"viewId": "vis-3309_00_3", "viewFile": "vis-3309_00_3.png", "specification": {"facet": {"column": {"field": "attribute", "type": "nominal"}, "row": {"field": "attribute", "type": "nominal"}}, "spec": {"condition_1": {"test": "non-diagonal", "value": {"mark": "rect", "encoding": {"x": {"field": "data source", "type": "nominal"}, "y": {"field": "data source", "type": "nominal"}, "color": {"field": "difference ratio", "type": "quantitative"}}}}, "condition_2": {"test": "diagonal", "value": {"facet": {"layout": "mirrored", "row": {"field": "side", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "data source", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}}}}}}, "marks": ["rect", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-correlation", "query-compare:Attributes-distribution"], "figId": "vis-3309_00", "figFile": "vis-3309_00.png", "figCaption": "", "figBox": {"x": 0.30491128559391834, "y": 0.008927859257855822, "width": 0.4256720425027603, "height": 0.6008896153233418}, "figVis": ["matrix"], "relationText": "DR4 Study the relationship between attributes and labels.: correlate\nDR5 Compare concepts in different contexts.: compare\n\nA correlation matrix (Figure 1(e)) is employed to support DR4 because of its representation ability [44, 48]. The identified concepts can be compared with other concepts (DR5, see Figure 3(e)).", "note": ""}, {"viewId": "vis-3311_00_0", "viewFile": "vis-3311_00_0.png", "specification": {"nested": {"parent": {"mark": "tree", "encoding": {"node": {"field": "filter", "type": "node"}, "link": {"field": "filter hierarchy", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "bar", "encoding": {"y": {"field": "indicator type", "type": "nominal"}, "x": {"field": "indicator value", "type": "quantitative"}, "color": {"field": "accuracy/compression", "type": "nominal"}}}}}}, "marks": ["tree", "bar"], "channels": ["node", "link", "y", "x", "color"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["nested"], "aggregates": [], "actionTargets": ["query-summarize:Graphs-graphs"], "figId": "vis-3311_00", "figFile": "vis-3311_00.png", "figCaption": "", "figBox": {"x": 0.03423143776061108, "y": 0.0130237595709676, "width": 0.21401109533127213, "height": 0.7248505057283657}, "figVis": ["bar_chart", "tree"], "relationText": "The Tree view provides an overview of the iterative model pruning process (R1.1). ", "note": ""}, {"viewId": "vis-3311_00_1", "viewFile": "vis-3311_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "rect", "encoding": {"x": {"field": "class", "type": "nominal"}, "y": {"field": "class", "type": "nominal"}, "lightness": {"field": "frequency", "type": "quantitative"}}}, {"layer": [{"mark": "boxplot", "encoding": {"x": {"field": "id", "type": "ordinal"}, "y": {"field": "accuracy", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "id", "type": "ordinal"}, "y": {"aggregate": "average", "field": "accuracy", "type": "quantitative"}}}]}, {"mark": "line", "encoding": {"x": {"field": "id", "type": "ordinal"}, "y": {"field": "loss", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "id", "type": "nominal"}, "y": {"field": "epoch", "type": "quantitative"}}}, {"layer": [{"mark": "bar", "encoding": {"x": {"field": "id", "type": "nominal"}, "y": {"field": "gflops", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "id", "type": "nominal"}, "y": {"field": "gflops", "type": "quantitative"}}}]}]}, "marks": ["rect", "boxplot", "line", "bar"], "channels": ["x", "y", "lightness"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat", "layer"], "aggregates": ["average"], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-3311_00", "figFile": "vis-3311_00.png", "figCaption": "", "figBox": {"x": 0.25766523818562376, "y": 0.008376922707248496, "width": 0.7111581745683546, "height": 0.23827921487837583}, "figVis": ["bar_chart", "line_chart", "matrix"], "relationText": "R1.2: display the states of the pruned models and monitor\nthe evolution of these states over the pruning process.\n\nThe Statistics view (Fig. 1-b) is used to display detailed statistical information of the CNNs (R1.2)", "note": "[matrix, line+scatter, line, bar, bar+line]"}, {"viewId": "vis-3311_00_2", "viewFile": "vis-3311_00_2.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "radar", "encoding": {"theta": {"field": "metric_type", "type": "nominal"}, "radius": {"field": "metric_value", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "sensitivity", "type": "quantitative"}, "y": {"field": "cnn layer", "type": "nominal"}, "color": {"field": "cnn layer", "type": "nominal"}}}]}, "marks": ["radar", "point"], "channels": ["theta", "radius", "x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "produce:Attributes-values"], "figId": "vis-3311_00", "figFile": "vis-3311_00.png", "figCaption": "", "figBox": {"x": 0.2601149540003573, "y": 0.4278438203323212, "width": 0.7099008374113038, "height": 0.2588500750650146}, "figVis": ["scatterplot", "polar_plot"], "relationText": "R1.3: visualize the internal structure of a selected CNN model (e.g., the original/intermediate/final pruned model) and its filters\u2019 attributes.\nR2.1: estimate the influence of a pruning plan on the model before the pruning actually happens (i.e., pre-estimation).\n\nThe visualization of filter evaluation is shown in Fig. 1-c2, which consists of a radar plot and a bubble plot (R1.3, R2.1). \n\nThe radar plot shows the impact of the pruning plan on the current model.: correlate", "note": "(x, area, row/color)"}, {"viewId": "vis-3311_00_3", "viewFile": "vis-3311_00_3.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "point", "encoding": {"x": {"field": "dimension1", "type": "quantitative"}, "y": {"field": "dimension2", "type": "quantitative"}, "color": {"field": "feature class", "type": "nominal"}}}, {"facet": {"field": "example id", "type": "ordinal"}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "area", "encoding": {"x": {"field": "pixel values", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "value", "type": "quantitative"}, "y": {"field": "sensitivity/instability", "type": "nominal"}}}]}}]}, "marks": ["point", "area", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "query-compare:Attributes-values"], "figId": "vis-3311_00", "figFile": "vis-3311_00.png", "figCaption": "", "figBox": {"x": 0.0409075648399157, "y": 0.7523121523003392, "width": 0.9264805687305087, "height": 0.24322839925153109}, "figVis": ["scatterplot", "area_chart"], "relationText": "\u2013 R3.1: visualize the filters of interest and help the user understand the roles that different filters played during pruning.\n\u2013 R3.2: interactively refine the pruning plan by adding or removing filters to be pruned to reduce undesired changes of the model over the pruning.\n\nFrom the filter visualization matrix, we can see that the system deletes the filters that have the lowest sensitivity and highest instability, i.e., Filter 0 and Filter 5 (see the blue and green bar on the right of the filter visualization).\n\nThe area chart on the top right of the item shows the distribution of pixel values of the\nfilter visualization images.: distribution", "note": "[(\u6563\u70b9\u56fe), (\u76f4\u65b9\u56fe, \u591a\u4e2a)]"}, {"viewId": "vis-3315_00_0", "viewFile": "vis-3315_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"aggregate": "count", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "time", "type": "temporal", "bin": true}, "y": {"aggregate": "count", "type": "quantitative"}}}]}, "marks": ["line", "bar"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": ["concat"], "aggregates": ["count", "bin"], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3315_00", "figFile": "vis-3315_00.png", "figCaption": "", "figBox": {"x": 0.00960704805943775, "y": 0.0073076658906553885, "width": 0.9828313663976225, "height": 0.19107170934086157}, "figVis": ["bar_chart"], "relationText": "R1 Enable interactive configurations for suspicious RPTTE groups detection.\n\nUsers can select their period of concern by brushing or clicking a bar to automatically select the quarter, which is a typical tax period (R1).: filter\n\nThe bar chart on the right-hand side of the Control Panel offers a temporal summary of the daily related party transaction amount, which reveals a cyclic pattern where most of the peaks are near the end of the month", "note": ""}, {"viewId": "vis-3315_00_1", "viewFile": "vis-3315_00_1.png", "specification": {"facet": {"row": {"field": "group", "type": "ordinal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "graph", "encoding": {"node": {"field": "party transactions", "type": "node"}, "link": {"field": "relation", "type": "relation"}}}, {"mark": "bar", "encoding": {"x": {"field": "group feature", "type": "nominal"}, "y": {"field": "group feature value", "type": "quantitative"}, "color": {"field": "group feature", "type": "nominal"}}}]}}, "marks": ["graph", "bar"], "channels": ["node", "link", "x", "y", "color"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": [], "figId": "vis-3315_00", "figFile": "vis-3315_00.png", "figCaption": "", "figBox": {"x": 0.005526677262072635, "y": 0.20543706492780822, "width": 0.2443982894705225, "height": 0.7832383323589053}, "figVis": ["bar_chart", "graph"], "relationText": "R2 Rank suspicious tax evasion groups with multiple criteria.\n\nThe Group Overview (Fig. 1(B)) shows a list of suspicious RPTTE groups, in which each row represents a suspicious RPTTE group, and consists of an arc-diagram based glyph and a bar chart to help users focus on the most suspicious groups (R2).", "note": "([relation, bar chart], items)"}, {"viewId": "vis-3315_00_2", "viewFile": "vis-3315_00_2.png", "specification": {"mark": "tree", "encoding": {"node": {"field": "party transactions", "type": "node"}, "link": {"field": "hierarchical investment relationship", "type": "relation"}}}, "marks": ["tree"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-graphs"], "figId": "vis-3315_00", "figFile": "vis-3315_00.png", "figCaption": "", "figBox": {"x": 0.25915553061466173, "y": 0.19411985277069693, "width": 0.7339626491387834, "height": 0.3235687861401135}, "figVis": ["graph"], "relationText": "R3 Support the interactive exploration of the common beneficial owners of taxpayers who conduct the related party transactions and their attributes.\n\nThe Graph View (Fig. 4) shows the hierarchical investment relationship and related party transactions within the selected suspicious group\n(R3)", "note": ""}, {"viewId": "vis-3315_00_3", "viewFile": "vis-3315_00_3.png", "specification": {"layer": [{"facet": {"column": {"field": "comparison targets", "type": "nominal"}}, "spec": {"mark": "unit", "layout": "calendar", "encoding": {"unit": {"field": "day", "type": "node"}, "color": {"field": "loss/profit value", "type": "quantitative"}}}}, {"mark": "graph", "encoding": {"node": {"field": "party transactions", "type": "node", "encoding": {"color": {"field": "loss/profit", "type": "nominal"}, "size": {"field": "loss/profit value", "type": "quantitative"}}}, "link": {"field": "same day", "type": "relation"}}}]}, "marks": ["unit", "graph"], "channels": ["unit", "color", "node", "link", "size"], "dataTypes": ["node", "quantitative", "relation"], "compositions": ["layer", "facet"], "aggregates": [], "actionTargets": ["query-compare:Graphs-graphs"], "figId": "vis-3315_00", "figFile": "vis-3315_00.png", "figCaption": "", "figBox": {"x": 0.25985004088668395, "y": 0.5243777032502955, "width": 0.7366645536277346, "height": 0.46332041406532576}, "figVis": ["heatmap"], "relationText": "By comparing the colors of the visual marks on the same day, users can observe and assess the influence of the related party transaction on the profit status of the two taxpayers.", "note": "((month/week, day, luminance), relation)"}, {"viewId": "vis-3317_00_0", "viewFile": "vis-3317_00_0.png", "specification": {"facet": {"row": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "student", "aggregate": "count", "type": "quantitative"}, "x": {"field": "feature_value", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["y", "x"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3317_00", "figFile": "vis-3317_00.png", "figCaption": "", "figBox": {"x": 0.008958145900171365, "y": 0.38190765206994415, "width": 0.21349795336939548, "height": 0.24879189610977973}, "figVis": ["bar_chart"], "relationText": "shows the distribution of students among different scores, grades, and also time invested in the problem-solving process using the bar chart: distribution", "note": ""}, {"viewId": "vis-3317_00_1", "viewFile": "vis-3317_00_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "rect", "encoding": {"y": {"field": "error", "sort": "count_of_student", "type": "nominal"}, "color": {"field": "student", "aggregate": "count", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"y": {"field": "incorrect_or_correct", "type": "nominal"}, "x": {"field": "step", "type": "ordinal"}, "color": {"field": "student", "aggregate": "count", "type": "quantitative"}}}, {"mark": "rect", "encoding": {"y": {"field": "error", "type": "nominal"}, "color": {"field": "student", "aggregate": "count", "type": "quantitative"}}}]}, "marks": ["rect"], "channels": ["y", "color", "x"], "dataTypes": ["nominal", "quantitative", "ordinal"], "compositions": ["concat"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3317_00", "figFile": "vis-3317_00.png", "figCaption": "", "figBox": {"x": 0.008280782293171536, "y": 0.6684563264272227, "width": 0.21349355458015912, "height": 0.3214633601837998}, "figVis": ["heatmap"], "relationText": "Common errors panel (Fig. 1(a3)) gives an overall insight into the errors student made when solving theproblem: derived value (count of each case)\nhe ranked list of common errors based on descending order of frequency: sort", "note": "(y, [color, (paths, step, color), color])"}, {"viewId": "vis-3317_00_2", "viewFile": "vis-3317_00_2.png", "specification": {"nested": {"parent": {"mark": "sankey", "encoding": {"node": {"field": "state", "type": "node", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "stage", "type": "nominal", "remark": "number of correct conditions"}}}, "link": {"field": "state_transition", "type": "relation", "encoding": {"width": {"field": "student", "aggregate": "count", "type": "quantitative"}}}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"mark": "rect", "encoding": {"y": {"field": "condition", "type": "nominal"}, "width": {"field": "student_reached_the_state", "aggregate": "count", "type": "quantitative"}, "color": {"field": "student_fulfill_the_condition", "aggregate": "count", "type": "quantitative"}}}}}}, "marks": ["sankey", "rect"], "channels": ["node", "link", "x", "y", "width", "color"], "dataTypes": ["node", "relation", "ordinal", "nominal", "quantitative"], "compositions": ["nested"], "aggregates": ["count"], "actionTargets": ["consume-present:Graphs-links/paths"], "figId": "vis-3317_00", "figFile": "vis-3317_00.png", "figCaption": "", "figBox": {"x": 0.22111899933148532, "y": 0.011633047319154419, "width": 0.5863036474049969, "height": 0.7918283016998844}, "figVis": ["sankey_diagram", "glyph_based"], "relationText": "Transition graph,as shown in Fig. 5, intuitively visualizes how a group of students fulfill a set of conditions step by step in order to reach the final an-swer (i.e., the problem-solving logic): {group} cluster, {reach} correlate", "note": "(step, number of correct answer, (y, color, width))"}, {"viewId": "vis-3317_00_3", "viewFile": "vis-3317_00_3.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "time", "aggregate": "average", "type": "quantitative"}, "color": {"field": "group", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "step", "type": "ordinal"}, "length": {"field": "student_try_the_question", "aggregate": "count", "type": "quantitative"}, "color": {"field": "student_reach_the_step_or_not", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "length", "aggregate": "average", "type": "quantitative"}, "color": {"field": "group", "type": "nominal"}}}]}, "marks": ["line", "bar"], "channels": ["x", "y", "color", "length"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": ["concat"], "aggregates": ["average", "count"], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3317_00", "figFile": "vis-3317_00.png", "figCaption": "", "figBox": {"x": 0.236016853483369, "y": 0.8201538111782113, "width": 0.57213788813845, "height": 0.16094999351140046}, "figVis": ["line_chart"], "relationText": "The engagement chart (Fig. 6) shows the efforts students pay on each step when solving the question.\nThe upper line chart shows the average time spent in seconds on each step, and the lower line chart shows the trajectory length of the cursor in pixels in each step: derived value: derived value (engagement)\n\nT4: comparison", "note": "I feel correlate is not a major task in this vis though the x-axis is step.\n\n(step, [lines and blocks])"}, {"viewId": "vis-3317_00_4", "viewFile": "vis-3317_00_4.png", "specification": {"facet": {"column": {"field": "group", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"facet": {"row": {"field": "stage", "type": "nominal", "remark": "number of correct conditions"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "rect", "encoding": {"y": {"field": "condition", "type": "nominal"}, "width": {"field": "student_reached_the_stage", "aggregate": "count", "type": "quantitative"}, "color": {"field": "student_fulfill_the_condition", "aggregate": "count", "type": "quantitative"}}}, {"mark": "boxplot", "encoding": {"x": {"field": "average_transition_time_distribution", "type": "quantitative"}}}]}}, {"mark": "bar", "encoding": {"y": {"field": "student", "aggregate": "count", "type": "quantitative"}, "color": {"field": "group", "type": "nominal"}}}]}}, "marks": ["rect", "boxplot", "bar"], "channels": ["y", "width", "color", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-clusters"], "figId": "vis-3317_00", "figFile": "vis-3317_00.png", "figCaption": "", "figBox": {"x": 0.8144397618327065, "y": 0.013806138908643071, "width": 0.1785989551778888, "height": 0.9737885222104525}, "figVis": ["box_plot", "glyph_based"], "relationText": "Comparison View, as shown in Fig. 1(c), aims to provide a sum-marized representation and comparison on how different groups ofstudents\u2019 approach a question presented to them: compare", "note": "(group, [bar height, (y, [glyph, box, triangle])])"}, {"viewId": "vis-3322_00_0", "viewFile": "vis-3322_00_0.png", "specification": {"facet": {"field": "alternative", "type": "nominal"}, "spec": {"layer": [{"mark": "bar", "encoding": {"x": {"field": "coefficient", "type": "quantitative"}, "y": {"field": "universe", "type": "nominal", "aggregate": "count"}}, "remark": "represented as unit visualization"}, {"mark": "area", "encoding": {"x": {"field": "coefficient", "type": "quantitative"}, "y": {"field": "uncertainty", "type": "quantitative"}}}]}}, "marks": ["bar", "area"], "channels": ["x", "y"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "layer"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3322_00", "figFile": "vis-3322_00.png", "figCaption": "", "figBox": {"x": 0.40661607219102663, "y": 0.103151066831784, "width": 0.39779728584616847, "height": 0.6253878539221221}, "figVis": ["unit_visualization", "area_chart"], "relationText": "The outcome view visualizes the final results of the multiverse, including point estimates (e.g., model coefficient of reader view, the independent variable encoding experimental conditions) and uncertainty information. By default, the chart contains outcomes from all\nuniverses in order to show the overall robustness of the conclusion (T2): {model coefficient, uncertainty} derive value ", "note": "(N, (unit, area))"}, {"viewId": "vis-3322_00_1", "viewFile": "vis-3322_00_1.png", "specification": {"facet": {"row": {"field": "unverse", "type": "nominal"}}, "spec": {"mark": "boxplot", "encoding": {"yoffset": {"field": "observed/predicted", "type": "nominal"}, "color": {"field": "observed/predicted", "type": "nominal"}, "x": {"field": "speed", "type": "quantitative"}}}}, "marks": ["boxplot"], "channels": ["yoffset", "color", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3322_00", "figFile": "vis-3322_00.png", "figCaption": "", "figBox": {"x": 0.8051182882941545, "y": 0.022092893121974072, "width": 0.1909520716979047, "height": 0.9623413675677379}, "figVis": ["others"], "relationText": " the model fit view with visual predictive checks, which show how well predictions from a given model replicate the empirical distribution of observed data [14], allowing users to further assess model quality (T5): distribution, compare", "note": "vis: violin plot"}, {"viewId": "vis-3322_00_2", "viewFile": "vis-3322_00_2.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "decision", "type": "node", "encoding": {"size": {"field": "alternatives", "aggregate": "count", "type": "quantitative"}}}, "link": {"field": "decision_path", "type": "relation", "encoding": {"color": {"field": "temporal_order_or_procedural_dependency", "type": "nominal"}}}}}, "marks": ["graph"], "channels": ["node", "link", "size", "color"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": [], "aggregates": ["count"], "actionTargets": ["consume-present:Graphs-links/paths"], "figId": "vis-3322_00", "figFile": "vis-3322_00.png", "figCaption": "", "figBox": {"x": 0.20306414537941048, "y": 0.02857124015963725, "width": 0.19335247542061743, "height": 0.9559118273041003}, "figVis": ["graph"], "relationText": "The decision view shows a graph of analytic decisions in the multiverse, along with their order and dependencies (Fig. 5a), helping users understand the decision space and inviting further exploration.", "note": "(color, size, graph)"}, {"viewId": "vis-3322_00_3", "viewFile": "vis-3322_00_3.png", "specification": {"facet": {"field": "decision", "type": "nominal", "columns": 3}, "spec": {"mark": "bar", "encoding": {"x": {"field": "result", "aggregate": "count", "type": "quantitative"}, "color": {"field": "result", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution", "query-identify:Attributes-extremes"], "figId": "vis-3322_00", "figFile": "vis-3322_00.png", "figCaption": "", "figBox": {"x": 0.41298780617565495, "y": 0.7239218040920202, "width": 0.38391506407870196, "height": 0.2587207919311268}, "figVis": ["bar_chart"], "relationText": "The option ratio view visualizes each decision as a stacked bar chart, where bar segment length encodes the percentage of results coming from an alternative\nThe option ratio view shows percentages of decision options to reveal dominating alternatives that produce specific results (T3).", "note": ""}, {"viewId": "vis-3326_01_0", "viewFile": "vis-3326_01_0.png", "specification": {"facet": {"column": {"field": "model", "type": "nominal"}}, "spec": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_1", "type": "quantitative"}, "y": {"field": "dimensionality reduction_2", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}}, "marks": ["point"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-identify:Attributes-clusters"], "figId": "vis-3326_01", "figFile": "vis-3326_01.png", "figCaption": "", "figBox": {"x": 0.001436186097076777, "y": -0.0037758577799990823, "width": 0.6970831718244417, "height": 0.5831093071544899}, "figVis": ["scatterplot"], "relationText": "From the results, the analyst can visually identify clusters and manually select them by using a lasso selection. Selected points are labeled as one cluster and color-coded with a categorical color: cluster, filter", "note": ""}, {"viewId": "vis-3326_01_1", "viewFile": "vis-3326_01_1.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "feature_contribution", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "nominal"}, "y": {"field": "feature_contribution", "type": "quantitative"}, "xoffset": {"field": "cluster", "type": "nominal"}, "color": {"field": "cluster", "type": "nominal"}}}]}, "marks": ["line", "bar"], "channels": ["x", "y", "color", "xoffset"], "dataTypes": ["temporal", "quantitative", "nominal"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3326_01", "figFile": "vis-3326_01.png", "figCaption": "", "figBox": {"x": 0.01148606025892309, "y": 0.5789044105438204, "width": 0.9869467044732734, "height": 0.20920078618048737}, "figVis": ["bar_chart", "line_chart"], "relationText": "The FC view shows feature contributions a for each of the DR results in the TDR view (the left and right plots in Fig. 2-c correspond to Fig. 2-a1 and a2, respectively): derived value (feature contribution)", "note": "line and bar are used for different data type"}, {"viewId": "vis-3326_01_2", "viewFile": "vis-3326_01_2.png", "specification": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "nominal"}, "y": {"field": "feature_contribution", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "feature_contribution", "type": "quantitative"}}}]}, "marks": ["bar", "line"], "channels": ["x", "y"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat"], "aggregates": [], "actionTargets": ["consume-discover:Attributes-values"], "figId": "vis-3326_01", "figFile": "vis-3326_01.png", "figCaption": "", "figBox": {"x": 0.004059074663514014, "y": 0.7896855514308974, "width": 0.9910552819237112, "height": 0.20507691267313505}, "figVis": ["bar_chart", "line_chart"], "relationText": "The last analysis step is to understand the meaning of features obtained after the first DR of the two-step DR (i.e., columns in Y)\uff1aderived value?(weight)", "note": ""}, {"viewId": "vis-3326_01_3", "viewFile": "vis-3326_01_3.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "bin": true, "type": "quantitative"}, "y": {"field": "relative_frequency", "type": "quantitative"}, "color": {"field": "cluster", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": ["bin"], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3326_01", "figFile": "vis-3326_01.png", "figCaption": "", "figBox": {"x": 0.3915386258958154, "y": 0.4360824363509212, "width": 0.13013302953606173, "height": 0.20487912882390974}, "figVis": ["bar_chart"], "relationText": "To compare value distributions of the selected feature, as shown in Fig. 2-d, the HC view shows relative frequency histograms of selected clusters (e.g., blue and orange) and unselected points (gray) with the corresponding colors: compare, distribution", "note": ""}, {"viewId": "vis-3327_00_0", "viewFile": "vis-3327_00_0.png", "specification": {"facet": {"column": {"field": "feature", "type": "nominal"}, "row": {"field": "node", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3327_00", "figFile": "vis-3327_00.png", "figCaption": "", "figBox": {"x": 0.010208471592436607, "y": 0.12671073554271423, "width": 0.31501933424870243, "height": 0.4678193233941221}, "figVis": ["bar_chart"], "relationText": "The system then visualizes the output in the sortable sensitivity index list (D1), which shows each node\u2019s current ranking and sensitivity indices with respectto the node\u2019s class label(s)", "note": ""}, {"viewId": "vis-3327_00_1", "viewFile": "vis-3327_00_1.png", "specification": {"mark": "radar", "encoding": {"theta": {"field": "metric_type", "type": "nominal"}, "radius": {"field": "metric_value", "type": "quantitative"}}}, "marks": ["radar"], "channels": ["theta", "radius"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3327_00", "figFile": "vis-3327_00.png", "figCaption": "", "figBox": {"x": 0.3313524927517698, "y": 0.10005211461013985, "width": 0.27617542434344305, "height": 0.23257175954463624}, "figVis": ["polar_plot"], "relationText": "The radar chart isused to provide an overview of the sensitivity metrics with respect to the effects of a perturbation: derived value", "note": ""}, {"viewId": "vis-3327_00_2", "viewFile": "vis-3327_00_2.png", "specification": {"mark": "bar", "encoding": {"x": {"field": "original_ranking", "type": "ordinal"}, "y": {"field": "ranking_change", "type": "quantitative"}, "color": {"field": "node_label", "type": "nominal"}}}, "marks": ["bar"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3327_00", "figFile": "vis-3327_00.png", "figCaption": "", "figBox": {"x": 0.6063463418660301, "y": 0.10906006935910556, "width": 0.3770716731990002, "height": 0.21035344996348174}, "figVis": ["bar_chart"], "relationText": " A bar chart (Figure 3) is used to show the ranking change distribution.", "note": "(x, y, color)"}, {"viewId": "vis-3327_00_3", "viewFile": "vis-3327_00_3.png", "specification": {"facet": {"column": {"field": "method", "type": "nominal"}}, "spec": {"mark": "arc", "remark": "donut chart", "encoding": {"theta": {"field": "node", "aggregate": "count", "type": "quantitative"}, "color": {"field": "category", "type": "nominal"}}}}, "marks": ["arc"], "channels": ["theta", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3327_00", "figFile": "vis-3327_00.png", "figCaption": "", "figBox": {"x": 0.7693429046225715, "y": 0.3356661257574238, "width": 0.21618081719017235, "height": 0.23901654670973146}, "figVis": ["donut_chart"], "relationText": "Inthe Top-k Proportional Distribution View, we use two donut charts to represent the proportions of nodes of different categories belonging to ranking 1 to ranking k before and after the perturbation (Figure 1 (5)),and k is interactively specified: distribution", "note": ""}, {"viewId": "vis-3327_00_4", "viewFile": "vis-3327_00_4.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "node", "type": "node", "encoding": {"color": {"field": "label", "type": "nominal"}, "border": {"field": "removed_or_not", "type": "nominal"}, "size": {"field": "ranking_change", "type": "quantitative"}}}, "link": {"field": "relation", "type": "relation", "encoding": {"strokeDash": {"field": "infinity_hop_or_not", "type": "nominal"}, "color": {"field": "ranking_increase_or_decrease", "type": "nominal"}, "width": {"field": "ranking_change", "type": "quantitative"}}}}}, "marks": ["graph"], "channels": ["node", "link", "color", "border", "size", "strokeDash", "width"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["search-explore:Graphs-topology/structures"], "figId": "vis-3327_00", "figFile": "vis-3327_00.png", "figCaption": "", "figBox": {"x": 0.3354116946906756, "y": 0.33704615378420677, "width": 0.43077800723665066, "height": 0.6438892987287823}, "figVis": ["graph"], "relationText": "While summarizing the changes in rank isimportant, our domain experts also required the ability to explore theimpacts on the graph topology caused by perturbations: graph", "note": "(color, graph) How to label the position of node?"}, {"viewId": "vis-3330_03_0", "viewFile": "vis-3330_03_0.png", "specification": {"nested": {"parent": {"mark": "graph", "encoding": {"node": {"condition_1": {"test": "node_left", "value": {"field": "player", "type": "node"}}, "condition_2": {"test": "node_right", "value": {"field": "passing_pattern", "type": "node"}}}, "link": {"field": "player_involved_in_passing_pattern", "type": "relation"}}}, "child": {"child_type": "configured", "canvas": "node", "configuration": {"condition_1": {"test": "node_left", "value": {"mark": "bar", "encoding": {"x": {"field": "total_pass", "type": "quantitative"}, "y": {"field": "player", "type": "nominal"}, "color": {"field": "pass_in_passing_pattern", "type": "nominal", "remark": "When hovering on a pattern, a dark bar (Fig. 4 (B)) is presented to show the number of a player\u2019s passes in that passing pattern"}}}}, "condition_2": {"test": "node_right", "value": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "pass_in_passing_pattern", "aggregate": "count", "type": "quantitative"}}}, {"mark": "surface", "encoding": {"x": {"field": "soccer_pitch_dim_1", "type": "quantitative"}, "y": {"field": "soccer_pitch_dim_1", "type": "quantitative"}, "surface": {"field": "start_or_end_position", "aggregate": "count", "type": "quantitative"}}}]}}}}}}, "marks": ["graph", "bar", "surface"], "channels": ["node", "link", "x", "y", "color", "surface"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["nested", "concat"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3330_03", "figFile": "vis-3330_03.png", "figCaption": "", "figBox": {"x": 0.031644115562557903, "y": 0.09123594389906585, "width": 0.10602789605754899, "height": 0.3776769034912099}, "figVis": ["heatmap", "bar_chart"], "relationText": "In this diagram (Fig. 4 (B)), we intend to visualize the characteristics of passing patterns (M1 and M2). The characteristics are twof old: one refers to the players involved, and the other refers to the spatial context: {passing pattern} derived value", "note": "(player, link, heatmap)"}, {"viewId": "vis-3330_03_1", "viewFile": "vis-3330_03_1.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "phase", "type": "ordinal"}, "y": {"field": "defense", "type": "quantitative", "remark": "We use the covered region of the opponents to represent the defense. A small covered region means that a team is using a good defense formation."}}}, {"facet": {"row": {"field": "passing_pattern", "type": "nominal"}}, "spec": {"mark": "point", "encoding": {"x": {"field": "phase", "type": "ordinal"}}}}, {"mark": "point", "encoding": {"x": {"field": "phase", "type": "ordinal"}, "icon": {"field": "event_type", "type": "nominal", "remark": "We use the metaphor to design the game event glyphs"}}}]}, "marks": ["bar", "point"], "channels": ["x", "y", "icon"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": ["concat", "facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-present:Attributes-correlation"], "figId": "vis-3330_03", "figFile": "vis-3330_03.png", "figCaption": "", "figBox": {"x": 0.13637219872491052, "y": 0.056218053168380404, "width": 0.8482497671288817, "height": 0.43604851832976377}, "figVis": ["bar_chart", "others"], "relationText": "We employ a timeline-based visualization to show the temporal distribution of passing patterns (P1-P3): correlate, distribution", "note": "(time, [phase, defense, event glyph])"}, {"viewId": "vis-3330_03_2", "viewFile": "vis-3330_03_2.png", "specification": {"layer": [{"mark": "geoshape"}, {"mark": "graph", "encoding": {"node": {"field": "player", "type": "node", "encoding": {"x": {"field": "player_position_x", "type": "quantitative"}, "y": {"field": "player_position_y", "type": "quantitative"}}}, "link": {"field": "soccer_movement", "type": "relation", "encoding": {"link_style": {"field": "soccer_movement_type", "type": "nominal"}}}}}]}, "marks": ["geoshape", "graph"], "channels": ["node", "link", "x", "y", "link_style"], "dataTypes": ["node", "relation", "quantitative", "nominal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["consume-present:Graphs-links/paths"], "figId": "vis-3330_03", "figFile": "vis-3330_03.png", "figCaption": "", "figBox": {"x": 0.10220927373617766, "y": 0.5277177309068756, "width": 0.37791049591481596, "height": 0.4558565483116943}, "figVis": ["map", "graph"], "relationText": "As shown in Fig. 4 (D1), in the static mode, we use a node-link diagram to visualize the whole process of players\u2019 passes in a soccer phase: raw data(whole process)", "note": "(x, y, player, line type, graph)"}, {"viewId": "vis-3330_03_3", "viewFile": "vis-3330_03_3.png", "specification": {"facet": {"row": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "line", "encoding": {"x": {"field": "ordinal", "type": "ordinal"}, "y": {"field": "feature_value", "type": "quantitative"}}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["ordinal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3330_03", "figFile": "vis-3330_03.png", "figCaption": "", "figBox": {"x": 0.4785945081965291, "y": 0.5123928537337527, "width": 0.3712028323936083, "height": 0.4710975023527911}, "figVis": ["line_chart"], "relationText": "Therefore, we provide a statistical table and a set of coordinated interactionsto show the necessary context. In the statistical table (Fig. 4 (D3)), we provide the following indicators to facilitate the analysis: derived value", "note": ""}, {"viewId": "vis-3330_03_4", "viewFile": "vis-3330_03_4.png", "specification": {"facet": {"row": {"field": "feature", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "feature_value", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-values"], "figId": "vis-3330_03", "figFile": "vis-3330_03.png", "figCaption": "", "figBox": {"x": 0.8516623877319235, "y": 0.5123928537337527, "width": 0.13978053844234534, "height": 0.4710975023527896}, "figVis": ["bar_chart"], "relationText": "Apart from the statistics of passing, we further provide statistics(e.g., maximum speed, dash distances, etc) of individual players (Fig. 4(D4)): derived value", "note": ""}, {"viewId": "vis-3332_00_0", "viewFile": "vis-3332_00_0.png", "specification": {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "feature_value", "type": "quantitative"}}}, "marks": ["line"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "consume-present:Attributes-outliers"], "figId": "vis-3332_00", "figFile": "vis-3332_00.png", "figCaption": "", "figBox": {"x": 0.1332942391549765, "y": 0.010319742900920498, "width": 0.5334840102804448, "height": 0.47476669124581133}, "figVis": ["line_chart"], "relationText": "The dimensionality reductionift degree line chart is used to alert the analyst of possible occurrences of concept dimensionality reductionift by displaying the calculated dimensionality reductionift degree over time (R1). {alert} anomaly, correlate", "note": ""}, {"viewId": "vis-3332_00_1", "viewFile": "vis-3332_00_1.png", "specification": {"layer": [{"mark": "point", "encoding": {"x": {"field": "DR_1", "type": "quantitative"}, "y": {"field": "DR_2", "type": "quantitative"}, "color": {"field": "Gaussian_component", "type": "nominal"}}}, {"mark": "surface", "encoding": {"x": {"field": "DR_1", "type": "quantitative"}, "y": {"field": "DR_2", "type": "quantitative"}, "surface": {"field": "Gaussian_component", "type": "nominal"}}}]}, "marks": ["point", "surface"], "channels": ["x", "y", "color", "surface"], "dataTypes": ["quantitative", "nominal"], "compositions": ["layer"], "aggregates": [], "actionTargets": ["search-explore:Attributes-correlation", "search-explore:Attributes-distribution"], "figId": "vis-3332_00", "figFile": "vis-3332_00.png", "figCaption": "", "figBox": {"x": 0.13528456478383294, "y": 0.49125662819321936, "width": 0.533488625030898, "height": 0.4495640890158703}, "figVis": ["scatterplot", "heatmap"], "relationText": "As described in requirement R2, it is critical to know where and why dimensionality reductionift occurs by exploring the change of data distribution over time: distribution, correlate", "note": ""}, {"viewId": "vis-3332_00_2", "viewFile": "vis-3332_00_2.png", "specification": {"facet": {"row": {"field": "base_learner", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "data_point", "aggregate": "count", "type": "quantitative"}, "color": {"field": "Gaussian_component", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["x", "color"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3332_00", "figFile": "vis-3332_00.png", "figCaption": "", "figBox": {"x": 0.6682914680447212, "y": 0.0016704324368476324, "width": 0.32430701026455216, "height": 0.26998359967696534}, "figVis": ["bar_chart"], "relationText": "For each base learner, it shows the size\nof the training set and the proportion of the data points in the training set that belong to each Gaussian component: distribution\n\nAnalysts can select a data subset to create a new base\nlearner and choose which base learners to use in the ensemble model: filter", "note": ""}, {"viewId": "vis-3332_00_3", "viewFile": "vis-3332_00_3.png", "specification": {"facet": {"row": {"field": "data_subset", "type": "nominal"}}, "spec": {"concat": {"layout": "horizontal"}, "spec": [{"mark": "bar", "encoding": {"x": {"field": "data_point", "aggregate": "count", "type": "quantitative"}, "color": {"field": "Gaussian_component", "type": "nominal"}}}, {"mark": "bar", "encoding": {"x": {"field": "importance", "type": "quantitative"}, "texture": {"field": "base_learner", "type": "nominal"}}}]}}, "marks": ["bar"], "channels": ["x", "color", "texture"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet", "concat"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3332_00", "figFile": "vis-3332_00.png", "figCaption": "", "figBox": {"x": 0.6682987006189999, "y": 0.2767719103445095, "width": 0.3256209671187163, "height": 0.30142322421090534}, "figVis": ["bar_chart"], "relationText": "Similar to the base learner view, the colored bars show the percentage of Gaussian component labels in every batch. \nTo see the effect of each base learner on the samples, we calculate a model distribution and visualize it using the combination of each base learner\u2019s glyph pattern: distribution\n\nFrom the model distribution, the analyst can determine which base learner is important: compare", "note": ""}, {"viewId": "vis-3332_00_4", "viewFile": "vis-3332_00_4.png", "specification": {"facet": {"row": {"field": "method", "type": "nominal"}, "column": {"field": "class", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "confidence_score", "bin": true, "type": "quantitative"}, "color": {"field": "confusion", "type": "nominal"}, "x": {"field": "data_point", "aggregate": "count", "type": "quantitative"}, "left_or_right": {"field": "confusion", "type": "nominal"}}}}, "marks": ["bar"], "channels": ["y", "color", "x", "left_or_right"], "dataTypes": ["quantitative", "nominal"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["query-compare:Attributes-distribution", "search-explore:Attributes-values"], "figId": "vis-3332_00", "figFile": "vis-3332_00.png", "figCaption": "", "figBox": {"x": 0.6722551753607406, "y": 0.5698900537027187, "width": 0.3183722286365955, "height": 0.37085675534274665}, "figVis": ["bar_chart"], "relationText": "The performance view visualizes the model performance before and after adaptation to verify the effectiveness of dimensionality reductionift adaptation: compare", "note": "(pre/current, x, left/right, y, true positive...)"}, {"viewId": "vis-3334_00_0", "viewFile": "vis-3334_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "sankey", "encoding": {"node": {"field": "hyperparameters", "type": "node", "column": {"field": "individual/selected hyperparameter", "type": "nominal"}, "width": {"field": "relative importance between hyperparameters", "type": "quantitative"}}, "link": {"field": "interaction/target relation", "type": "relation"}, "remark": "The\u00a0visualization is composed of two layers of a bar plot for the\u00a0importance of individual hyperparameters and the selected hyperparameter,\u00a0respectively"}}, {"nested": {"parent": {"mark": "line", "encoding": {"x": {"field": "metrics", "type": "nominal"}, "y": {"field": "metric value 1", "type": "quantitative"}}}, "child": {"child_type": "configured", "canvas": "axis", "configuration": {"mark": "bar", "encoding": {"x": {"field": "parameter value 2", "type": "quantitative", "bin": "true"}, "y": {"field": "estimated performance values", "type": "quantitative"}, "color": {"field": "estimated performance values", "type": "quantitative"}}, "remark": "the estimated performance values in the search space regionare visualized in the parallel coordinates as a bar chart."}}}}]}, "marks": ["sankey", "line", "bar"], "channels": ["node", "link", "remark", "x", "y", "color"], "dataTypes": ["node", "relation", "nominal", "quantitative"], "compositions": ["concat", "nested"], "aggregates": ["bin"], "actionTargets": ["search-explore:Attributes-correlation"], "figId": "vis-3334_00", "figFile": "vis-3334_00.png", "figCaption": "", "figBox": {"x": 0.25419721809814294, "y": 0.0625714676173356, "width": 0.3922086787664448, "height": 0.45480820481290263}, "figVis": ["parallel_coordinate"], "relationText": "The Search space overview (Fig. 6(A)) utilizes a parallel coordinates plot [16] to present the overall search spaces and exploration results for the qualitative analysis support.\n\nBased on this view, different combinations of hyperparameters are ef- fectively visualized as high-dimensional vectors, together with a par- ticular objective metric (e.g., a test accuracy) chosen by users. \n\nAlso, its effective interaction capability can achieve our design goals to aid users in analyzing the effective hyperparameters (G1), filtering the de- sired models (G3), and refining the search space (G1) via brushing interactions. ", "note": "(N, N, Q): parallel coordinate\nQ#: histogram on each axis\nQ#: the top bar chart (aggregating)"}, {"viewId": "vis-3334_00_1", "viewFile": "vis-3334_00_1.png", "specification": {"facet": {"column": {"field": "test accuracy top 5/all", "type": "nominal"}}, "spec": {"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "accuracy", "type": "quantitative"}, "color": {"field": "aggregate type", "type": "nominal"}}}}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3334_00", "figFile": "vis-3334_00.png", "figCaption": "", "figBox": {"x": 0.2541972180981426, "y": 0.5204027761666443, "width": 0.3922086787664444, "height": 0.45576877497052676}, "figVis": ["line_chart"], "relationText": "By filtering or selecting the models from each inter-linked components (B, C, and E1) in Fig 1, the Model analysis view visualizes the line plot of each model over iterations with several metrics users selected, as shown in Fig. 1(D).", "note": ""}, {"viewId": "vis-3334_00_2", "viewFile": "vis-3334_00_2.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"layer": [{"mark": "area", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "step", "type": "ordinal"}, "color": {"field": "training metric value", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "step", "type": "ordinal"}}}]}, {"facet": {"column": {"field": "hyperparameter search space", "type": "nominal"}}, "spec": {"layer": [{"mark": "circle", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "hyperparameter value", "type": "quantitative"}, "size": {"field": "ordinal", "type": "quantitative"}}}, {"mark": "line", "encoding": {"x": {"field": "step", "type": "ordinal"}, "y": {"field": "hyperparameter value", "type": "quantitative"}}}]}}]}, "marks": ["area", "point", "circle", "line"], "channels": ["x", "y", "color", "size"], "dataTypes": ["ordinal", "quantitative"], "compositions": ["concat", "layer", "facet"], "aggregates": [], "actionTargets": ["search-explore:Attributes-values", "consume-present:Attributes-correlation"], "figId": "vis-3334_00", "figFile": "vis-3334_00.png", "figCaption": "", "figBox": {"x": 0.6456118347727597, "y": 0.161603376020234, "width": 0.3485723720736717, "height": 0.7979482820594306}, "figVis": ["scatterplot", "area_chart", "line_chart"], "relationText": "The user interface is composed of two coordinated views (Fig. 4) for (a) monitoring of performance improvement and (b) the exploration history of each hyperparameter search space, respectively.", "note": "O => x-axis\n(Q, N) => y-axis, record\n(N, Q, Q, Q) => bottom matrix. n: hyperparameter_type, q: value (each row), q, q => size and color of each point"}, {"viewId": "vis-3338_00_0", "viewFile": "vis-3338_00_0.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "event type", "type": "node", "color": {"condition_1": {"test": "node is effect", "value": {"field": "under inspectation or not", "type": "nominal"}}, "condition_2": {"test": "node is causes", "value": {"field": "causal strength", "type": "quantitative"}}}}, "link": {"field": "causal link", "type": "relation"}}}, "marks": ["graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-graphs", "consume-discover:Graphs-links/paths"], "figId": "vis-3338_00", "figFile": "vis-3338_00.png", "figCaption": "", "figBox": {"x": 0.43147780760088256, "y": 0.5058991255086346, "width": 0.3067045851204654, "height": 0.4916649300284603}, "figVis": ["graph"], "relationText": "The causal model view (Fig. 1(3)) suggests potential causal relationships using a node-link causal graph, allowing users to investigate the causalities and make updates on the causal model after verifying the causal relations (R2, R4, R5)", "note": ""}, {"viewId": "vis-3338_00_1", "viewFile": "vis-3338_00_1.png", "specification": {"mark": "sankey", "encoding": {"node": {"field": "cause/effect", "type": "node", "color": {"field": "cause/effect", "type": "nominal"}, "height": {"field": "number of sequence 1", "type": "quantitative"}}, "link": {"field": "grouping relation", "type": "relation", "color": {"field": "cause/effect", "type": "nominal"}, "height": {"field": "number of sequence 2", "type": "quantitative"}}}}, "marks": ["sankey"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-topology/structures"], "figId": "vis-3338_00", "figFile": "vis-3338_00.png", "figCaption": "", "figBox": {"x": 0.32459215395926394, "y": 0.039510475946626857, "width": 0.4168127432027067, "height": 0.41181173321326675}, "figVis": ["others"], "relationText": "The causal sequence view (Fig. 1(4)) facilitates causal verification by showing the causal patterns in raw event sequences using a flow-based visualization.: {raw data} retrieve value", "note": "(N, N, O): raw sequence"}, {"viewId": "vis-3338_00_2", "viewFile": "vis-3338_00_2.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "effects", "type": "nominal"}, "y": {"field": "causes", "type": "nominal"}, "outer_region_color": {"field": "causal strength of first group", "type": "quantitative"}, "inner_region_color": {"field": "causal strength of second group", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["x", "y", "outer_region_color", "inner_region_color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-similarity"], "figId": "vis-3338_00", "figFile": "vis-3338_00.png", "figCaption": "", "figBox": {"x": 0.7524949182708912, "y": 0.6125669895033519, "width": 0.1553710778437388, "height": 0.354915870477404}, "figVis": ["map", "matrix"], "relationText": "causal comparison view (Fig. 1(6)), showing the differences between causal graphs inferred from two sub- groups of sequences through a matrix-based visualization (R7).", "note": "(n,n,q,q) => x/y/inner cell/outer cell"}, {"viewId": "vis-3341_00_0", "viewFile": "vis-3341_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"facet": {"row": {"field": "commits or LOCs", "type": "nominal"}}, "spec": {"mark": "area", "encoding": {"x": {"field": "date", "type": "temporal"}, "y": {"field": "commit", "aggregate": "count", "type": "quantitative"}}}}, {"mark": "tick", "encoding": {"x": {"field": "commit index", "type": "ordinal"}}}]}, "marks": ["area", "tick"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": ["count"], "actionTargets": ["search-locate:Attributes-range"], "figId": "vis-3341_00", "figFile": "vis-3341_00.png", "figCaption": "", "figBox": {"x": 0.004943561152973466, "y": 0.029544397529685646, "width": 0.6325125901461832, "height": 0.13725815140869008}, "figVis": ["area_chart", "stripe_graph"], "relationText": "Therefore, we provided a Global Temporal Filter with ways to filter for a certain time period: Brushing (Fig. 1a) and a Select Box", "note": "(N, (T, Q)): area chart on the top\n(Q#): stripe graph at the bottom"}, {"viewId": "vis-3341_00_1", "viewFile": "vis-3341_00_1.png", "specification": {"mark": "others", "encoding": {"column": {"field": "time slots"}, "row": {"field": "stems"}, "cell": {"field": "commit"}, "block": {"field": "adjacent commits"}, "vertical_centered_box_in_blocks": {"field": "number of commits"}, "outline_enclosing_blocks": {"field": "block_cluster_grouping"}}}, "marks": ["others"], "channels": ["column", "row", "cell", "block", "vertical_centered_box_in_blocks", "outline_enclosing_blocks"], "dataTypes": [], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-clusters/groups"], "figId": "vis-3341_00", "figFile": "vis-3341_00.png", "figCaption": "", "figBox": {"x": 0.014038619686444275, "y": 0.17767471337008314, "width": 0.6188924448050914, "height": 0.31206830436998256}, "figVis": ["sunburst_icicle"], "relationText": "The stem graph visualizes a cluster information of each commit at a single glance", "note": "((O, N), G) => original data of git commit config\nperform complex data transformation over the git commit configs"}, {"viewId": "vis-3341_00_2", "viewFile": "vis-3341_00_2.png", "specification": {"facet": {"row": {"field": "cluster", "type": "nominal"}, "width": {"field": "proportion of commit numbers", "type": "quantitative"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "criteria", "type": "nominal"}, "x": {"field": "proportion of the number of relevant commits", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["y", "x"], "dataTypes": ["nominal", "quantitative"], "compositions": ["facet"], "aggregates": [], "actionTargets": ["query-compare:Attributes-clusters", "query-summarize:Attributes-clusters"], "figId": "vis-3341_00", "figFile": "vis-3341_00.png", "figCaption": "", "figBox": {"x": 0.01575520380521783, "y": 0.5015534847687905, "width": 0.6211717412248601, "height": 0.1888884727552967}, "figVis": ["bar_chart"], "relationText": "The Grouped Summary View provides a rough summary of the selected clusters. This view enables a visual comparison of the relative size among selected clusters, which was frequently cited as a needed task in the requirement analysis (R4).", "note": "(N, Q) => each column for a cluster, its width for size\n(N, N, Q): within each column, there are colored bars with length"}, {"viewId": "vis-3341_00_3", "viewFile": "vis-3341_00_3.png", "specification": {"mark": "icicle", "layout": "horizontal", "encoding": {"node": {"field": "file", "type": "node"}, "link": {"field": "file relation", "type": "relation"}}}, "marks": ["icicle"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-topology/structures"], "figId": "vis-3341_00", "figFile": "vis-3341_00.png", "figCaption": "", "figBox": {"x": 0.017657438226171152, "y": 0.6986106568541605, "width": 0.191217408947315, "height": 0.29356632483198103}, "figVis": ["sunburst_icicle"], "relationText": "A file icicle tree allows users to interactively observe the modified file hierarchy.", "note": ""}, {"viewId": "vis-3341_00_4", "viewFile": "vis-3341_00_4.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"facet": {"row": {"field": "author/commit type", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "compare target", "type": "nominal"}, "x": {"field": "commit", "aggregate": "count", "type": "quantitative"}}}}, {"facet": {"column": {"field": "compare target", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "files", "type": "nominal"}, "x": {"field": "proportion of the commits", "type": "quantitative"}}}}, {"facet": {"column": {"field": "compare target", "type": "nominal"}}, "spec": {"mark": "word_cloud", "encoding": {"word": {"field": "word", "type": "nominal"}, "size": {"field": "TF-IDF value", "type": "quantitative"}}}}]}, "marks": ["bar", "word_cloud"], "channels": ["y", "x", "word", "size"], "dataTypes": ["nominal", "quantitative"], "compositions": ["concat", "facet"], "aggregates": ["count"], "actionTargets": ["query-compare:Attributes-distribution"], "figId": "vis-3341_00", "figFile": "vis-3341_00.png", "figCaption": "", "figBox": {"x": 0.6471077779715405, "y": 0.006252334146990856, "width": 0.34553397874424646, "height": 0.9802243454976057}, "figVis": ["bar_chart", "word_cloud"], "relationText": "Diff View shows a two-way comparison between selections for authors, commit types, files, and keywords (Fig. 1g). Since comparison becomes difficult as the number of objects increases [34] and Grouped Summary View already provides a rough overview of a multi-way comparison, a two-way comparison fits the details-ondemand strategy (R3, R4).", "note": "[bar charts, word cloud]"}, {"viewId": "vis-3342_00_0", "viewFile": "vis-3342_00_0.png", "specification": {"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "class", "type": "nominal"}, "shape": {"field": "source/target", "type": "nominal"}, "border": {"field": "mispredict or not", "type": "nominal"}}}, "marks": ["point"], "channels": ["x", "y", "color", "shape", "border"], "dataTypes": ["quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution", "consume-discover:Attributes-correlation"], "figId": "vis-3342_00", "figFile": "vis-3342_00.png", "figCaption": "", "figBox": {"x": 0.03615470192365314, "y": 0.40964720240754804, "width": 0.20479035609890103, "height": 0.33827966696764433}, "figVis": ["scatterplot"], "relationText": "The instance view shows the data distributions of selected classes from the two domains and provides a detailed analysis of the relationships between instances with different attributes (T2).: distribution, correlate", "note": "In the scatterplot, the colors of the glyphs indicate their class labels. To visualize the predictions made by the target model, the glyph borders for the mispredicted instances are set to dark gray. Similar to the encoding in the accuracy chart, we use crosses and circles for the instances from the source and the target domain, respectively. \n\n(N,N,N) -> color, shape, border"}, {"viewId": "vis-3342_00_1", "viewFile": "vis-3342_00_1.png", "specification": {"layer": [{"concat": {"layout": "crossing\u00a0 "}, "spec": [{"mark": "rect", "position": 1, "encoding": {"x": {"field": "important neurons 1", "bin": "true", "type": "nominal"}, "y": {"field": "important neurons 2", "bin": "true", "type": "nominal"}, "color": {"field": "similarity values", "type": "quantitative"}, "inner_red_dot": {"field": "existance of the corresponding important weight", "type": "nominal"}}}, {"position": 4, "concat": {"layout": "horizontal"}, "spec": [{"facet": {"column": {"field": "neurons", "type": "nominal"}}, "spec": {"mark": "arc", "encoding": {"field": "proportionsof weights", "type": "quantitative"}}}, {"mark": "boxplot", "encoding": {"x": {"field": "important neurons 1", "bin": "true", "type": "nominal"}, "width": {"field": "weights", "aggregate": "sum", "type": "quantitative"}}}]}, {"position": 3, "concat": {"layout": "horizontal"}, "spec": [{"mark": "boxplot", "encoding": {"y": {"field": "important neurons 2", "bin": "true", "type": "nominal"}, "height": {"field": "weights", "aggregate": "sum", "type": "quantitative"}}}, {"facet": {"column": {"field": "neurons", "type": "nominal"}}, "spec": {"mark": "arc", "encoding": {"field": "proportionsof weights", "type": "quantitative"}}}]}]}, {"mark": "bar", "encoding": {"x": {"field": "weight values", "type": "quantitative", "bin": "true"}, "y": {"type": "quantitative", "aggregate": "count"}}}]}, "marks": ["rect", "arc", "boxplot", "bar"], "channels": ["x", "y", "color", "inner_red_dot", "field", "type", "width", "height"], "dataTypes": ["nominal", "quantitative"], "compositions": ["layer", "concat", "facet"], "aggregates": ["bin", "sum", "count"], "actionTargets": ["query-compare:Attributes-similarity"], "figId": "vis-3342_00", "figFile": "vis-3342_00.png", "figCaption": "", "figBox": {"x": 0.41115025745282596, "y": 0.2597629829728148, "width": 0.24199734518225716, "height": 0.24203958333048556}, "figVis": ["heatmap", "box_plot", "bar_chart"], "relationText": "The Feature View (Figure 1 (D)) visualizes the domain discrim- inability of feature extractors in the target model (T3). ", "note": "left top: (N, N, Q, N) => column, row, cell color, is_dot\nleft bottom and top right: (Q#, Q#, N) => box plot, pie, column or row\n\n(left top, left bottom share the same x; while left top, left right share the same y)\n"}, {"viewId": "vis-3342_00_2", "viewFile": "vis-3342_00_2.png", "specification": {"facet": {"row": {"field": "layer index", "type": "ordinal"}}, "spec": {"x": {"field": "layer conductance values", "type": "quantitative", "bin": "true"}, "y": {"aggregate": "sum", "type": "quantitative"}, "color": {"field": "target/source", "type": "nominal"}}}, "marks": [], "channels": [], "dataTypes": [], "compositions": ["facet"], "aggregates": ["bin", "sum"], "actionTargets": ["query-compare:Attributes-distribution", "consume-present:Attributes-order"], "figId": "vis-3342_00", "figFile": "vis-3342_00.png", "figCaption": "", "figBox": {"x": 0.741868540505916, "y": 0.5663371633778572, "width": 0.14902597200283496, "height": 0.31413110047034465}, "figVis": ["bar_chart"], "relationText": "To differentiate the instances from two domains, the distribution of source instances are placed above the horizontal axis, while the target distribution is at the bottom. The colors of the bars map to the corresponding domains as well. : distribution\n\nAnalysts can select whether to sort the neurons based on their domain discriminability values in ascending or descending order.: sort", "note": "A feature discriminability plot is proposed to visualize how much domainrelevant information is carried by the filters, indicating the extent of\nknowledge sharing in the filter level.\n\n(q#, n) => distribution, color"}, {"viewId": "vis-3344_00_0", "viewFile": "vis-3344_00_0.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "icicle", "encoding": {"node": {"field": "shifts", "type": "node", "color": {"field": "weighted distance", "type": "quantitative"}}, "link": {"field": "hierarchy", "type": "relation"}}}, {"nested": {"parent": {"mark": "rect", "encoding": {"x": {"field": "metrics", "type": "nominal"}, "y": {"field": "shifts", "type": "nominal"}}}, "child": {"child_type": "configured", "canvas": "cell", "configuration": {"mark": "icon", "encoding": {"field": "metric value of shifts", "type": "quantitative"}}}}}]}, "marks": ["icicle", "rect", "icon"], "channels": ["node", "link", "x", "y", "field", "type"], "dataTypes": ["node", "relation", "nominal"], "compositions": ["concat", "nested"], "aggregates": [], "actionTargets": ["consume-present:Attributes-distribution"], "figId": "vis-3344_00", "figFile": "vis-3344_00.png", "figCaption": "", "figBox": {"x": 0.20446759246316643, "y": 0.005822104538196439, "width": 0.2883023346206095, "height": 0.9758388776522499}, "figVis": ["sunburst_icicle"], "relationText": "The split icicle plot was developed to visualize shifts in distribution for dimensions in large hierarchies, indicating potential selection bias ", "note": "(q, n, q): each row -> length (distribution shift), (n,n) -> table\n"}, {"viewId": "vis-3344_00_1", "viewFile": "vis-3344_00_1.png", "specification": {"mark": "vector", "encoding": {"x": {"field": "correlation", "type": "quantitative"}, "y": {"field": "distance", "type": "quantitative"}, "color": {"field": "distance", "type": "quantitative"}, "theta": {"field": "unweighted value and points towards the position of the weighted value", "type": "quantitative"}}}, "marks": ["vector"], "channels": ["x", "y", "color", "theta"], "dataTypes": ["quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation"], "figId": "vis-3344_00", "figFile": "vis-3344_00.png", "figCaption": "", "figBox": {"x": 0.49210560385866375, "y": 0.1585617089244556, "width": 0.28941584936802156, "height": 0.5228214146715388}, "figVis": ["vector_graph"], "relationText": "show the effect of reweighting on per- dimension distances and outcome correlations for the baseline and focus cohorts (R3) and enable the selection of reweighting dimensions", "note": "[n, g]: each node and link between nodes"}, {"viewId": "vis-3344_00_2", "viewFile": "vis-3344_00_2.png", "specification": {"mark": "tree", "encoding": {"node": {"field": "cohort", "type": "node"}, "link": {"field": "cohort hierarchy", "type": "relation"}}}, "marks": ["tree"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["search-locate:Graphs-nodes", "consume-present:Graphs-topology/structures"], "figId": "vis-3344_00", "figFile": "vis-3344_00.png", "figCaption": "", "figBox": {"x": 0.0016731992690231948, "y": 0.006876061611895905, "width": 0.20204976762954804, "height": 0.9521171517460089}, "figVis": ["tree"], "relationText": "As the event sequence analysis capabilities of Cadence are used to filter existing cohorts to create new cohorts, representations of each cohort and their provenance are shown in the cohort provenance tree (Figure 1-a", "note": "each node is a glyph (Q,Q,N,Q): size, color, mark at left, bar at right"}, {"viewId": "vis-3345_00_0", "viewFile": "vis-3345_00_0.png", "specification": {"facet": {"row": {"field": "scale level", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"x": {"field": "date", "type": "temporal"}, "y": {"aggregate": "count", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["x", "y"], "dataTypes": ["temporal", "quantitative"], "compositions": ["facet"], "aggregates": ["count"], "actionTargets": ["consume-discover:Attributes-outliers"], "figId": "vis-3345_00", "figFile": "vis-3345_00.png", "figCaption": "", "figBox": {"x": 0.0023762218845579178, "y": 0.012195569186390339, "width": 0.1734290013687708, "height": 0.412893161143528}, "figVis": ["bar_chart"], "relationText": "Detect Outbreak.\n\nEpidemic Curve View shows the number of infected persons per day in order to support Task 1 \u2013 outbreak detection", "note": ""}, {"viewId": "vis-3345_00_1", "viewFile": "vis-3345_00_1.png", "specification": {"mark": "graph", "encoding": {"node": {"field": "patient", "type": "node", "color": {"field": "infection type", "type": "nominal"}}, "link": {"field": "patient relation", "type": "relation", "color": {"field": "infection type", "type": "nominal"}}}}, "marks": ["graph"], "channels": ["node", "link"], "dataTypes": ["node", "relation"], "compositions": [], "aggregates": [], "actionTargets": ["query-identify:Graphs-nodes", "consume-present:Graphs-links/paths"], "figId": "vis-3345_00", "figFile": "vis-3345_00.png", "figCaption": "", "figBox": {"x": 0.001317029373959977, "y": 0.43332683493498025, "width": 0.1739526543947633, "height": 0.5465404301994932}, "figVis": ["graph"], "relationText": "T5 Identify potentially infected patients.\n\nContact Network View shows the contacts of selected patients for determining putative infected patients (Task 5).", "note": ""}, {"viewId": "vis-3345_00_2", "viewFile": "vis-3345_00_2.png", "specification": {"mark": "line", "layout": "storyline", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "location", "type": "nominal"}, "color": {"field": "infection type", "type": "nominal"}}, "remark": "The y-axis encodes patient location"}, "marks": ["line"], "channels": ["x", "y", "color"], "dataTypes": ["temporal", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Graphs-links/paths", "consume-present:Graphs-nodes", "search-locate:Graphs-nodes"], "figId": "vis-3345_00", "figFile": "vis-3345_00.png", "figCaption": "", "figBox": {"x": 0.18004376945412523, "y": 0.015900147053190806, "width": 0.5660232119806023, "height": 0.976238501614813}, "figVis": ["storyline"], "relationText": "T2 Outbreak Pathway.\nT3 Outbreak Location.\nLocate ward(s) with pathogen transmissions\nT4 Quantify outbreak duration\n\nTransmission Pathway View supports Tasks 2\u20134.", "note": "Each line represents a patient and the x-axis encodes time (Task 4).\nEach patient line starts with the earliest recorded admission to hospital\nand ends with the last recorded stay. \n\nstoryline without y-axis"}, {"viewId": "vis-3345_00_3", "viewFile": "vis-3345_00_3.png", "specification": {"facet": {"row": {"field": "patient id", "type": "nominal"}}, "spec": {"layer": [{"mark": "bar", "encoding": {"x": {"field": "location_start", "type": "temporal"}, "x2": {"field": "location_end", "type": "temporal"}, "color": {"field": "infection type", "type": "nominal"}}}, {"mark": "line", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "microbiological data 1", "type": "quantitative"}}}, {"mark": "point", "encoding": {"x": {"field": "time", "type": "temporal"}, "y": {"field": "microbiological data 2", "type": "nominal"}}}]}}, "marks": ["bar", "line", "point"], "channels": ["x", "x2", "color", "y"], "dataTypes": ["temporal", "nominal", "quantitative"], "compositions": ["facet", "layer"], "aggregates": [], "actionTargets": ["query-identify:Attributes-extremes", "consume-present:Attributes-values"], "figId": "vis-3345_00", "figFile": "vis-3345_00.png", "figCaption": "", "figBox": {"x": 0.7503010504382172, "y": 0.04172918306853899, "width": 0.24732720487453258, "height": 0.9470890576034638}, "figVis": ["area_chart"], "relationText": "Patient event details are shown in Patient Timeline View.\n\nPatient Timeline View of the outbreak patients sorted by time of first infection shows first infected patients already in 2011.", "note": "((x, bar height, color), row)"}, {"viewId": "vis-3349_00_0", "viewFile": "vis-3349_00_0.png", "specification": {"facet": {"column": {"field": "stacks", "type": "nominal"}}, "spec": {"concat": {"layout": "vertical"}, "spec": [{"mark": "bar", "layout": "circular", "encoding": {"x": {"field": "metrics", "type": "nominal"}, "y": {"field": "metric value", "type": "quantitative"}}}, {"mark": "unit", "encoding": {"unit": {"field": "model", "type": "node"}, "color": {"field": "model type", "type": "quantitative"}}}]}}, "marks": ["bar", "unit"], "channels": ["x", "y", "unit", "color"], "dataTypes": ["nominal", "quantitative", "node"], "compositions": ["facet", "concat"], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3349_00", "figFile": "vis-3349_00.png", "figCaption": "", "figBox": {"x": 0.2573020656852648, "y": -0.0015839435160115824, "width": 0.4900680420292132, "height": 0.31246096626869535}, "figVis": ["unit_visualization", "donut_chart"], "relationText": "we track the history of the previously stored stacking ensembles in Fig. 1(b) and compare their performances against the active stacking ensemble\u2014the one not yet stored in the history\u2014in Fig. 1(c). {raw data}", "note": "[donut, units category and number]"}, {"viewId": "vis-3349_00_1", "viewFile": "vis-3349_00_1.png", "specification": {"mark": "line", "encoding": {"x": {"field": "step of the execution", "type": "ordinal"}, "y": {"field": "performance", "type": "quantitative"}, "color": {"field": "active/stack", "type": "nominal"}, "annotation": {"field": "metric", "type": "nominal"}}}, "marks": ["line"], "channels": ["x", "y", "color", "annotation"], "dataTypes": ["ordinal", "quantitative", "nominal"], "compositions": [], "aggregates": [], "actionTargets": ["query-compare:Attributes-values"], "figId": "vis-3349_00", "figFile": "vis-3349_00.png", "figCaption": "", "figBox": {"x": 0.7575127637452362, "y": 0.0019197979858551525, "width": 0.2391203472607556, "height": 0.3018808612610123}, "figVis": ["line_chart"], "relationText": "For instance, the performance comparison view Fig. 1(c) only uses four metrics", "note": ""}, {"viewId": "vis-3349_00_2", "viewFile": "vis-3349_00_2.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "performance", "type": "quantitative"}}}, {"facet": {"column": {"field": "metric type", "type": "nominal"}}, "spec": {"mark": "boxplot", "encoding": {"color": {"field": "all point/selected point", "type": "nominal"}, "xoffset": {"field": "all point/selected point", "type": "nominal"}, "y": {"field": "performance", "type": "quantitative"}}}}]}, "marks": ["point", "boxplot"], "channels": ["x", "y", "color", "xoffset"], "dataTypes": ["quantitative", "nominal"], "compositions": ["concat", "facet"], "aggregates": [], "actionTargets": ["search-explore:Attributes-values", "query-summarize:Attributes-values"], "figId": "vis-3349_00", "figFile": "vis-3349_00.png", "figCaption": "", "figBox": {"x": 0.0056711267871682085, "y": 0.3666140656870024, "width": 0.488177256357405, "height": 0.6226761546740972}, "figVis": ["scatterplot"], "relationText": "For the visual exploration of the models shown in Fig. 6, we use MDS projections (t-SNE or UMAP are also available). \nThus, groups of points represent clusters of models that perform similarly according to all the metrics. A summary of the performance of each model according to all selected and user weighted metrics is color-encoded using the Viridis colormap [26].\n\nT1: Search the solution space for the most suitable algorithms, entire space of available algorithms (yellow contour) against the current selection of models per algorithm (black star plot).\nT5: Inspect the same view with alternative techniques and visualizations.\n\n(3) ML algorithm exploration, (4) data wrangling, (5) model exploration (\u2192 T1 and T5),", "note": ""}, {"viewId": "vis-3349_00_3", "viewFile": "vis-3349_00_3.png", "specification": {"concat": {"layout": "vertical"}, "spec": [{"mark": "point", "encoding": {"x": {"field": "dimensionality reduction_x", "type": "quantitative"}, "y": {"field": "dimensionality reduction_y", "type": "quantitative"}, "color": {"field": "healthy/disease", "type": "quantitative"}}}, {"mark": "bar", "encoding": {"x": {"field": "model performance", "type": "quantitative", "bin": "true"}, "y": {"aggregate": "count", "type": "quantitative"}, "color": {"field": "selected/all points", "type": "nominal"}}}]}, "marks": ["point", "bar"], "channels": ["x", "y", "color"], "dataTypes": ["quantitative"], "compositions": ["concat"], "aggregates": ["bin", "count"], "actionTargets": ["query-summarize:Attributes-correlation"], "figId": "vis-3349_00", "figFile": "vis-3349_00.png", "figCaption": "", "figBox": {"x": 0.5045299383964048, "y": 0.36661406568700167, "width": 0.48878751496914113, "height": 0.6226761546740965}, "figVis": ["scatterplot", "bar_chart"], "relationText": "The goal of the predictions\u2019 space visualization (Fig. 1(f)) is to show an overview of the performance of all models of the current stack for different instances.\n\n(3) ML algorithm exploration, (4) data wrangling, (5) model exploration (\u2192 T1 and T5),", "note": ""}, {"viewId": "vis-3352_00_0", "viewFile": "vis-3352_00_0.png", "specification": {"mark": "rect", "encoding": {"x": {"field": "topic", "type": "nominal"}, "y": {"field": "people", "type": "nominal"}, "color": {"field": "connection strength", "type": "quantitative"}}}, "marks": ["rect"], "channels": ["x", "y", "color"], "dataTypes": ["nominal", "quantitative"], "compositions": [], "aggregates": [], "actionTargets": ["consume-present:Attributes-correlation", "consume-discover:Attributes-outliers"], "figId": "vis-3352_00", "figFile": "vis-3352_00.png", "figCaption": "", "figBox": {"x": 0.004100021958230354, "y": 0.1026914204860561, "width": 0.9912152289359718, "height": 0.8824404965208086}, "figVis": ["heatmap", "matrix", "bar_chart", "glyph_based"], "relationText": "1.Matrix Reordering and Sorting To support the tasks relevant for our dimensionality reductioniving application (see Section 2.3), a matrix reordering is desirable such that related users and topics appear close to each other.\n\n2.Interaction and Filter Concepts Standard methods available in an interactive visualization are included.\n\nFinally, (5) a design study on combining timeline and graph visualization by Saraiya et al. [35] shows that our approach\u2014simultaneously overlaying the timeline\u2014is best suited for detecting outliers.", "note": ""}, {"viewId": "vis-3353_00_0", "viewFile": "vis-3353_00_0.png", "specification": {"facet": {"column": {"field": "dataest", "type": "nominal"}}, "spec": {"mark": "bar", "encoding": {"y": {"field": "input", "type": "quantitative", "bin": "true"}, "x": {"type": "quantitative", "aggregate": "count"}, "color": {"field": "target value", "type": "quantitative"}}}}, "marks": ["bar"], "channels": ["y", "x", "color"], "dataTypes": ["quantitative"], "compositions": ["facet"], "aggregates": ["bin", "count"], "actionTargets": ["search-locate:Attributes-extremes"], "figId": "vis-3353_00", "figFile": "vis-3353_00.png", "figCaption": "", "figBox": {"x": 0.08159270998433557, "y": 0.09902048850478531, "width": 0.9080181213112959, "height": 0.503049648660092}, "figVis": ["bar_chart"], "relationText": "We want to visualize for which kind of input ranges the particular hidden node is mostly contributing. ", "note": ""}, {"viewId": "vis-3353_00_1", "viewFile": "vis-3353_00_1.png", "specification": {"mark": "line", "encoding": {"x": "dataset", "type": "nominal"}, "y": {"field": "target value", "type": "quantitative"}, "color": {"field": "target value", "type": "quantitative"}}, "marks": ["line"], "channels": ["x", "type"], "dataTypes": [], "compositions": [], "aggregates": [], "actionTargets": ["consume-discover:Attributes-correlation", "search-explore:Attributes-values"], "figId": "vis-3353_00", "figFile": "vis-3353_00.png", "figCaption": "", "figBox": {"x": 0.08853549738158432, "y": 0.6201105242207055, "width": 0.9062892486865491, "height": 0.367124692229792}, "figVis": ["parallel_coordinate"], "relationText": "We employ node-specific PCPs to let analysts explore parts of the data set at a time and investigate relationships between the variables", "note": ""}]